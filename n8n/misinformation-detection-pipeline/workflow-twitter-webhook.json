{
  "name": "Misinformation Detection - Twitter Webhook",
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "misinformation-check",
        "responseMode": "responseNode",
        "options": {}
      },
      "id": "webhook-trigger",
      "name": "Webhook Trigger",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1,
      "position": [250, 300],
      "webhookId": "misinformation-webhook"
    },
    {
      "parameters": {
        "jsCode": "// Parse incoming tweet data\nconst tweets = $input.item.json.tweets || [];\nconst results = [];\n\nfor (const tweet of tweets) {\n  results.push({\n    tweetText: tweet.tweetText || tweet.text,\n    tweetSource: tweet.tweetSource || tweet.source,\n    tweetMetadata: tweet.tweetMetadata || {},\n    twitterHandle: tweet.tweetMetadata?.account_handle || '',\n    accountData: tweet.tweetMetadata || {},\n    originalTweet: tweet\n  });\n}\n\nreturn results.map(item => ({ json: item }));"
      },
      "id": "parse-tweet-data",
      "name": "Parse Tweet Data",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [450, 300]
    },
    {
      "parameters": {
        "model": "gemini-pro",
        "options": {
          "temperature": 0.3
        },
        "prompt": "=ROLE: Factual Claim Verifier\n\nINPUT: {{ $json.tweetText }}\n\nPRIMARY MISSION:\nExtract and verify specific factual claims made in the tweet using authoritative sources.\n\nANALYSIS PROCESS:\n\nStep 1 - Claim Extraction:\n- Identify all verifiable factual claims (names, dates, events, statistics, quotes)\n- Distinguish between opinions and factual assertions\n- Flag claims that are presented as facts but lack specificity\n\nStep 2 - Claim Verification:\nUse the following sources in priority order:\n1. Professional fact-checking sites:\n   - https://www.snopes.com/\n   - https://www.politifact.com/\n   - https://www.factcheck.org/\n   - https://fullfact.org/\n   - https://factcheck.afp.com/\n\n2. Primary sources (for direct verification):\n   - Official government statements/websites\n   - Court documents and legal filings\n   - Academic papers and peer-reviewed research\n   - Original news reports from reputable outlets\n   - Company official statements\n\n3. Reverse image search (if images mentioned):\n   - https://images.google.com/\n   - https://tineye.com/\n\nStep 3 - Evidence Assessment:\n- Multiple credible sources confirm = VERIFIED\n- Multiple credible sources contradict = FALSE\n- Mixed evidence or lack of coverage = UNVERIFIED\n- Claim is too vague to verify = NOT VERIFIABLE\n\nRED FLAGS FOR MISINFORMATION:\n- Extraordinary claims without extraordinary evidence\n- Out-of-context statistics or quotes\n- Misleading temporal framing (\"just happened\" for old events)\n- Manipulated or misattributed images\n- Claims that contradict expert consensus\n- Emotional language designed to provoke rather than inform\n\nCLASSIFICATION CRITERIA:\n- TRUE: All major claims verified by multiple credible sources\n- MOSTLY TRUE: Core claims verified, minor details unverified\n- MIXED: Some claims true, others false or unverified\n- MOSTLY FALSE: Core claims contradicted or unverified\n- FALSE: Major claims definitively contradicted by evidence\n- UNVERIFIABLE: Claims too vague or lacking sufficient information\n\nOUTPUT FORMAT (JSON ONLY):\n{\n  \"verdict\": \"TRUE/MOSTLY_TRUE/MIXED/MOSTLY_FALSE/FALSE/UNVERIFIABLE\",\n  \"confidence\": \"high/medium/low\",\n  \"verified_claims\": [\n    {\n      \"claim\": \"specific claim text\",\n      \"status\": \"verified/false/unverified\",\n      \"evidence\": \"brief explanation\",\n      \"sources\": [\"source1\", \"source2\"]\n    }\n  ],\n  \"overall_assessment\": \"2-3 sentence summary of findings\",\n  \"fact_check_score\": 0-100\n}\n\nIMPORTANT NOTES:\n- Focus on CLAIMS, not opinions or predictions\n- A tweet can be opinion-heavy but factually accurate\n- Absence of evidence is not evidence of falsehood\n- Be transparent about limitations in verification\n\nRespond ONLY with valid JSON, no other text."
      },
      "id": "agent1-fact-check",
      "name": "Agent 1: Fact Check",
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [650, 200],
      "credentials": {
        "googleGeminiApi": {
          "id": "1",
          "name": "Google Gemini API"
        }
      }
    },
    {
      "parameters": {
        "model": "gemini-pro",
        "options": {
          "temperature": 0.3
        },
        "prompt": "=ROLE: Source Trustworthiness Evaluator\n\nINPUT:\n- Tweet source/domain: {{ $json.tweetSource }}\n- Tweet metadata: {{ JSON.stringify($json.tweetMetadata) }}\n\nPRIMARY MISSION:\nAssess the reliability and trustworthiness of the information source and detect potential bot behavior.\n\nANALYSIS PROCESS:\n\nPART A - SOURCE CREDIBILITY ASSESSMENT:\n\nStep 1 - Domain/Source Identification:\n- Extract domain or news source mentioned in tweet\n- Identify if tweet links to external source or is original claim\n\nStep 2 - Source Credibility Check:\nUse these databases in order:\n1. https://mediabiasfactcheck.com/ (MBFC ratings)\n2. https://www.newsguardtech.com/ (NewsGuard ratings)\n3. https://www.poynter.org/ifcn/ (IFCN verified signatories)\n4. Wikipedia list of fake news websites\n5. Domain age check via WHOIS lookup\n\nStep 3 - Source Classification:\n- HIGH CREDIBILITY: Established media, fact-checked, transparent methodology\n- MEDIUM CREDIBILITY: Known outlet but with bias or mixed record\n- LOW CREDIBILITY: Flagged by fact-checkers, history of misinformation\n- UNKNOWN: No available ratings, new or obscure source\n\nCREDIBILITY RED FLAGS:\n- Domain flagged by MBFC as \"questionable source\" or \"low credibility\"\n- NewsGuard rating below 60/100\n- Domain created recently (less than 1 year old)\n- Mimics legitimate news site names\n- No clear editorial standards or correction policy\n- History of publishing debunked claims\n\nPART B - BOT BEHAVIOR DETECTION:\n\nAccount Age Signals:\n- SUSPICIOUS: Account less than 30 days old\n- CAUTION: Account 30-90 days old\n- NORMAL: Account older than 90 days\n\nTweet Frequency Analysis:\n- Calculate: tweets per day ratio\n- SUSPICIOUS: >50 tweets per day consistently\n- CAUTION: 20-50 tweets per day\n- NORMAL: <20 tweets per day\n\nProfile Completeness Check:\n- Profile picture present? (1 point)\n- Bio/description present? (1 point)\n- Location specified? (1 point)\n- Verified account? (2 points)\n- Custom header image? (1 point)\n- SCORE: 0-1 = Incomplete, 2-3 = Partial, 4-6 = Complete\n\nBot Behavior Heuristics:\n- Repetitive posting patterns\n- Generic or nonsensical username\n- No original content, only retweets\n- Engagement ratio imbalance\n- Amplification of known misinformation sources\n\nOUTPUT FORMAT (JSON ONLY):\n{\n  \"source_credibility\": {\n    \"rating\": \"HIGH/MEDIUM/LOW/UNKNOWN\",\n    \"score\": 0-100,\n    \"explanation\": \"brief reasoning\",\n    \"sources_checked\": [\"MBFC\", \"NewsGuard\"],\n    \"red_flags\": []\n  },\n  \"bot_likelihood\": {\n    \"assessment\": \"HIGH_RISK/MODERATE_RISK/LOW_RISK/HUMAN_LIKELY\",\n    \"account_age_days\": 0,\n    \"tweets_per_day\": 0.0,\n    \"profile_completeness_score\": \"0/6\",\n    \"bot_indicators\": [],\n    \"confidence\": \"high/medium/low\"\n  },\n  \"overall_trustworthiness_score\": 0-100,\n  \"recommendation\": \"Brief summary for decision agent\"\n}\n\nSCORING LOGIC:\nOverall Trustworthiness = (Source Credibility × 0.6) + (Bot Assessment × 0.4)\n\nWhere Bot Assessment:\n- Human-likely account = 100\n- Low bot risk = 75\n- Moderate bot risk = 40\n- High bot risk = 10\n\nRespond ONLY with valid JSON, no other text."
      },
      "id": "agent2-credibility",
      "name": "Agent 2: Credibility",
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [650, 300],
      "credentials": {
        "googleGeminiApi": {
          "id": "1",
          "name": "Google Gemini API"
        }
      }
    },
    {
      "parameters": {
        "model": "gemini-pro",
        "options": {
          "temperature": 0.3
        },
        "prompt": "=ROLE: Twitter Account Behavior Analyst\n\nINPUT:\n- Account handle: {{ $json.twitterHandle }}\n- Account data: {{ JSON.stringify($json.accountData) }}\n\nREQUIRED DATA INPUTS:\n{\n  \"account_handle\": \"@username\",\n  \"account_created_date\": \"YYYY-MM-DD\",\n  \"follower_count\": number,\n  \"following_count\": number,\n  \"tweet_count\": number,\n  \"bio\": \"text or null\",\n  \"profile_image_url\": \"url or null\",\n  \"location\": \"text or null\",\n  \"verified\": true/false,\n  \"header_image_url\": \"url or null\",\n  \"recent_tweets\": []\n}\n\nPRIMARY MISSION:\nAnalyze Twitter account behavior patterns to identify automated, suspicious, or coordinated inauthentic behavior.\n\nANALYSIS FRAMEWORK:\n\nMETRIC 1 - Account Age Analysis:\n- Calculate: Days since account creation\n- RISK LEVELS:\n  * <7 days = VERY HIGH RISK\n  * 7-30 days = HIGH RISK\n  * 31-90 days = MODERATE RISK\n  * 91-365 days = LOW RISK\n  * >365 days = MINIMAL RISK\n\nMETRIC 2 - Tweet Frequency Analysis:\n- Calculate: Total tweets / Account age in days = tweets_per_day\n- RISK LEVELS:\n  * >100 tweets/day = VERY HIGH RISK\n  * 50-100 tweets/day = HIGH RISK\n  * 20-49 tweets/day = MODERATE RISK\n  * 10-19 tweets/day = LOW RISK\n  * <10 tweets/day = MINIMAL RISK\n\nMETRIC 3 - Profile Completeness Score:\n- Profile picture (not default) = 1 point\n- Bio/description filled out = 1 point\n- Location specified = 1 point\n- Verified badge = 2 points\n- Custom header image = 1 point\n- Website/link provided = 1 point\nTOTAL: X/7 points\n- 6-7 points = COMPLETE (low risk)\n- 4-5 points = PARTIAL (moderate risk)\n- 2-3 points = MINIMAL (high risk)\n- 0-1 points = INCOMPLETE (very high risk)\n\nMETRIC 4 - Follower/Following Ratio:\n- Calculate: follower_count / following_count\n- ANALYSIS:\n  * Ratio >10 = Influential/Popular\n  * Ratio 0.1-10 = Balanced\n  * Ratio <0.1 AND following >1000 = Spam pattern\n  * Ratio >100 AND followers <500 = Suspicious\n\nMETRIC 5 - Content Pattern Analysis:\nCheck for:\n- Repetitive content\n- Excessive hashtags (>5 per tweet)\n- Only retweets, no original content\n- Links to suspicious domains\n- Coordinated timing\n- Generic engagement farming\n\nBEHAVIORAL RED FLAGS:\n- Account created recently but tweeting excessively\n- Profile mostly incomplete\n- Username is random strings/numbers\n- No bio or generic bio\n- Ratio imbalanced\n- Repetitive or automated-looking content\n- Only tweets on controversial topics\n- Part of coordinated network\n\nOUTPUT FORMAT (JSON ONLY):\n{\n  \"account_analysis\": {\n    \"handle\": \"@username\",\n    \"account_age_days\": 0,\n    \"account_age_risk\": \"VERY_HIGH/HIGH/MODERATE/LOW/MINIMAL\",\n    \"tweets_per_day\": 0.0,\n    \"frequency_risk\": \"VERY_HIGH/HIGH/MODERATE/LOW/MINIMAL\",\n    \"profile_completeness\": {\n      \"score\": \"0/7\",\n      \"rating\": \"COMPLETE/PARTIAL/MINIMAL/INCOMPLETE\",\n      \"missing_elements\": []\n    },\n    \"follower_ratio\": 0.0,\n    \"follower_analysis\": \"interpretation\",\n    \"content_patterns\": {\n      \"repetitive_content\": false,\n      \"original_vs_retweets\": \"X% original\",\n      \"suspicious_patterns\": []\n    }\n  },\n  \"behavioral_red_flags\": [],\n  \"bot_probability\": \"VERY_HIGH/HIGH/MODERATE/LOW/MINIMAL\",\n  \"authenticity_score\": 0-100,\n  \"recommendation\": \"Brief assessment for decision agent\"\n}\n\nSCORING LOGIC:\nAuthenticity Score = weighted average of:\n- Account age (25%)\n- Tweet frequency (20%)\n- Profile completeness (25%)\n- Follower patterns (15%)\n- Content patterns (15%)\n\nNOTES:\n- Legitimate journalists/activists may have high tweet frequency\n- Verified accounts get credibility boost\n- New accounts aren't automatically suspicious if well-formed\n- Consider cultural context\n\nRespond ONLY with valid JSON, no other text."
      },
      "id": "agent3-twitter-check",
      "name": "Agent 3: Twitter Check",
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [650, 400],
      "credentials": {
        "googleGeminiApi": {
          "id": "1",
          "name": "Google Gemini API"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Parse all agent outputs and combine\nconst item = $input.item.json;\n\n// Parse JSON responses from agents\nlet agent1Output = {};\nlet agent2Output = {};\nlet agent3Output = {};\n\ntry {\n  agent1Output = typeof item.agent1 === 'string' ? JSON.parse(item.agent1) : item.agent1;\n} catch (e) {\n  agent1Output = { verdict: 'UNVERIFIABLE', confidence: 'low', fact_check_score: 50 };\n}\n\ntry {\n  agent2Output = typeof item.agent2 === 'string' ? JSON.parse(item.agent2) : item.agent2;\n} catch (e) {\n  agent2Output = { overall_trustworthiness_score: 50, bot_likelihood: { confidence: 'low' } };\n}\n\ntry {\n  agent3Output = typeof item.agent3 === 'string' ? JSON.parse(item.agent3) : item.agent3;\n} catch (e) {\n  agent3Output = { authenticity_score: 50 };\n}\n\nreturn [{\n  json: {\n    factCheckOutput: agent1Output,\n    credibilityOutput: agent2Output,\n    accountOutput: agent3Output,\n    originalData: item\n  }\n}];"
      },
      "id": "combine-agent-outputs",
      "name": "Combine Agent Outputs",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [850, 300]
    },
    {
      "parameters": {
        "conditions": {
          "string": [
            {
              "value1": "={{ $json.factCheckOutput.confidence }}",
              "operation": "equals",
              "value2": "low"
            },
            {
              "value1": "={{ $json.factCheckOutput.verdict }}",
              "operation": "equals",
              "value2": "UNVERIFIABLE"
            },
            {
              "value1": "={{ $json.credibilityOutput.bot_likelihood.confidence }}",
              "operation": "equals",
              "value2": "low"
            }
          ]
        },
        "combineOperation": "any"
      },
      "id": "check-backup-needed",
      "name": "Check if Backup Needed",
      "type": "n8n-nodes-base.if",
      "typeVersion": 1,
      "position": [1050, 300]
    },
    {
      "parameters": {
        "model": "gpt-4",
        "options": {
          "temperature": 0.3
        },
        "prompt": "=ROLE: Independent Factual Claim Verifier (Second Opinion)\n\nCONTEXT: Primary fact-check agent returned uncertain results.\n\nINPUT: {{ $json.originalData.tweetText }}\n\nPRIMARY AGENT OUTPUT: {{ JSON.stringify($json.factCheckOutput) }}\n\nPRIMARY MISSION:\nProvide independent verification of factual claims using the same methodology but different reasoning approach.\n\nUse the same process as primary agent, but:\n- Approach verification from different angles\n- Consider alternative interpretations of claims\n- Look for sources primary agent might have missed\n- Apply independent judgment on ambiguous cases\n\nOUTPUT FORMAT (JSON ONLY):\n{\n  \"verdict\": \"TRUE/MOSTLY_TRUE/MIXED/MOSTLY_FALSE/FALSE/UNVERIFIABLE\",\n  \"confidence\": \"high/medium/low\",\n  \"verified_claims\": [\n    {\n      \"claim\": \"specific claim text\",\n      \"status\": \"verified/false/unverified\",\n      \"evidence\": \"brief explanation\",\n      \"sources\": [\"source1\", \"source2\"]\n    }\n  ],\n  \"overall_assessment\": \"2-3 sentence summary of findings\",\n  \"fact_check_score\": 0-100,\n  \"backup_notes\": \"What primary agent might have missed\"\n}\n\nRespond ONLY with valid JSON, no other text."
      },
      "id": "agent1b-backup-fact-check",
      "name": "Agent 1B: Backup Fact Check",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1,
      "position": [1250, 200],
      "credentials": {
        "openAiApi": {
          "id": "2",
          "name": "OpenAI API"
        }
      }
    },
    {
      "parameters": {
        "model": "gpt-4",
        "options": {
          "temperature": 0.3
        },
        "prompt": "=ROLE: Independent Source Trustworthiness Evaluator (Second Opinion)\n\nCONTEXT: Primary credibility agent returned uncertain results.\n\nINPUT:\n- Tweet source: {{ $json.originalData.tweetSource }}\n- Tweet metadata: {{ JSON.stringify($json.originalData.tweetMetadata) }}\n\nPRIMARY AGENT OUTPUT: {{ JSON.stringify($json.credibilityOutput) }}\n\nPRIMARY MISSION:\nProvide independent assessment of source credibility and bot likelihood using the same methodology but different reasoning approach.\n\nUse the same process as primary agent, but:\n- Apply independent judgment on borderline cases\n- Consider cultural/regional context for bot detection\n- Look for nuances primary agent might have missed\n\nOUTPUT FORMAT (JSON ONLY):\n{\n  \"source_credibility\": {\n    \"rating\": \"HIGH/MEDIUM/LOW/UNKNOWN\",\n    \"score\": 0-100,\n    \"explanation\": \"brief reasoning\",\n    \"sources_checked\": [\"MBFC\", \"NewsGuard\"],\n    \"red_flags\": []\n  },\n  \"bot_likelihood\": {\n    \"assessment\": \"HIGH_RISK/MODERATE_RISK/LOW_RISK/HUMAN_LIKELY\",\n    \"account_age_days\": 0,\n    \"tweets_per_day\": 0.0,\n    \"profile_completeness_score\": \"0/6\",\n    \"bot_indicators\": [],\n    \"confidence\": \"high/medium/low\"\n  },\n  \"overall_trustworthiness_score\": 0-100,\n  \"recommendation\": \"Brief summary for decision agent\",\n  \"backup_notes\": \"What primary agent might have missed\"\n}\n\nRespond ONLY with valid JSON, no other text."
      },
      "id": "agent2b-backup-credibility",
      "name": "Agent 2B: Backup Credibility",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1,
      "position": [1250, 300],
      "credentials": {
        "openAiApi": {
          "id": "2",
          "name": "OpenAI API"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Average scores if backup agents were triggered\nconst item = $input.item.json;\n\nlet finalFactCheck = item.factCheckOutput;\nlet finalCredibility = item.credibilityOutput;\n\n// If backup agents ran, average the scores\nif (item.agent1b) {\n  const backup1 = typeof item.agent1b === 'string' ? JSON.parse(item.agent1b) : item.agent1b;\n  finalFactCheck.fact_check_score = Math.round(\n    (finalFactCheck.fact_check_score + backup1.fact_check_score) / 2\n  );\n  finalFactCheck.confidence = 'medium'; // Downgrade confidence when agents disagree\n  finalFactCheck.backup_used = true;\n}\n\nif (item.agent2b) {\n  const backup2 = typeof item.agent2b === 'string' ? JSON.parse(item.agent2b) : item.agent2b;\n  finalCredibility.overall_trustworthiness_score = Math.round(\n    (finalCredibility.overall_trustworthiness_score + backup2.overall_trustworthiness_score) / 2\n  );\n  finalCredibility.confidence = 'medium';\n  finalCredibility.backup_used = true;\n}\n\nreturn [{\n  json: {\n    factCheckOutput: finalFactCheck,\n    credibilityOutput: finalCredibility,\n    accountOutput: item.accountOutput\n  }\n}];"
      },
      "id": "merge-backup-results",
      "name": "Merge Backup Results",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1450, 300]
    },
    {
      "parameters": {
        "model": "gemini-pro",
        "options": {
          "temperature": 0.2
        },
        "prompt": "=ROLE: Final Misinformation Risk Assessor\n\nINPUT:\n- Fact-check results: {{ JSON.stringify($json.factCheckOutput) }}\n- Source credibility results: {{ JSON.stringify($json.credibilityOutput) }}\n- Account analysis results: {{ JSON.stringify($json.accountOutput) }}\n\nPRIMARY MISSION:\nSynthesize all agent outputs to produce a final misinformation risk classification and actionable recommendation.\n\nDECISION FRAMEWORK:\n\nSTEP 1 - Data Integration:\nCollect scores from previous agents:\n- Fact Check Score: {{ $json.factCheckOutput.fact_check_score }}\n- Source Trustworthiness Score: {{ $json.credibilityOutput.overall_trustworthiness_score }}\n- Account Authenticity Score: {{ $json.accountOutput.authenticity_score }}\n\nSTEP 2 - Weighted Risk Calculation:\nRisk Score = (Fact Check × 0.50) + (Source Credibility × 0.30) + (Account Authenticity × 0.20)\n\nReasoning:\n- Fact accuracy is most important (50%)\n- Source matters but doesn't override facts (30%)\n- Account behavior is supplementary indicator (20%)\n\nSTEP 3 - Risk Classification:\n- HIGH RISK (0-40): Claims FALSE, source LOW credibility, multiple red flags\n  Actions: Flag for review, warning label, alert moderation\n- MEDIUM RISK (41-70): Claims MIXED/UNVERIFIABLE, source MEDIUM credibility\n  Actions: Add context label, monitor engagement, reduce amplification\n- LOW RISK (71-100): Claims TRUE, source HIGH credibility, account authentic\n  Actions: No intervention needed\n\nSTEP 4 - Contextual Adjustments:\nINCREASE risk if:\n- Urgent breaking news (higher harm potential)\n- Public health, elections, or safety topics\n- Large engagement (>1000 shares)\n- Coordinated campaign detected\n- Emotionally manipulative language\n\nDECREASE risk if:\n- Clearly marked as opinion/satire\n- Limited reach\n- Account has history of reliable information\n- Content is nuanced\n\nSTEP 5 - Confidence Assessment:\n- HIGH CONFIDENCE: All agents agree, clear evidence\n- MEDIUM CONFIDENCE: Some conflicting signals\n- LOW CONFIDENCE: Limited data, need human review\n\nSPECIAL CASES:\n- Fact FALSE but source HIGH: Flag for human review\n- Account BOT but fact TRUE: MEDIUM risk (inauthentic amplification)\n- Account AUTHENTIC but fact FALSE: HIGH risk\n- Any agent LOW confidence: Flag for human review\n\nESCALATION CRITERIA:\nEscalate to human if:\n- Risk HIGH and engagement >10,000\n- Imminent harm (violence, health crisis)\n- Coordinated campaign detected\n- Legal implications\n- All agents LOW confidence\n\nOUTPUT FORMAT (JSON ONLY):\n{\n  \"final_assessment\": {\n    \"risk_level\": \"HIGH/MEDIUM/LOW\",\n    \"composite_score\": 0-100,\n    \"confidence\": \"HIGH/MEDIUM/LOW\"\n  },\n  \"contributing_factors\": {\n    \"fact_check_verdict\": \"from agent 1\",\n    \"fact_check_score\": 0,\n    \"source_credibility\": \"from agent 2\",\n    \"source_score\": 0,\n    \"account_authenticity\": \"from agent 3\",\n    \"account_score\": 0\n  },\n  \"key_concerns\": [\n    \"List 2-3 most important red flags\"\n  ],\n  \"mitigating_factors\": [\n    \"List any factors that reduce concern\"\n  ],\n  \"recommended_action\": {\n    \"primary_action\": \"specific recommendation\",\n    \"rationale\": \"why this action\",\n    \"urgency\": \"immediate/within_24h/monitor/none\"\n  },\n  \"human_review_needed\": true,\n  \"human_review_reason\": \"explanation if true\",\n  \"summary\": \"1-2 sentence plain-language explanation for moderators\"\n}\n\nRespond ONLY with valid JSON, no other text."
      },
      "id": "agent4-decision",
      "name": "Agent 4: Decision",
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [1650, 300],
      "credentials": {
        "googleGeminiApi": {
          "id": "1",
          "name": "Google Gemini API"
        }
      }
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ $json }}"
      },
      "id": "webhook-response",
      "name": "Webhook Response",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [1850, 300]
    }
  ],
  "connections": {
    "Webhook Trigger": {
      "main": [
        [
          {
            "node": "Parse Tweet Data",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Parse Tweet Data": {
      "main": [
        [
          {
            "node": "Agent 1: Fact Check",
            "type": "main",
            "index": 0
          },
          {
            "node": "Agent 2: Credibility",
            "type": "main",
            "index": 0
          },
          {
            "node": "Agent 3: Twitter Check",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Agent 1: Fact Check": {
      "main": [
        [
          {
            "node": "Combine Agent Outputs",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Agent 2: Credibility": {
      "main": [
        [
          {
            "node": "Combine Agent Outputs",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Agent 3: Twitter Check": {
      "main": [
        [
          {
            "node": "Combine Agent Outputs",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Combine Agent Outputs": {
      "main": [
        [
          {
            "node": "Check if Backup Needed",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Check if Backup Needed": {
      "main": [
        [
          {
            "node": "Agent 1B: Backup Fact Check",
            "type": "main",
            "index": 0
          },
          {
            "node": "Agent 2B: Backup Credibility",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Agent 4: Decision",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Agent 1B: Backup Fact Check": {
      "main": [
        [
          {
            "node": "Merge Backup Results",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Agent 2B: Backup Credibility": {
      "main": [
        [
          {
            "node": "Merge Backup Results",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge Backup Results": {
      "main": [
        [
          {
            "node": "Agent 4: Decision",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Agent 4: Decision": {
      "main": [
        [
          {
            "node": "Webhook Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {},
  "staticData": null,
  "tags": [],
  "triggerCount": 0,
  "updatedAt": "2025-12-02T00:00:00.000Z",
  "versionId": "1"
}
