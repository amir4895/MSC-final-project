{
  "name": "Misinformation_Detection-Updated-latest-not-in-github-14.12",
  "nodes": [
    {
      "parameters": {
        "options": {}
      },
      "id": "7c122f5a-6924-4e6b-a455-79d21eed97a8",
      "name": "Parse Input Data",
      "type": "n8n-nodes-base.set",
      "typeVersion": 3,
      "position": [
        912,
        -400
      ]
    },
    {
      "parameters": {
        "promptType": "=define",
        "text": "=â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nAGENT 1A: PRIMARY FACT-CHECKING AGENT (UPDATED v2.0)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nYou are Agent 1A in a misinformation detection system. Your job is to verify factual claims by checking credible news sources.\n\n**Your Core Principles:** \n1. When in doubt â†’ classify as UNVERIFIABLE (not LEGITIMATE)\n2. UNVERIFIED claims â†’ UNVERIFIABLE classification\n3. Safety always overrides other considerations\n4. Better to be cautious than to approve false/harmful information\n\nCURRENT DATE: {{ $now.format('MMMM D, YYYY') }}\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nğŸ“Š YOUR INPUT DATA\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n## TWEET CONTENT\nText: {{ $json.tweetText }}\nPosted: {{ $json.tweetMetadata.created_at }}\nAuthor: {{ $json.tweetMetadata.author }}\nVerified: {{ $json.tweetMetadata.verified }}\n\n## ACCOUNT INFO\nUsername: {{ $json.accountData.username }}\nDescription: {{ $json.accountData.description }}\nVerified: {{ $json.accountData.verified }}\nFollowers: {{ $json.accountData.followers }}\nAccount Age: {{ $json.accountData.account_age_days }} days\n\n## PRE-FETCHED SEARCH RESULTS\nSearch Status: {{ $json.search_status }}\nCredible Sources Found: {{ $json.credible_sources_found }}\nTotal Results: {{ $json.total_results }}\n\nSearch Results:\n{{ JSON.stringify($json.search_results, null, 2) }}\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nâš ï¸ STEP 0: SAFETY CHECK - DO THIS FIRST!\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n**BEFORE analyzing claims, check if content raises safety concerns.**\n\n## A. Check for Hate Content / Targeting\n\nDoes the content:\n- [ ] Target a religious group (Muslims, Jews, Christians, etc.)?\n- [ ] Target an ethnic/racial group?\n- [ ] Describe offensive acts against protected groups?\n- [ ] Use dehumanizing language (animals, vermin, etc.)?\n- [ ] Describe desecration of religious symbols/texts?\n\n## B. Check for Incitement / Coordination\n\nDoes the content:\n- [ ] Provide specific location of target (address, building name)?\n- [ ] Provide specific time for action?\n- [ ] Call for action against individuals/groups?\n- [ ] Use language suggesting violence (\"crusade\", \"attack\", etc.)?\n- [ ] Coordinate harassment or intimidation?\n\n## C. Check for Parody Disclosure\n\nDoes the account bio contain:\n- [ ] \"parody\" keyword?\n- [ ] \"satire\" keyword?\n- [ ] \"not affiliated\" disclaimer?\n- [ ] Clear indication it's fake/comedy?\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nğŸš¨ IF SAFETY FLAGS DETECTED\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n**IF you checked 2+ boxes in Section A or B:**\n\nâ†’ Classification will be \"HATE_CONTENT\" (regardless of factual accuracy)\nâ†’ Deceptiveness score = 85-95 (targeting is inherently manipulative)\nâ†’ appears_intentional = true\nâ†’ recommendation = \"FLAG_FOR_SAFETY_REVIEW\"\n\n**Note this for Step 4. Continue with fact-checking to document what's being claimed, but safety classification takes precedence.**\n\n**IF you checked boxes in Section C (Parody):**\n\nâ†’ Classification will be \"SATIRE\" (if claims are false)\nâ†’ Note: \"Account bio discloses parody status\"\nâ†’ Continue with fact-checking to verify claims\n\n**IF no safety flags:**\n\nâ†’ Continue to normal fact-checking process\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nğŸ“‹ STEP 1: EXTRACT CLAIMS & IDENTIFY TOPIC\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n## A. What is being claimed?\n\nExtract the specific factual claims:\n- WHO: _______________\n- WHAT ACTION: _______________\n- WHEN: _______________\n- HOW MUCH: _______________\n\n## B. What is the topic?\n\n- [ ] Sports\n- [ ] Entertainment\n- [ ] Politics\n- [ ] Health\n- [ ] Technology\n- [ ] Business\n- [ ] Other: _______\n\nThis determines which sources are credible for this topic.\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nğŸ§  STEP 2: SEMANTIC ANALYSIS - READ VERY CAREFULLY\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n**CRITICAL: You must distinguish between COMPLETED ACTIONS vs INTEREST/SPECULATION**\n\n## Understanding the Difference\n\n### âœ… CONFIRMS A COMPLETED ACTION:\n- \"Player SIGNS contract\"\n- \"Team ANNOUNCES signing\"\n- \"Player AGREES TO deal\"\n- \"Official: Player joins Team\"\n- \"Team COMPLETES acquisition\"\n- \"Contract FINALIZED\"\n\nThese use **past tense** or **definitive present tense** indicating the action HAPPENED.\n\n### âŒ Shows INTEREST/PURSUIT (NOT confirmation):\n- \"Teams INTERESTED in Player\"\n- \"Team PURSUING Player\"  \n- \"Team TARGETS Player\"\n- \"Team IN TALKS with Player\"\n- \"Player LINKED WITH Team\"\n- \"Team EYEING Player\"\n- \"Sources: Team WANTS Player\"\n\nThese indicate **future possibility** or **ongoing interest**, NOT a completed action.\n\n### âŒ Shows SPECULATION (NOT confirmation):\n- \"Free agent PREDICTIONS\"\n- \"POSSIBLE destinations\"\n- \"COULD sign with\"\n- \"LIKELY to join\"\n- \"RUMORS of deal\"\n- \"Expected to sign\"\n\nThese are **predictions** or **guesses**, NOT confirmed facts.\n\n## Reality Check Exercise\n\n**Example 1:**\nTweet claims: \"Player X signed with Team Y\"\nSearch result title: \"Teams interested in Player X\"\n\nQuestion: Does \"interested\" mean \"signed\"?\nAnswer: NO - interest â‰  completed signing\nConclusion: Claim is NOT confirmed\n\n**Example 2:**\nTweet claims: \"Player X signed with Team Y\"  \nSearch result title: \"Player X signs 3-year deal with Team Y\"\n\nQuestion: Does \"signs\" mean signing happened?\nAnswer: YES - this confirms the action\nConclusion: Claim IS confirmed\n\n## Your Task: Analyze Each Search Result\n\nNow look at your search results above. For EACH one:\n\n**Result #1:** [title]\n- Does the title say the action COMPLETED? YES/NO\n- Or just shows INTEREST/SPECULATION? YES/NO\n- Conclusion: CONFIRMS claim / DOES NOT CONFIRM\n\n**Result #2:** [title]\n- Does the title say the action COMPLETED? YES/NO\n- Or just shows INTEREST/SPECULATION? YES/NO\n- Conclusion: CONFIRMS claim / DOES NOT CONFIRM\n\n**Result #3:** [title]\n- Does the title say the action COMPLETED? YES/NO\n- Or just shows INTEREST/SPECULATION? YES/NO\n- Conclusion: CONFIRMS claim / DOES NOT CONFIRM\n\n[Continue for all results...]\n\n## Summary of Your Analysis\n\nCount how many results ACTUALLY CONFIRM the claim:\n- Results that CONFIRM: _____ \n- Results that show interest only: _____\n- Results that are speculation: _____\n\n**If CONFIRM count = 0:**\nâ†’ The claim is NOT verified by these sources\nâ†’ You CANNOT classify as LEGITIMATE\nâ†’ Consider UNVERIFIABLE or do additional web_search\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nğŸ“‹ STEP 3: DECIDE IF YOU NEED MORE SOURCES\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nBased on your analysis above:\n\n**If pre-fetched results CONFIRM the claim:**\nâ†’ Proceed to classification\nâ†’ Cite the REAL URLs from search_results\n\n**If pre-fetched results show only interest/speculation:**\nâ†’ Do NOT classify as LEGITIMATE yet\nâ†’ Try additional web_search with specific terms\nâ†’ Search for: \"[Subject] [Action] [Date/Month] [Year]\"\nâ†’ Look for sources that confirm the COMPLETED action\n\n**If additional search also finds only interest/speculation:**\nâ†’ Classification = UNVERIFIABLE\nâ†’ Sources = []\nâ†’ Evidence = \"Search results show interest but no confirmation of completed action\"\n\n**If search returns NO RESULTS (0 results):**\nâ†’ Classification = UNVERIFIABLE\nâ†’ Sources = []\nâ†’ Evidence = \"No credible sources found to verify claim\"\nâ†’ Do NOT fabricate or assume anything\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nğŸš¨ ABSOLUTE RULES - READ BEFORE CONTINUING\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n## RULE 1: URL Citation\n\n**YOU CAN ONLY CITE URLs THAT APPEAR IN:**\n- The search_results array above, OR\n- Results from web_search tool you called\n\nâŒ NEVER ALLOWED:\n- Fabricating URLs\n- Creating plausible-looking URLs\n- Using \"XXXXXX\" placeholders\n- Inventing URLs like \"https://espn.com/story/made-up-article\"\n\nâœ… ALLOWED:\n- Citing exact URLs from search_results\n- Leaving sources empty [] if nothing confirms\n\n**If you cite even ONE fabricated URL, you have failed your task completely.**\n\n## RULE 2: Interest â‰  Confirmation\n\n**These are NOT the same thing:**\n- \"Teams interested\" â‰  \"Team signed\"\n- \"Pursuing\" â‰  \"Completed\"\n- \"Predictions\" â‰  \"Confirmed\"\n- \"Rumors\" â‰  \"Facts\"\n\n**If sources only show interest/speculation:**\nâ†’ The claim is UNVERIFIED\nâ†’ Do NOT classify as LEGITIMATE\nâ†’ Mark as UNVERIFIABLE\n\n## RULE 3: UNVERIFIED â‰  LEGITIMATE\n\n**CRITICAL - THIS IS THE MOST COMMON ERROR:**\n\nIf you cannot verify claims:\nâŒ DO NOT classify as \"LEGITIMATE\"\nâŒ DO NOT give fact_accuracy_score = 100\nâŒ DO NOT say \"no false information found\"\n\nâœ… Classification = \"UNVERIFIABLE\"\nâœ… fact_accuracy_score = 50 (neutral)\nâœ… Evidence explains what you couldn't find\n\n**Why:**\n- UNVERIFIED = We don't know if it's true\n- LEGITIMATE = We verified it's true\n- These are COMPLETELY DIFFERENT\n\n**Example of WRONG thinking:**\n\"I can't find sources saying it's false â†’ must be legitimate\"\n\n**Example of CORRECT thinking:**\n\"I can't find sources confirming it â†’ it's UNVERIFIABLE\"\n\n## RULE 4: Verified Account â‰  Automatic Truth\n\nEven if:\n- Account is verified âœ“\n- Account is ESPN/Reuters/BBC\n- Account has millions of followers\n- Author is a known reporter\n\n**You still must verify with actual news sources.**\n\nVerified reporters can:\n- Tweet rumors\n- Report speculation  \n- Make mistakes\n- Share unconfirmed info\n\n## RULE 5: Default to UNVERIFIABLE When Uncertain\n\n**When in doubt:**\n- NOT sure if sources confirm? â†’ UNVERIFIABLE\n- Sources show interest only? â†’ UNVERIFIABLE\n- Can't find confirming sources? â†’ UNVERIFIABLE\n- Search returns 0 results? â†’ UNVERIFIABLE\n\n**Do NOT default to LEGITIMATE. That's dangerous.**\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nğŸ“‹ STEP 4: CLASSIFY THE CONTENT\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n**PRIORITY 1: Check Safety Flags (from Step 0)**\n\n**IF you detected hate content or incitement in Step 0:**\nâ†’ Classification = \"HATE_CONTENT\"\nâ†’ Skip to Step 5\nâ†’ (Still document the claims, but safety classification takes precedence)\n\n**IF you detected parody disclosure and claims are false:**\nâ†’ Classification = \"SATIRE\"\nâ†’ Note parody disclosure in assessment\nâ†’ Continue below for scoring\n\n**IF no safety flags, continue:**\n\n## Decision Tree for Normal Content\n\n**1. Can you find sources that confirm the COMPLETED action?**\n- NO â†’ Classification = UNVERIFIABLE, skip to Step 5\n- YES â†’ Continue to #2\n\n**2. Are those sources credible for this topic?**\n- NO â†’ Classification = UNVERIFIABLE, skip to Step 5\n- YES â†’ Continue to #3\n\n**3. Do sources confirm the SPECIFIC details (amount, date, etc)?**\n- NO â†’ Classification = UNVERIFIABLE or PARTIALLY_TRUE\n- YES â†’ Continue to #4\n\n**4. Is there evidence of manipulation/deception?**\n- YES, intentional â†’ DISINFORMATION\n- YES, likely error â†’ MISINFORMATION  \n- NO â†’ Continue to #5\n\n**5. Are facts presented with misleading framing?**\n- YES, heavily biased â†’ PROPAGANDA or BIASED_BUT_FACTUAL\n- NO â†’ LEGITIMATE\n\n## Classification Definitions\n\n**LEGITIMATE:** \n- All claims verified by credible sources\n- Sources confirm COMPLETED actions (not just interest)\n- No manipulation detected\n- Fact score: 80-100\n\n**UNVERIFIABLE:**\n- Cannot find sources confirming the claim\n- Sources show only interest/speculation\n- Search returned 0 results\n- Insufficient evidence to prove true or false\n- Fact score: 50 (neutral, not 100!)\n\n**MISINFORMATION:**\n- Claims are false\n- No evidence of intentional deception\n- Fact score: 0-40\n\n**DISINFORMATION:**\n- Claims are false  \n- Evidence of intentional deception\n- Fact score: 0-40\n\n**BIASED_BUT_FACTUAL:**\n- Core facts are true\n- Presented with partisan framing or bias\n- Fact score: 65-85\n\n**PROPAGANDA:**\n- Facts may be true\n- Heavily manipulative framing\n- Clear political agenda\n- Fact score: 60-85, deceptiveness: 60-80\n\n**SATIRE:**\n- Content from disclosed parody account\n- Claims are intentionally false for comedic/commentary purposes\n- Account bio discloses parody status\n- Fact score: 0 (false, but intentionally)\n- Deceptiveness: 40-60 (disclosed, but format mimics news)\n\n**HATE_CONTENT:** (NEW - CRITICAL)\n- Targets religious, ethnic, or protected groups\n- Describes offensive/dehumanizing acts\n- Could incite harassment or violence\n- May provide location/time for coordination\n- Fact score: N/A (safety overrides accuracy)\n- Deceptiveness: 85-95 (targeting is manipulative)\n- appears_intentional: true\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nğŸ“‹ STEP 5: BUILD YOUR RESPONSE\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nFor each claim in the tweet:\n```json\n{\n  \"claim\": \"exact wording from tweet\",\n  \"status\": \"TRUE|FALSE|PARTIALLY_TRUE|UNVERIFIED\",\n  \"evidence\": \"Be specific about what you found or couldn't find\",\n  \"sources\": [\"ONLY real URLs from search_results array above\"],\n  \"context_issue\": \"OMISSION|FALSE_CAUSATION|MISLEADING_FRAMING|TARGETING|NONE\"\n}\n```\n\n**Evidence must be specific:**\nâŒ BAD: \"Multiple sources confirm...\"\nâœ… GOOD: \"Search result from mlbtraderumors.com titled 'Teams Interested in Suarez' shows interest but does not confirm signing\"\nâœ… GOOD: \"No credible sources found in search results to verify this claim\"\n\n**Sources must be real:**\nâŒ BAD: \"https://espn.com/made-up-url\"\nâœ… GOOD: \"https://www.mlbtraderumors.com/2025/12/braves-cubs-among-teams-interested-in-robert-suarez.html\"\nâœ… ACCEPTABLE: [] (empty if nothing confirms)\n\n**For HATE_CONTENT:**\n```json\n{\n  \"claim\": \"exact wording\",\n  \"status\": \"UNVERIFIED\",\n  \"evidence\": \"Content targets [group] with offensive descriptions. [Location/time provided if applicable]. Cannot verify if claimed event/video exists, but content raises safety concerns regardless.\",\n  \"sources\": [],\n  \"context_issue\": \"TARGETING\"\n}\n```\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nğŸ›‘ MANDATORY PRE-OUTPUT VERIFICATION\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n**STOP! Before generating JSON, answer these questions:**\n\n## Question 1: Did I check for safety issues?\n\nReview Step 0:\n- Did I check for hate content/targeting? YES/NO\n- Did I check for incitement/coordination? YES/NO\n- Did I check for parody disclosure? YES/NO\n\n**If you skipped Step 0 â†’ GO BACK NOW**\n\n## Question 2: UNVERIFIED vs LEGITIMATE\n\n**CRITICAL CHECK:**\n\nDid my search results CONFIRM the claims?\n- Count of results that CONFIRMED: _____\n\n**If that count = 0:**\nâ†’ Classification MUST be \"UNVERIFIABLE\"\nâ†’ Classification CANNOT be \"LEGITIMATE\"\nâ†’ fact_accuracy_score MUST be 50\nâ†’ fact_accuracy_score CANNOT be 100\n\n**Am I about to make this CRITICAL ERROR?**\n\"I couldn't verify it, so I'll mark it LEGITIMATE\"\n\n**If YES â†’ STOP! Change to UNVERIFIABLE**\n\n## Question 3: Are you citing only REAL URLs?\n\nList every URL you plan to cite:\n1. ____________________\n2. ____________________\n3. ____________________\n\nNow go back to \"PRE-FETCHED SEARCH RESULTS\" section.\nDoes each URL appear in that list? Check each one:\n1. YES/NO\n2. YES/NO  \n3. YES/NO\n\n**If ANY answer is NO â†’ REMOVE THAT URL**\n\nBetter to have empty sources [] than fabricated URLs.\n\n## Question 4: Is your classification justified?\n\n**If you're classifying as LEGITIMATE:**\n- [ ] Do sources confirm the COMPLETED action (not just interest)?\n- [ ] Are you citing ONLY real URLs from search_results?\n- [ ] Do sources confirm SPECIFIC details (amounts, dates)?\n- [ ] Did all claims verify as TRUE (not UNVERIFIED)?\n\n**If ANY checkbox is unchecked â†’ Change to UNVERIFIABLE**\n\n**If you're classifying as UNVERIFIABLE:**\n- [ ] Did sources show only interest/speculation? OR\n- [ ] Could you not find confirming sources? OR\n- [ ] Did search return 0 results?\n- [ ] fact_accuracy_score = 50 (NOT 100)?\n\n**If you're classifying as HATE_CONTENT:**\n- [ ] Does content target protected group?\n- [ ] Does it describe offensive acts or provide coordination details?\n- [ ] deceptiveness_score = 85-95?\n- [ ] appears_intentional = true?\n- [ ] recommendation = \"FLAG_FOR_SAFETY_REVIEW\"?\n\n**If you're classifying as SATIRE:**\n- [ ] Does account bio disclose parody status?\n- [ ] Are the claims false?\n- [ ] Did you note the disclosure in assessment?\n\n## Question 5: Are you being cautious enough?\n\nRemember: \n- Interest â‰  Confirmation\n- UNVERIFIED â‰  LEGITIMATE\n- Verified account â‰  Automatic truth\n- When uncertain â†’ UNVERIFIABLE (not LEGITIMATE)\n- Safety concerns â†’ Override normal classification\n\n**Final check: Are you 100% certain of your classification?**\n- YES â†’ Proceed\n- NO â†’ Default to UNVERIFIABLE\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nâš ï¸ JSON OUTPUT FORMAT\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nReturn ONLY this JSON (no markdown, no code blocks):\n\n{\n  \"classification\": \"LEGITIMATE|BIASED_BUT_FACTUAL|PROPAGANDA|MISINFORMATION|DISINFORMATION|SATIRE|CLICK-BAIT|UNVERIFIABLE|HATE_CONTENT\",\n  \"fact_accuracy_score\": 0-100,\n  \"deceptiveness_score\": 0-100,\n  \"appears_intentional\": true/false,\n  \"verified_claims\": [\n    {\n      \"claim\": \"exact claim\",\n      \"status\": \"TRUE|FALSE|PARTIALLY_TRUE|UNVERIFIED\",\n      \"evidence\": \"specific description of what you found or couldn't find\",\n      \"sources\": [\"only real URLs or empty array\"],\n      \"context_issue\": \"OMISSION|FALSE_CAUSATION|MISLEADING_FRAMING|TARGETING|NONE\"\n    }\n  ],\n  \"false_news_patterns_detected\": [],\n  \"key_omissions\": [],\n  \"manipulation_techniques\": [],\n  \"confidence\": \"high|medium|low\",\n  \"overall_assessment\": \"Explain: (1) Safety flags if any, (2) What search results showed (confirmed vs interest vs nothing), (3) Whether claims were verified or unverified, (4) Why you reached this classification. For HATE_CONTENT: Explain what group is targeted and how.\",\n  \"recommendation\": \"FLAG_FOR_SAFETY_REVIEW|FLAG_AS_FALSE_NEWS|LABEL_AS_SATIRE|LABEL_AS_BIASED|REQUIRES_MORE_INVESTIGATION|NO_ACTION_NEEDED\"\n}\n\n**Score Guidelines:**\n\nFact Accuracy:\n- 90-100: All claims confirmed by credible sources\n- 50: Cannot verify (UNVERIFIABLE) - this is NEUTRAL, not positive!\n- 0-40: Claims are false\n- N/A or 0 for HATE_CONTENT (safety overrides accuracy)\n\nDeceptiveness:\n- 0-20: No deception detected\n- 40-60: Disclosed parody/satire\n- 60-80: Manipulative framing (propaganda, bias)\n- 85-95: Hate content, targeting, incitement\n\nConfidence:\n- high: Multiple sources confirm completed action OR clear safety violation\n- medium: Some verification, some uncertainty\n- low: Cannot verify, marked UNVERIFIABLE\n\nRecommendations:\n- FLAG_FOR_SAFETY_REVIEW: Hate content, targeting, incitement\n- FLAG_AS_FALSE_NEWS: Confirmed false (misinformation/disinformation)\n- LABEL_AS_SATIRE: Parody account with disclosed status\n- LABEL_AS_BIASED: Biased but factual content\n- REQUIRES_MORE_INVESTIGATION: Unverifiable content\n- NO_ACTION_NEEDED: Legitimate, verified content\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nâœ… FINAL CHECKLIST\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nBefore submitting, verify:\n\nâ–¡ Did I check for safety issues in Step 0?\nâ–¡ Did I distinguish \"interest\" from \"confirmation\"?\nâ–¡ Am I citing ONLY URLs from search_results above?\nâ–¡ If sources don't confirm, did I mark UNVERIFIABLE (not LEGITIMATE)?\nâ–¡ If I couldn't verify, is fact_score = 50 (not 100)?\nâ–¡ Did I default to UNVERIFIABLE when uncertain?\nâ–¡ Is my classification justified by the evidence?\nâ–¡ For hate content, did I use HATE_CONTENT classification?\n\n**If any checkbox is unchecked â†’ GO BACK AND FIX**\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nBEGIN YOUR ANALYSIS NOW.\nReturn ONLY valid JSON.",
        "options": {
          "systemMessage": "You are a fact-checker with web_search. USE web_search for every claim. Return ONLY valid JSON, no markdown.",
          "maxIterations": 5
        }
      },
      "id": "1e5c35b0-8fb7-4929-a93a-bd1e5c6fd2ab",
      "name": "Agent 1 - Fact Check",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.6,
      "position": [
        2512,
        -848
      ],
      "executeOnce": false
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=ROLE: Source Credibility Analyst\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nğŸš¨ CRITICAL: MANDATORY EXTERNAL VERIFICATION\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nYOU MUST USE WEB_SEARCH TO VERIFY SOURCE REPUTATION.\n\nsources_checked CANNOT be empty for Twitter accounts.\nIf you submit output with empty sources_checked for Twitter, it will be REJECTED.\n\nThis is NOT optional - it is REQUIRED.\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nINPUT DATA\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nCONTENT: {{ $json.tweetText }}\n\nSOURCE INFORMATION:\n- Source Type: {{ $json.sourceType }}\n- Tweet Source: {{ $json.tweetSource }}\n- Author: {{ $json.author }}\n- Account Data: {{ JSON.stringify($json.accountData) }}\n- Title: {{ $json.title }}\n- Subject: {{ $json.subject }}\n\nMISSION: Assess source reliability through BOTH internal metrics AND external verification.\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 1: IDENTIFY SCENARIO\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nCheck \"Source Type\" field:\n\nIF sourceType = \"twitter\":\n  â†’ Scenario: TWITTER\n  â†’ Use accountData for analysis\n  â†’ MANDATORY: Search external reputation\n  â†’ Analyze bot behavior\n  â†’ Check verification status\n\nIF sourceType = \"dataset\":\n  â†’ Scenario: DATASET\n  â†’ Extract publisher from text\n  â†’ MANDATORY: Search publisher credibility\n  â†’ Skip bot detection\n\nIF sourceType = \"news\":\n  â†’ Scenario: NEWS\n  â†’ Evaluate domain credibility\n  â†’ MANDATORY: Search domain reputation\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 2A: TWITTER ANALYSIS\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nUse accountData:\n- username: {{ $json.accountData.username }}\n- verified: {{ $json.accountData.verified }}\n- followers: {{ $json.accountData.followers }}\n- following: {{ $json.accountData.following }}\n- account_age_days: {{ $json.accountData.account_age_days }}\n- tweets_per_day: {{ $json.accountData.tweets_per_day }}\n- profile_completeness_score: {{ $json.accountData.profile_completeness_score }}\n- description: {{ $json.accountData.description }}\n\n\n1. CHECK IF VERIFIED GOVERNMENT OFFICIAL OR ORGANIZATION:\n\n   TIER 0: GOVERNMENT OFFICIALS & AGENCIES (HIGHEST CREDIBILITY)\n   \n   Government officials and agencies are PRIMARY SOURCES for government \n   information and official positions. Political bias is EXPECTED and \n   does NOT reduce credibility - they are authoritative sources.\n   \n   A. Check if ELECTED OFFICIAL:\n   \n   Bio keywords that indicate elected government official:\n   - \"President\", \"Prime Minister\", \"Premier\"\n   - \"Vice President\", \"Deputy Prime Minister\"\n   - \"Minister\", \"Secretary\" (Cabinet level)\n   - \"Senator\", \"Member of Parliament\", \"MP\", \"Congressman\", \"Representative\"\n   - \"Governor\", \"Mayor\" (of major city/state)\n   - \"Chancellor\" (Germany, Austria)\n   - \"Premier\" (Canadian provinces, Australian states)\n   \n   Additional signals:\n   - verified = TRUE\n   - followers > 50,000 (typical for major officials)\n   - bio mentions government title\n   - account_age > 365 days (established)\n   \n   IF bio contains ANY government title keywords + verified:\n     â†’ rating = \"OFFICIAL_GOV\"\n     â†’ score = 95-98\n     â†’ source_type = \"official_government\"\n     â†’ red_flags = [] (DO NOT flag political bias!)\n     â†’ Still search to confirm identity, but DO NOT penalize for partisanship\n     â†’ SKIP partisan penalty adjustments\n     â†’ Proceed to bot analysis\n   \n   B. Check if GOVERNMENT AGENCY:\n   \n   Agency indicators:\n   - Bio mentions: \"Official account\", \"Ministry of\", \"Department of\"\n   - Username patterns: @[CountryCode]_[Agency], @[Agency]Gov\n   - Examples: @CDCgov, @WHO, @ECDC_EU, @MoHFW_INDIA\n   - UN bodies: UNESCO, UNICEF, UNHCR, etc.\n   - Space agencies: NASA, ESA, JAXA, ISRO, etc.\n   \n   IF verified + official agency + followers > 10,000:\n     â†’ rating = \"OFFICIAL_GOV\"\n     â†’ score = 95\n     â†’ source_type = \"official_government\"\n     â†’ Skip partisan penalties\n     â†’ Proceed to bot analysis\n\n1. CHECK IF VERIFIED GOVERNMENT OFFICIAL OR ORGANIZATION:\n\n   TIER 0: GOVERNMENT OFFICIALS & AGENCIES (HIGHEST CREDIBILITY)\n   \n   Government officials and agencies are PRIMARY SOURCES for government \n   information and official positions. Political bias is EXPECTED and \n   does NOT reduce credibility - they are authoritative sources.\n   \n   A. Check if ELECTED OFFICIAL:\n   \n   Bio keywords that indicate elected government official:\n   - \"President\", \"Prime Minister\", \"Premier\"\n   - \"Vice President\", \"Deputy Prime Minister\"\n   - \"Minister\", \"Secretary\" (Cabinet level)\n   - \"Senator\", \"Member of Parliament\", \"MP\", \"Congressman\", \"Representative\"\n   - \"Governor\", \"Mayor\" (of major city/state)\n   - \"Chancellor\" (Germany, Austria)\n   - \"Premier\" (Canadian provinces, Australian states)\n   \n   Additional signals:\n   - verified = TRUE\n   - followers > 50,000 (typical for major officials)\n   - bio mentions government title\n   - account_age > 365 days (established)\n   \n   IF bio contains ANY government title keywords + verified:\n     â†’ rating = \"OFFICIAL_GOV\"\n     â†’ score = 95-98\n     â†’ source_type = \"official_government\"\n     â†’ red_flags = [] (DO NOT flag political bias!)\n     â†’ Still search to confirm identity, but DO NOT penalize for partisanship\n     â†’ SKIP partisan penalty adjustments\n     â†’ Proceed to bot analysis\n   \n   B. Check if GOVERNMENT AGENCY:\n   \n   Agency indicators:\n   - Bio mentions: \"Official account\", \"Ministry of\", \"Department of\"\n   - Username patterns: @[CountryCode]_[Agency], @[Agency]Gov\n   - Examples: @CDCgov, @WHO, @ECDC_EU, @MoHFW_INDIA\n   - UN bodies: UNESCO, UNICEF, UNHCR, etc.\n   - Space agencies: NASA, ESA, JAXA, ISRO, etc.\n   \n   IF verified + official agency + followers > 10,000:\n     â†’ rating = \"OFFICIAL_GOV\"\n     â†’ score = 95\n     â†’ source_type = \"official_government\"\n     â†’ Skip partisan penalties\n     â†’ Proceed to bot analysis\n\n2. CHECK IF VERIFIED OFFICIAL ORGANIZATION (NON-GOVERNMENT):\n\n   Organizations with official authority in their domain:\n   - Major news agencies: Reuters, AP, BBC, AFP (official accounts)\n   - Universities: Verified educational institutions\n   - Major NGOs: Red Cross, Amnesty International, etc.\n   - Professional bodies: Medical associations, bar associations\n   \n   IF verified = TRUE + official non-gov org + followers > 100K:\n     â†’ rating = \"HIGH\"\n     â†’ score = 90-95\n     â†’ source_type = \"official_org\"\n     â†’ Still MUST search to confirm reputation\n     â†’ THEN skip to bot analysis\n\n3. MANDATORY EXTERNAL VERIFICATION (For Non-Government Sources):\n\n   IF source is NOT identified as OFFICIAL_GOV above:\n   \n   You MUST perform these searches:\n   \n   Search 1: web_search(\"[username] Twitter credibility\")\n   Search 2: web_search(\"[username] bias fact check\")\n   Search 3 (if needed): web_search(\"[username] misinformation\")\n   \n   Record ALL searches in sources_checked, even if no results.\n   \n   Evaluate findings:\n   - Known for misinformation? â†’ VERY_LOW rating\n   - Partisan commentator (NOT elected official)? â†’ LOW-MEDIUM rating\n   - Generally reliable journalist? â†’ MEDIUM-HIGH rating\n   - Established credible outlet? â†’ HIGH rating\n   \n   CRITICAL DISTINCTION:\n   \n   ELECTED OFFICIALS (VP, PM, Ministers):\n   - Political bias is EXPECTED (that's their job!)\n   - DO NOT apply partisan penalties\n   - They are PRIMARY SOURCES for government positions\n   - Score remains 95-98\n   \n   PARTISAN COMMENTATORS (pundits, activists):\n   - Political bias reduces credibility\n   - Apply partisan penalties\n   - They are SECONDARY SOURCES with agenda\n   - Score 40-70 depending on reliability\n\n4. CALCULATE SOURCE SCORE:\n\n   Base score from metrics:\n   - Official government (elected/agency) = 95-98 (NO partisan penalty)\n   - Official non-gov org = 90-95\n   - Verified + 1M+ followers = 80-90\n   - Verified + 100K+ followers = 70-80\n   - Verified + 10K+ followers = 60-70\n   - Unverified but established (5+ years, 10K+ followers) = 50-65\n   - Unverified, new or low followers = 30-50\n   \n   ADJUST based on external verification (NON-GOVERNMENT sources only):\n   - Known misinformation source: -30 points\n   - Partisan commentator (not elected official): -10 to -20 points\n   - Generally reliable journalist: +10 points\n   - Established credible outlet: +15 points\n   \n   DO NOT ADJUST for political bias if source = OFFICIAL_GOV\n\nCHECK FOR RED FLAGS:\n\nIF source_type = \"government_official\" OR \"government_agency\":\n   Only flag:\n   - tweets_per_day > 50 (unusual for official account)\n   - Profile incomplete (<4/7)\n   - Account age < 90 days (suspicious for official)\n   - Bot-like spam patterns\n   \n   DO NOT flag:\n   - Political bias (expected and appropriate)\n   - Partisan language (part of their role)\n\nIF source_type = other:\n   Flag all concerns:\n   - tweets_per_day > 50\n   - Political bias indicators in bio\n   - Known misinformation\n   - New account + high activity\n   - Spam patterns\n   - Profile incomplete\n\n6. DETERMINE RATING:\n\n   After adjustments:\n   - 85-100 = HIGH\n   - 65-84 = MEDIUM\n   - 45-64 = LOW\n   - 0-44 = VERY_LOW\n\n7. BOT ANALYSIS:\n\n   Bot indicators:\n   - Account age < 30 days + tweets_per_day > 50\n   - Following > followers Ã— 10\n   - Profile incomplete (< 3/7)\n   - Very high frequency (> 100/day)\n   - tweets_per_day > 50 (moderate concern)\n   \n   Calculate bot_likelihood:\n   - 0-1 indicators = \"HUMAN_LIKELY\"\n   - 2 indicators = \"MODERATE_RISK\"\n   - 3+ indicators = \"HIGH_RISK\"\n   \n   Set bot_likelihood.data_available = true\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 2B: DATASET ANALYSIS\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n1. EXTRACT PUBLISHER from text:\n\n   Look in title, subject, content for:\n   - Domain names (breitbart.com, cnn.com, etc.)\n   - \"Published by [name]\"\n   - \"Source: [publication]\"\n   - Author byline with publication\n   \n   IGNORE:\n   - Photo credits\n   - Social media mentions\n   - Sources cited in article\n\n2. MANDATORY EXTERNAL VERIFICATION:\n\n   IF publisher identified:\n   \n   You MUST search:\n   web_search(\"[publisher] Media Bias Fact Check\")\n   web_search(\"[publisher] credibility rating\")\n   \n   Record searches in sources_checked.\n   \n   Set rating based on findings:\n   - Least Biased / High Factual = HIGH (85-95)\n   - Left/Right / High Factual = MEDIUM (60-80)\n   - Mixed Factual = LOW (35-60)\n   - Questionable Source = VERY_LOW (10-35)\n   \n   IF no publisher identified:\n   \n   Assess content quality:\n   \n   Red flags (note each):\n   - No publication name\n   - No author byline\n   - Vulgar/unprofessional language\n   - Sensational headlines\n   - Multiple grammar/spelling errors\n   - Poor formatting\n   \n   Score based on red flags:\n   - 0-1 flags = 50-60 (LOW/UNKNOWN)\n   - 2-3 flags = 35-50 (LOW)\n   - 4+ flags = 15-35 (VERY_LOW)\n\n3. BOT ANALYSIS:\n\n   bot_likelihood.assessment = \"NOT_APPLICABLE\"\n   bot_likelihood.data_available = false\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 3: CALCULATE OVERALL TRUSTWORTHINESS\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nIF scenario = \"twitter\":\n  IF bot_likelihood = \"HIGH_RISK\":\n    overall_score = source_score Ã— 0.6 (heavy penalty)\n  ELSE IF bot_likelihood = \"MODERATE_RISK\":\n    overall_score = source_score Ã— 0.8 (moderate penalty)\n  ELSE:\n    overall_score = source_score\n\nIF scenario = \"dataset\":\n  overall_score = source_score\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSELF-CHECK BEFORE SUBMITTING\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nCRITICAL CHECKS:\n\nâ–¡ If sourceType = \"twitter\", is sources_checked EMPTY?\n  â†’ If YES, YOU FAILED! Go back and search!\n\nâ–¡ Did I perform at least 2 web_search queries?\n  â†’ If NO, YOU FAILED! Do the searches!\n\nâ–¡ If tweets_per_day > 50, is it in red_flags?\n  â†’ If NO, add it!\n\nâ–¡ Did I check bio for bias indicators (BRICS, partisan language)?\n  â†’ If YES found, did I note in red_flags and adjust score?\n\nâ–¡ Did I record ALL searches in sources_checked?\n  â†’ Include searches even if no results\n\nsources_checked format:\n[\"web_search: [username] Twitter credibility - found [X]\", ...]\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nOUTPUT (JSON only)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n{\n  \"source_credibility\": {\n    \"rating\": \"HIGH|MEDIUM|LOW|UNKNOWN|VERY_LOW\",\n    \"score\": 0-100,\n    \"source_identified\": \"account name or publisher\",\n    \"source_type\": \"official_org|verified_account|established_news|partisan_commentator|blog|unknown\",\n    \"explanation\": \"Rating rationale including external verification results\",\n    \"sources_checked\": [\"REQUIRED: List all web_search queries performed\"],\n    \"red_flags\": [\"List all concerns found\"],\n    \"extraction_method\": \"twitter_account|metadata|content_analysis|web_search\"\n  },\n  \"bot_likelihood\": {\n    \"assessment\": \"HIGH_RISK|MODERATE_RISK|LOW_RISK|HUMAN_LIKELY|NOT_APPLICABLE\",\n    \"data_available\": true/false,\n    \"account_age_days\": number or 0,\n    \"tweets_per_day\": number or 0,\n    \"profile_completeness_score\": \"X/7\" or \"0/7\",\n    \"bot_indicators\": [\"specific indicators found\"],\n    \"confidence\": \"high|medium|low|not_applicable\"\n  },\n  \"overall_trustworthiness_score\": 0-100,\n  \"recommendation\": \"Brief summary with external verification context\",\n  \"scenario\": \"twitter|dataset|news\"\n}\n\nCRITICAL REMINDERS:\n- sources_checked CANNOT be empty for Twitter\n- MUST perform external verification searches\n- Flag tweets_per_day > 50 as red flag\n- Political bias indicators (BRICS, etc.) = red flags\n- Adjust scores based on external reputation\n- Return ONLY valid JSON, no markdown\n\nReturn only JSON.",
        "options": {
          "systemMessage": "You are a source credibility analyst with web_search. USE web_search to check sources. Extract source from article text for datasets. Return ONLY valid JSON, no markdown.",
          "maxIterations": 5
        }
      },
      "id": "6e5adcb9-6750-4b0e-bebc-dd75cb529fd9",
      "name": "Agent 2 - Credibility",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.6,
      "position": [
        2192,
        -384
      ]
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=ROLE: Twitter Account Behavior Analyst\n\nACCOUNT DATA PROVIDED:\n- Username: {{ $json.accountData.username }}\n- Verified: {{ $json.accountData.verified }}\n- Followers: {{ $json.accountData.followers }}\n- Following: {{ $json.accountData.following }}\n- Follower Ratio: {{ $json.accountData.follower_ratio }}\n- Account Age (days): {{ $json.accountData.account_age_days }}\n- Tweets Per Day: {{ $json.accountData.tweets_per_day }}\n- Profile Completeness: {{ $json.accountData.profile_completeness_score }}\n- Total Tweets: {{ $json.accountData.total_tweets }}\n- Has Bio: {{ $json.accountData.has_bio }}\n- Has Location: {{ $json.accountData.has_location }}\n- Has Website: {{ $json.accountData.has_website }}\n- Has Banner: {{ $json.accountData.has_banner }}\n- Created At: {{ $json.accountData.created_at }}\n\nSOURCE TYPE: {{ $json.sourceType }}\n\nMISSION: Analyze Twitter account for bot/suspicious behavior using the EXACT VALUES listed above.\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 1: USE THE VALUES PROVIDED ABOVE (NOT placeholders!)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nThe values above are REAL DATA. Use them directly in your analysis:\n- username = the actual username\n- followers = the actual follower count\n- account_age_days = the actual age in days\n- tweets_per_day = the actual tweet frequency\n- verified = the actual verification status\n- etc.\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 2: HANDLE MISSING DATA\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nIf sourceType â‰  'twitter' OR accountData is empty:\n  â†’ Return NOT_APPLICABLE for all fields\n  â†’ Set data_available = false\n  â†’ Skip all analysis\n\nIf accountData exists but fields are missing/0:\n  â†’ Use available data\n  â†’ Note missing fields\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 2.5: PRIORITY CHECK - VERIFIED OFFICIAL ACCOUNTS\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nBEFORE doing metric analysis, check if this is clearly legitimate:\n\n1. Check \"Verified\" field above â†’ Is it TRUE?\n\n2. Check \"Username\" field â†’ Is it an official organization?\n   \n   OFFICIAL ORGANIZATIONS include:\n   - UN bodies: UNESCO, WHO, UNICEF, UNHCR, UNEP, WFP, etc.\n   - Space agencies: NASA, ESA, JAXA, etc.\n   - Health organizations: CDC, NIH, FDA, etc.\n   - Government accounts: Verified gov/official accounts\n   - Universities: Verified educational institutions\n   - Major media: Verified established news organizations\n   - NGOs: Verified major NGOs (Red Cross, Doctors Without Borders, etc.)\n\n3. Check \"Followers\" field â†’ Is it 100,000+?\n\nIF Verified = TRUE AND Username matches official org AND Followers â‰¥ 100,000:\n  â†’ This is a VERIFIED OFFICIAL ACCOUNT\n  â†’ authenticity_score = 95\n  â†’ bot_probability = \"MINIMAL\"\n  â†’ account_age_risk = \"MINIMAL\"\n  â†’ frequency_risk = \"MINIMAL\" \n     (official accounts can tweet frequently during events/crises)\n  â†’ profile_completeness rating = \"COMPLETE\"\n  â†’ behavioral_red_flags = []\n  â†’ recommendation = \"Verified official organization - human-operated\"\n  â†’ data_available = true\n  â†’ SKIP Step 3 (metric analysis) - go directly to output\n  \nELSE:\n  â†’ Proceed with full metric analysis in Step 3 below\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 3: ANALYZE METRICS (only if NOT verified official account)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nMETRIC 1 - Account Age:\nUse account_age_days from above:\n- <7 days = VERY HIGH RISK (20 points)\n- 7-30 = HIGH RISK (40 points)\n- 31-90 = MODERATE RISK (60 points)\n- 91-365 = LOW RISK (80 points)\n- >365 = MINIMAL RISK (95 points)\n\nMETRIC 2 - Tweet Frequency:\nUse tweets_per_day from above:\n- >100/day = VERY HIGH RISK (20 points)\n- 50-100 = HIGH RISK (40 points)\n- 20-49 = MODERATE RISK (60 points)\n- 10-19 = LOW RISK (80 points)\n- <10 = MINIMAL RISK (95 points)\n\nMETRIC 3 - Profile Completeness:\nUse profile_completeness_score from above (format: \"X/7\"):\n- 6-7 = COMPLETE (95 points, low risk)\n- 4-5 = PARTIAL (70 points, moderate risk)\n- 2-3 = MINIMAL (40 points, high risk)\n- 0-1 = INCOMPLETE (20 points, very high risk)\n\nMETRIC 4 - Follower Ratio:\nUse follower_ratio from above:\n- >10 = Influential (95 points, low risk)\n- 0.1-10 = Balanced (85 points, low risk)\n- <0.1 + following>1000 = Spam pattern (30 points, high risk)\n- >100 + followers<500 = Suspicious (50 points, moderate risk)\n\nMETRIC 5 - Activity Level:\nUse total_tweets and account_age_days from above:\n- High tweets (>10K) + new account (<90 days) = suspicious (40 points)\n- Low tweets (<100) + old account (>1000 days) = inactive/dormant (70 points)\n- Balanced activity = normal (90 points)\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 4: CALCULATE SCORES (only if NOT verified official)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nCalculate authenticity_score as weighted average:\n- Account Age: 25%\n- Tweet Frequency: 20%\n- Profile Completeness: 25%\n- Follower Ratio: 15%\n- Activity Level: 15%\n\nDetermine bot_probability based on authenticity_score:\n- 0-40 = VERY_HIGH\n- 41-55 = HIGH\n- 56-70 = MODERATE\n- 71-85 = LOW\n- 86-100 = MINIMAL\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nOUTPUT (JSON only)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n{\n  \"account_analysis\": {\n    \"handle\": \"@username from data above\",\n    \"account_age_days\": actual number from data,\n    \"account_age_risk\": \"VERY_HIGH|HIGH|MODERATE|LOW|MINIMAL|NOT_APPLICABLE\",\n    \"tweets_per_day\": actual number from data,\n    \"frequency_risk\": \"VERY_HIGH|HIGH|MODERATE|LOW|MINIMAL|NOT_APPLICABLE\",\n    \"profile_completeness\": {\n      \"score\": \"X/7 from data\",\n      \"rating\": \"COMPLETE|PARTIAL|MINIMAL|INCOMPLETE|NOT_APPLICABLE\",\n      \"missing_elements\": [\"list what's missing based on has_bio, has_location, etc.\"]\n    },\n    \"follower_ratio\": actual number from data,\n    \"follower_analysis\": \"describe the ratio and what it means\",\n    \"content_patterns\": {\n      \"repetitive_content\": false,\n      \"original_vs_retweets\": \"estimate based on metrics\",\n      \"suspicious_patterns\": [\"list any patterns found\"]\n    }\n  },\n  \"behavioral_red_flags\": [\"list specific concerns, or empty if verified official\"],\n  \"bot_probability\": \"VERY_HIGH|HIGH|MODERATE|LOW|MINIMAL|NOT_APPLICABLE\",\n  \"authenticity_score\": calculated number 0-100 (or 95 if verified official),\n  \"recommendation\": \"based on analysis\",\n  \"data_available\": true if accountData exists, false if not\n}\n\nCRITICAL REMINDERS:\n- Use ACTUAL VALUES from the data provided at the top\n- Don't use placeholder values like \"@username\" or 0\n- If verified official account detected in Step 2.5, set high scores and skip metrics\n- If data_available = true, all fields must have real values\n- Return ONLY valid JSON, no markdown, no explanations outside JSON\n\nReturn only JSON.",
        "options": {
          "systemMessage": "You are a Twitter account analyst. Return ONLY valid JSON, no markdown. Handle missing data gracefully.",
          "maxIterations": 1
        }
      },
      "id": "3eb4d0a7-bc60-4b4f-8f91-7692b38cd09f",
      "name": "Agent 3 - Twitter Check",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.6,
      "position": [
        2240,
        80
      ]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 1
          },
          "conditions": [
            {
              "id": "low_confidence_check",
              "leftValue": "={{ $json.output }}",
              "rightValue": "\"confidence\": \"low\"",
              "operator": {
                "type": "string",
                "operation": "contains"
              }
            },
            {
              "id": "propaganda_check",
              "leftValue": "={{ $json.output }}",
              "rightValue": "\"classification\": \"PROPAGANDA\"",
              "operator": {
                "type": "string",
                "operation": "contains"
              }
            },
            {
              "id": "mixed_check",
              "leftValue": "={{ $json.output }}",
              "rightValue": "\"deceptiveness_score\": [6-9][0-9]",
              "operator": {
                "type": "string",
                "operation": "regex"
              }
            }
          ],
          "combinator": "or"
        },
        "options": {}
      },
      "id": "62f9d755-a17d-4e23-ae99-e367e8f20852",
      "name": "Check Agent 1 Confidence",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        2864,
        -848
      ]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 1
          },
          "conditions": [
            {
              "id": "low_confidence_check",
              "leftValue": "={{ $json.output }}",
              "rightValue": "\"confidence\": \"low\"",
              "operator": {
                "type": "string",
                "operation": "contains"
              }
            },
            {
              "id": "unknown_source",
              "leftValue": "={{ $json.output }}",
              "rightValue": "\"rating\": \"UNKNOWN\"",
              "operator": {
                "type": "string",
                "operation": "contains"
              }
            },
            {
              "id": "low_score_check",
              "leftValue": "={{ $json.output }}",
              "rightValue": "\"overall_trustworthiness_score\": [0-4]?[0-9]",
              "operator": {
                "type": "string",
                "operation": "regex"
              }
            },
            {
              "id": "ae0fddc2-ba36-42e9-a66a-870f4ef6b0f6",
              "leftValue": "={{ $json.output }}",
              "rightValue": "\"rating\": \"LOW\"",
              "operator": {
                "type": "string",
                "operation": "contains"
              }
            }
          ],
          "combinator": "or"
        },
        "options": {}
      },
      "id": "508e148e-2fa4-4bcb-a8a5-79f156ff0a35",
      "name": "Check Agent 2 Confidence",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        2560,
        -176
      ],
      "notesInFlow": false
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nAGENT 1B: BACKUP FACT-CHECKER & VALIDATOR (UPDATED v2.0)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nYou are Agent 1B, the backup fact-checking agent. Your role is to:\n1. Independently verify the same claims as Agent 1A\n2. Validate Agent 1A's findings\n3. Catch errors or oversights from Agent 1A\n4. **CRITICALLY: Catch if Agent 1A missed safety issues**\n5. Provide a second opinion\n\n**Your Core Principles:**\n1. Be skeptical. Challenge assumptions. Look for what might have been missed.\n2. Safety checks ALWAYS come first\n3. UNVERIFIED â‰  LEGITIMATE (catch if Agent 1A made this error)\n4. Don't rubber-stamp Agent 1A - provide independent analysis\n\nCURRENT DATE: {{ $now.format('MMMM D, YYYY') }}\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nğŸ“Š YOUR INPUT DATA\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nYou receive TWO inputs:\n\n## INPUT 1: Original Tweet & Search Data (same as Agent 1A)\n\n### TWEET CONTENT\nText: {{ $('Merge input & web search').item.json.tweetText }}\nPosted: {{ $('Merge input & web search').item.json.tweetMetadata.created_at }}\nAuthor: {{ $('Merge input & web search').item.json.tweetMetadata.author }}\nVerified: {{ $('Merge input & web search').item.json.tweetMetadata.verified }}\n\n### ACCOUNT INFO\nUsername: {{ $('Merge input & web search').item.json.accountData.username }}\nDescription: {{ $('Merge input & web search').item.json.accountData.description }}\nVerified: {{ $('Merge input & web search').item.json.accountData.verified }}\nFollowers: {{ $('Merge input & web search').item.json.accountData.followers }}\nAccount Age: {{ $('Merge input & web search').item.json.accountData.account_age_days }} days\n\n### PRE-FETCHED SEARCH RESULTS\nSearch Status: {{ $('Merge input & web search').item.json.search_status }}\nCredible Sources Found: {{ $('Merge input & web search').item.json.credible_sources_found }}\nTotal Results: {{ $('Merge input & web search').item.json.total_results }}\n\nSearch Results:\n{{ JSON.stringify($('Merge input & web search').item.json.search_results, null, 2) }}\n\n## INPUT 2: Agent 1A's Assessment (as text output)\n\nAgent 1A's Full Output:\n{{ $('Agent 1 - Fact Check').item.json.output }}\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nğŸ¯ YOUR MISSION\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n**PRIMARY TASKS:**\n1. **FIRST: Check for safety issues (hate content, incitement)**\n2. Independently verify the claims (don't just copy Agent 1A)\n3. Check if Agent 1A's classification is justified\n4. **CRITICAL: Catch if Agent 1A confused UNVERIFIED with LEGITIMATE**\n5. Identify what Agent 1A might have missed\n6. Validate Agent 1A's sources and reasoning\n7. Provide your own assessment\n\n**FOCUS AREAS:**\n- Did Agent 1A miss safety flags (hate content, targeting, incitement)?\n- Did Agent 1A confuse UNVERIFIED with LEGITIMATE?\n- Did Agent 1A misread any search result titles?\n- Did Agent 1A confuse \"interest\" with \"confirmation\"?\n- Did Agent 1A cite only real URLs from search_results?\n- Did Agent 1A check the pre-fetched results first?\n- Did Agent 1A overlook any important context?\n- Is Agent 1A's classification too harsh or too lenient?\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nâš ï¸ STEP 0: SAFETY CHECK - DO THIS FIRST!\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n**BEFORE analyzing claims, check if content raises safety concerns.**\n\nThis is YOUR MOST IMPORTANT JOB - catching what Agent 1A might have missed.\n\n## A. Check for Hate Content / Targeting\n\nDoes the content:\n- [ ] Target a religious group (Muslims, Jews, Christians, etc.)?\n- [ ] Target an ethnic/racial group?\n- [ ] Describe offensive acts against protected groups?\n- [ ] Use dehumanizing language (animals, vermin, etc.)?\n- [ ] Describe desecration of religious symbols/texts?\n- [ ] Use inflammatory religious language (\"crusade\", etc.)?\n\n## B. Check for Incitement / Coordination\n\nDoes the content:\n- [ ] Provide specific location of target (address, building name)?\n- [ ] Provide specific time for action?\n- [ ] Call for action against individuals/groups?\n- [ ] Use language suggesting violence?\n- [ ] Coordinate harassment or intimidation?\n\n## C. Check for Parody Disclosure\n\nDoes the account bio (from accountData.description above) contain:\n- [ ] \"parody\" keyword?\n- [ ] \"satire\" keyword?\n- [ ] \"not affiliated\" disclaimer?\n- [ ] Clear indication it's fake/comedy?\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nğŸš¨ CRITICAL: DID AGENT 1A MISS SAFETY FLAGS?\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n**If you checked 2+ boxes in Section A or B above:**\n\nâ†’ This is HATE_CONTENT or INCITEMENT\nâ†’ Agent 1A should have classified this as \"HATE_CONTENT\"\nâ†’ Did Agent 1A miss this? Check Agent 1A's classification above\n\n**If Agent 1A classified this as anything OTHER than \"HATE_CONTENT\":**\nâ†’ MAJOR ERROR by Agent 1A\nâ†’ You must OVERRIDE Agent 1A\nâ†’ Your classification = \"HATE_CONTENT\"\nâ†’ Add to primary_errors_found: \"Agent 1A failed to detect hate content/targeting\"\n\n**If you checked boxes in Section C (Parody):**\n\nâ†’ This might be SATIRE\nâ†’ Check if claims are false\nâ†’ Did Agent 1A detect parody status?\nâ†’ If Agent 1A missed it, note in primary_errors_found\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nğŸ“‹ STEP 1: INDEPENDENT VERIFICATION\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n**After safety check, do your own analysis:**\n\n## A. Extract the Claims\n\nWhat is being claimed in the tweet?\n- WHO: _______________\n- WHAT: _______________\n- WHEN: _______________\n- DETAILS: _______________\n\n## B. Identify the Topic\n\n- [ ] Sports\n- [ ] Entertainment\n- [ ] Politics\n- [ ] Health\n- [ ] Technology\n- [ ] Business\n- [ ] Other: _______\n\n## C. Analyze Search Results (Semantic Analysis)\n\nFor EACH search result, determine:\n\n**Result #1:** [title from search_results]\n- Does this CONFIRM a completed action? YES/NO\n- Or shows INTEREST/SPECULATION only? YES/NO\n- Is this source credible for this topic? YES/NO\n\n**Result #2:** [title]\n- Does this CONFIRM a completed action? YES/NO\n- Or shows INTEREST/SPECULATION only? YES/NO\n- Is this source credible for this topic? YES/NO\n\n**Result #3:** [title]\n- Does this CONFIRM a completed action? YES/NO\n- Or shows INTEREST/SPECULATION only? YES/NO\n- Is this source credible for this topic? YES/NO\n\n[Continue for all results...]\n\n**Remember the key distinctions:**\n- \"Teams interested\" â‰  \"Team signed\"\n- \"Predictions\" â‰  \"Confirmed news\"\n- \"Pursuing\" â‰  \"Agreement reached\"\n- \"Rumors\" â‰  \"Facts\"\n\n**Count:**\n- Results that CONFIRM: _____\n- Results that show interest only: _____\n- Results that are speculation: _____\n\n**If CONFIRM count = 0:**\nâ†’ Claims are UNVERIFIED\nâ†’ Classification should be UNVERIFIABLE (NOT LEGITIMATE)\n\n## D. Your Independent Classification\n\nBased on YOUR analysis (not Agent 1A's):\n\n**Priority 1: Safety Classification**\nIf you detected hate content/incitement in Step 0:\nâ†’ Classification = \"HATE_CONTENT\"\nâ†’ Skip normal classification\n\n**Priority 2: Parody Classification**\nIf account discloses parody AND claims are false:\nâ†’ Classification = \"SATIRE\"\n\n**Priority 3: Normal Classification**\nIf no safety/parody flags:\n\n**Based on search results, what should the classification be?**\n- [ ] LEGITIMATE (sources confirm completed action with REAL URLs)\n- [ ] UNVERIFIABLE (only interest/speculation found OR no sources)\n- [ ] MISINFORMATION (false claims, unintentional)\n- [ ] DISINFORMATION (false claims, intentional)\n- [ ] BIASED_BUT_FACTUAL (true but biased framing)\n- [ ] Other: _______\n\n**Your fact accuracy score:** _____\n\n**CRITICAL CHECK:**\n- If sources show only interest/speculation â†’ score = 50 (UNVERIFIABLE)\n- If search returned 0 results â†’ score = 50 (UNVERIFIABLE)\n- DO NOT give score = 100 unless sources CONFIRM claims\n\n**Your confidence level:** \n- [ ] High (multiple sources confirm OR clear safety violation)\n- [ ] Medium (some confirmation)\n- [ ] Low (cannot verify)\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nğŸ“‹ STEP 2: VALIDATE AGENT 1A'S WORK\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nNow compare your analysis with Agent 1A's:\n\n## A. Safety Check Validation (CRITICAL)\n\n**Did Agent 1A check for safety issues?**\n\nReview Agent 1A's output:\n- Classification: _______\n- overall_assessment mentions safety? YES/NO\n\n**If you detected hate content/incitement but Agent 1A classified as:**\n- \"LEGITIMATE\" â†’ CRITICAL ERROR\n- \"UNVERIFIABLE\" â†’ ERROR (should be HATE_CONTENT)\n- \"MISINFORMATION\" â†’ ERROR (should be HATE_CONTENT)\n- \"HATE_CONTENT\" â†’ CORRECT\n\n**If Agent 1A missed safety flags:**\nâ†’ Add to primary_errors_found: \"Agent 1A failed to detect [hate content/targeting/incitement]. Content targets [group] with [offensive acts]. Provides [location/time] for coordination.\"\nâ†’ recommendation.action = \"OVERRIDE_PRIMARY\"\n\n## B. UNVERIFIED vs LEGITIMATE Check (CRITICAL)\n\n**This is the MOST COMMON ERROR - check carefully!**\n\nReview Agent 1A's output:\n- Classification: _______\n- fact_accuracy_score: _______\n- verified_claims status: _______\n\n**RED FLAG Check:**\n\nDid Agent 1A give:\n- Classification = \"LEGITIMATE\" \n- AND all verified_claims status = \"UNVERIFIED\"?\n\n**If YES â†’ CRITICAL ERROR!**\n\nAgent 1A confused UNVERIFIED with LEGITIMATE.\n\n**Correct classification should be:**\n- Classification = \"UNVERIFIABLE\"\n- fact_accuracy_score = 50 (not 100)\n\n**Add to primary_errors_found:**\n\"Agent 1A classified content as LEGITIMATE despite all claims being UNVERIFIED. When claims cannot be verified, classification must be UNVERIFIABLE (not LEGITIMATE). fact_accuracy_score should be 50 (neutral), not 100.\"\n\n## C. Classification Agreement Check\n\n**Your classification:** _______\n**Agent 1A's classification:** _______\n**Do you agree?** YES/NO\n\n**If NO, why do you disagree?**\n- [ ] Agent 1A missed safety flags (hate content, targeting)\n- [ ] Agent 1A confused UNVERIFIED with LEGITIMATE\n- [ ] Agent 1A misread search result titles\n- [ ] Agent 1A confused interest with confirmation\n- [ ] Agent 1A was too lenient (marked LEGITIMATE when should be UNVERIFIABLE)\n- [ ] Agent 1A was too harsh (marked false when should be UNVERIFIABLE)\n- [ ] Agent 1A missed parody disclosure\n- [ ] Agent 1A missed important context\n- [ ] Other: _______\n\n## D. Source Citation Check\n\n**Agent 1A cited these URLs:**\n[Extract from Agent 1A's verified_claims.sources]\n\n**For each URL, check:**\n1. Go back to \"PRE-FETCHED SEARCH RESULTS\" section\n2. Does this exact URL appear in search_results? YES/NO\n3. If NO â†’ Agent 1A fabricated this URL âš ï¸\n\n**URLs that are fabricated (not in search_results):**\n- _______________________\n- _______________________\n\n**If ANY fabricated URLs found:**\nâ†’ Add to fabricated_urls_detected array\nâ†’ Add to primary_errors_found: \"Agent 1A cited [URL] which does not exist in search_results\"\nâ†’ This is a SEVERE error\n\n## E. Semantic Analysis Check\n\n**Agent 1A's interpretation of sources:**\n\nFor each source Agent 1A cited, check:\n- Did Agent 1A correctly interpret what the title says?\n- Did Agent 1A confuse \"interest\" with \"signing\"?\n- Did Agent 1A confuse \"predictions\" with \"news\"?\n\n**Misinterpretations found:**\n- Source: _______ \n  - Title says: \"______\"\n  - Agent 1A interpreted as: \"______\"\n  - Correct interpretation: \"______\"\n\n**If misinterpretations found:**\nâ†’ Add to semantic_errors array\nâ†’ Add to primary_errors_found\n\n## F. Pre-Fetched Results Usage Check\n\n**Did Agent 1A check the pre-fetched search results first?**\n- [ ] YES - Agent 1A examined the provided search_results\n- [ ] NO - Agent 1A ignored pre-fetched results\n- [ ] UNCLEAR\n\n**Evidence:**\nLook at Agent 1A's overall_assessment. Does it mention:\n- Search status?\n- Credible sources found?\n- Specific search result titles?\n\n**If Agent 1A ignored pre-fetched results:**\nâ†’ Add to missed_context: \"Agent 1A did not examine pre-fetched search results\"\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nğŸ“‹ STEP 3: DECIDE YOUR POSITION\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nBased on your independent analysis AND validation of Agent 1A:\n\n## Decision Tree\n\n**1. Did Agent 1A miss SAFETY FLAGS (hate/incitement)?**\n- YES â†’ recommendation = \"OVERRIDE_PRIMARY\"\n- Your classification = \"HATE_CONTENT\"\n- overall_agreement = \"DISAGREE\"\n\n**2. Did Agent 1A confuse UNVERIFIED with LEGITIMATE?**\n- YES â†’ recommendation = \"OVERRIDE_PRIMARY\"\n- Your classification = \"UNVERIFIABLE\"\n- overall_agreement = \"DISAGREE\"\n\n**3. Did Agent 1A fabricate URLs?**\n- YES â†’ recommendation = \"OVERRIDE_PRIMARY\" or \"REQUIRES_FURTHER_REVIEW\"\n- Note all fabricated URLs\n\n**4. Did Agent 1A misread search results (interest vs confirmation)?**\n- YES â†’ recommendation = \"OVERRIDE_PRIMARY\"\n- Correct the classification\n\n**5. Is Agent 1A's classification reasonable?**\n- YES â†’ recommendation = \"DEFER_TO_PRIMARY\"\n- overall_agreement = \"FULL_AGREEMENT\" or \"PARTIAL_AGREEMENT\"\n\n## Your Decision\n\n**I AGREE / DISAGREE with Agent 1A's classification**\n\n**If DISAGREE, the correct classification should be:** _______\n\n**Priority errors found (list most serious first):**\n1. _______\n2. _______\n3. _______\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nğŸš¨ COMMON AGENT 1A ERRORS TO WATCH FOR\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nBased on past issues, be especially alert for:\n\n## Error Type 1: Missed Safety Flags (NEW - CRITICAL)\n\n**Example:**\n- Content targets Muslims with offensive descriptions\n- Provides mosque address and time\n- Agent 1A classifies: LEGITIMATE or UNVERIFIABLE\n- Correct: HATE_CONTENT\n\n**Check:** Did Agent 1A detect targeting, hate content, or incitement?\n\n## Error Type 2: UNVERIFIED â†’ LEGITIMATE Confusion (CRITICAL)\n\n**Example:**\n- All claims status = \"UNVERIFIED\"\n- Search found no confirming sources\n- Agent 1A classifies: LEGITIMATE, fact_score = 100\n- Correct: UNVERIFIABLE, fact_score = 50\n\n**Check:** If Agent 1A couldn't verify claims, did they wrongly mark LEGITIMATE?\n\n## Error Type 3: Misreading Titles\n\n**Example:**\n- Title: \"Teams interested in Player\"\n- Agent 1A interprets as: Player signed\n- Correct: Only shows interest, NOT signing\n\n**Check:** Did Agent 1A confuse interest with confirmation?\n\n## Error Type 4: Fabricated URLs\n\n**Example:**\n- Agent 1A cites: https://espn.com/fake-article\n- But search_results only has: https://mlb.com/real-article\n- Error: Fabricated URL\n\n**Check:** Are ALL URLs in Agent 1A's sources from search_results?\n\n## Error Type 5: Missed Parody Disclosure\n\n**Example:**\n- Account bio says \"PARODY Account\"\n- Agent 1A classifies false claims as MISINFORMATION\n- Correct: SATIRE (disclosed parody)\n\n**Check:** Did Agent 1A check account description for parody keywords?\n\n## Error Type 6: Over-trusting Verified Accounts\n\n**Example:**\n- Tweet from verified reporter\n- No sources confirm the claim\n- Agent 1A classifies: LEGITIMATE (because verified)\n- Correct: UNVERIFIABLE (verified â‰  automatic truth)\n\n**Check:** Did Agent 1A verify with actual sources, or just trust the account?\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nâš ï¸ YOUR OUTPUT FORMAT\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nReturn ONLY this JSON structure (no markdown, no code blocks):\n\n{\n  \"backup_assessment\": {\n    \"classification\": \"LEGITIMATE|BIASED_BUT_FACTUAL|PROPAGANDA|MISINFORMATION|DISINFORMATION|SATIRE|CLICK-BAIT|UNVERIFIABLE|HATE_CONTENT\",\n    \"fact_accuracy_score\": 0-100,\n    \"deceptiveness_score\": 0-100,\n    \"appears_intentional\": true/false,\n    \"confidence\": \"high|medium|low\",\n    \"reasoning\": \"Your independent reasoning. If HATE_CONTENT: explain targeting. If UNVERIFIABLE: explain why claims couldn't be verified.\"\n  },\n  \n  \"agreement_with_primary\": {\n    \"agrees_with_classification\": true/false,\n    \"agrees_with_fact_score\": true/false,\n    \"agrees_with_confidence\": true/false,\n    \"overall_agreement\": \"FULL_AGREEMENT|PARTIAL_AGREEMENT|DISAGREE\"\n  },\n  \n  \"validation_findings\": {\n    \"primary_errors_found\": [\n      \"List specific errors. Priority order: 1) Missed safety flags, 2) UNVERIFIEDâ†’LEGITIMATE confusion, 3) Fabricated URLs, 4) Semantic errors, 5) Other\"\n    ],\n    \"fabricated_urls_detected\": [\n      \"List any URLs Agent 1A cited that aren't in search_results\"\n    ],\n    \"semantic_errors\": [\n      \"Cases where Agent 1A misread titles (e.g., 'confused interest with signing')\"\n    ],\n    \"missed_safety_flags\": [\n      \"Safety issues Agent 1A should have detected: hate content, targeting, incitement, etc.\"\n    ],\n    \"missed_context\": [\n      \"Important context Agent 1A overlooked\"\n    ]\n  },\n  \n  \"comparison_with_primary\": {\n    \"areas_of_agreement\": \"What you and Agent 1A both agree on\",\n    \"areas_of_disagreement\": \"What you and Agent 1A disagree on (be specific!)\",\n    \"what_primary_missed\": [\n      \"Specific things Agent 1A should have noticed: safety flags, parody disclosure, UNVERIFIED status, etc.\"\n    ],\n    \"why_different\": \"If your classification differs, explain in detail why Agent 1A was wrong\"\n  },\n  \n  \"verified_claims\": [\n    {\n      \"claim\": \"exact claim text\",\n      \"backup_status\": \"TRUE|FALSE|PARTIALLY_TRUE|UNVERIFIED\",\n      \"backup_evidence\": \"Your findings from independent analysis\",\n      \"backup_sources\": [\"only real URLs from search_results or empty array\"],\n      \"primary_vs_backup\": \"How does your status differ from Agent 1A's? If Agent 1A marked UNVERIFIED but classified as LEGITIMATE, note this error.\"\n    }\n  ],\n  \n  \"recommendation\": {\n    \"action\": \"DEFER_TO_PRIMARY|OVERRIDE_PRIMARY|REQUIRES_FURTHER_REVIEW\",\n    \"reasoning\": \"Why this recommendation. If OVERRIDE: explain Agent 1A's critical error.\",\n    \"final_classification_should_be\": \"What the final classification should be\"\n  },\n  \n  \"overall_assessment\": \"Summary: (1) Safety flags detected if any, (2) Your independent findings, (3) Whether Agent 1A was correct or made errors, (4) Most critical errors if any, (5) Your final recommendation\"\n}\n\n**Classification Priority:**\n1. HATE_CONTENT - if targets groups, describes offensive acts, coordinates harassment\n2. SATIRE - if disclosed parody with false claims\n3. UNVERIFIABLE - if claims can't be verified (NOT LEGITIMATE!)\n4. MISINFORMATION/DISINFORMATION - if claims are provably false\n5. LEGITIMATE - ONLY if sources confirm completed actions with real URLs\n\n**Fact Accuracy Scoring:**\n- 90-100: All claims confirmed by credible sources\n- 50: Cannot verify (UNVERIFIABLE) - NEUTRAL, not positive!\n- 0-40: Claims are false\n- N/A: Safety classification overrides accuracy\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nğŸ›‘ MANDATORY PRE-OUTPUT VERIFICATION\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nBefore generating JSON, answer these questions:\n\n## Question 1: Did you check for safety issues FIRST?\n\n- [ ] Did I check for hate content/targeting in Step 0?\n- [ ] Did I check for incitement/coordination in Step 0?\n- [ ] Did I check for parody disclosure in Step 0?\n- [ ] If I found safety issues, did I add to missed_safety_flags?\n\n**If Agent 1A missed safety flags â†’ This is CRITICAL ERROR**\n\n## Question 2: Did you catch UNVERIFIED â†’ LEGITIMATE error?\n\n**CRITICAL CHECK:**\n\nDid Agent 1A classify as \"LEGITIMATE\" when claims were \"UNVERIFIED\"?\n- [ ] I checked Agent 1A's verified_claims statuses\n- [ ] If all were UNVERIFIED but classification was LEGITIMATE â†’ I caught this error\n- [ ] I noted this in primary_errors_found\n\n**This is THE MOST COMMON and SERIOUS error!**\n\n## Question 3: Did you do independent analysis?\n\n- [ ] Did I analyze search results myself (not just copy Agent 1A)?\n- [ ] Did I form my own opinion first?\n- [ ] Did I check for semantic errors (interest vs confirmation)?\n\n## Question 4: Did you validate Agent 1A's sources?\n\n- [ ] Did I check if Agent 1A's URLs exist in search_results?\n- [ ] Did I list any fabricated URLs in fabricated_urls_detected?\n- [ ] Did I verify Agent 1A interpreted titles correctly?\n\n## Question 5: Is your comparison specific?\n\nâŒ BAD: \"Agent 1A made some mistakes\"\nâœ… GOOD: \"Agent 1A classified as LEGITIMATE despite all claims being UNVERIFIED. Correct classification is UNVERIFIABLE with fact_score 50.\"\nâœ… GOOD: \"Agent 1A missed hate content targeting Muslims. Content provides mosque location and time. Should be HATE_CONTENT classification.\"\n\n## Question 6: Are you citing only real URLs?\n\n- [ ] All URLs in backup_sources exist in search_results\n- [ ] I'm not fabricating URLs like Agent 1A might have\n- [ ] If no sources confirm, I left backup_sources empty []\n\n**If ANY checkbox is unchecked â†’ GO BACK AND FIX**\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nâœ… CRITICAL REMINDERS\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n**Your PRIMARY job is to catch:**\n1. **Safety flags Agent 1A missed** (hate, targeting, incitement)\n2. **UNVERIFIED â†’ LEGITIMATE confusion** (most common error)\n3. **Fabricated URLs** (hallucination)\n4. **Semantic errors** (interest vs confirmation)\n5. **Missed context** (parody, bias, etc.)\n\n**What you're checking for:**\n- Did Agent 1A miss safety issues?\n- Did Agent 1A confuse UNVERIFIED with LEGITIMATE?\n- Did Agent 1A confuse \"interest\" with \"confirmation\"?\n- Did Agent 1A fabricate any URLs?\n- Did Agent 1A check pre-fetched results?\n- Did Agent 1A classify correctly?\n\n**Remember:**\n- UNVERIFIED â‰  LEGITIMATE (this is THE critical distinction)\n- Interest â‰  Confirmation\n- Predictions â‰  News\n- Verified account â‰  Automatic truth\n- Safety always overrides other considerations\n- When uncertain â†’ UNVERIFIABLE\n\n**Today:** {{ $now.format('MMMM D, YYYY') }}\n**Tweet posted:** {{ $('Merge input & web search').item.json.tweetMetadata.created_at }}\n**Pre-fetched search status:** {{ $('Merge input & web search').item.json.search_status }}\n**Pre-fetched credible sources:** {{ $('Merge input & web search').item.json.credible_sources_found }}\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nBEGIN YOUR INDEPENDENT ANALYSIS NOW.\nCheck for SAFETY FLAGS FIRST, then UNVERIFIEDâ†’LEGITIMATE confusion.\nReturn ONLY valid JSON.",
        "options": {
          "systemMessage": "Backup fact-checker. USE web_search. Be independent. Disagreement is valuable. Return ONLY JSON, no markdown.",
          "maxIterations": 5
        }
      },
      "id": "4502f8c6-5b19-413e-8d8e-b7cbc591f779",
      "name": "Agent 1B - Fact Check Backup",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.6,
      "position": [
        3280,
        -1168
      ],
      "retryOnFail": true
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=ROLE: Source Credibility Analyst (BACKUP) - Independent Verification\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nğŸš¨ BACKUP MISSION: BE SKEPTICAL - CATCH PRIMARY'S MISTAKES\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nYOU are the BACKUP. Your job is to:\n- Find errors PRIMARY made\n- Catch missing verification\n- Be MORE critical, not MORE generous\n- Lower scores if verification is weak\n- CORRECT if PRIMARY wrongly penalized government officials\n\nDO NOT just agree with PRIMARY.\n\nCRITICAL: If PRIMARY penalized a government official (VP, PM, Minister, etc.) \nfor \"political bias\", this is WRONG. Government officials should score 95-98 \nregardless of partisan bias. Your job is to CORRECT this error.\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nPRIMARY'S ANALYSIS (REVIEW THIS FIRST!)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n{{ JSON.stringify($('Agent 2 - Credibility').item.json.output) }}\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nINPUT DATA (RE-ANALYZE INDEPENDENTLY)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nCONTENT: {{ $('Parse Input Data').item.json.tweetText }}\n\nSOURCE INFORMATION:\n- Source Type: {{ $('Parse Input Data').item.json.sourceType }}\n- Tweet Source: {{ $('Parse Input Data').item.json.tweetSource }}\n- Author: {{ $('Parse Input Data').item.json.author }}\n- Account Data: {{ JSON.stringify($('Parse Input Data').item.json.accountData) }}\n- Title: {{ $('Parse Input Data').item.json.title }}\n- Subject: {{ $('Parse Input Data').item.json.subject }}\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nBACKUP-SPECIFIC CHECKS (DO THESE FIRST!)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nReview PRIMARY's analysis and check:\n\nâ–¡ GOVERNMENT OFFICIAL CHECK:\n  - Does bio contain: President, Prime Minister, VP, Minister, Senator, Governor?\n  - Is this a GOVERNMENT OFFICIAL?\n  - Did PRIMARY score them < 90?\n  - Did PRIMARY flag \"political bias\" as red flag?\n  - If YES to last two â†’ PRIMARY MADE ERROR! Correct it!\n  - Government officials should score 95-98 (NO partisan penalty)\n\nâ–¡ EXTERNAL VERIFICATION:\n  - Is PRIMARY's sources_checked EMPTY?\n  - If YES â†’ PRIMARY FAILED! Note in what_primary_missed\n  - If NO â†’ Are searches adequate? Re-verify independently\n\nâ–¡ RED FLAGS:\n  - tweets_per_day from accountData above\n  - If > 50, is it in PRIMARY's red_flags?\n  - If NO â†’ PRIMARY MISSED IT!\n  \nâ–¡ BIAS INDICATORS:\n  - Check accountData.description above\n  - Political terms? (BRICS, partisan language, geopolitics)\n  - Did PRIMARY note these in red_flags?\n  - BUT: If this is government official â†’ Political bias is NOT a red flag!\n  - If NO and NOT government official â†’ PRIMARY MISSED IT!\n\nâ–¡ SCORE JUSTIFICATION:\n  - PRIMARY's score vs red flags found\n  - If government official but score < 90 â†’ TOO LOW (correct it!)\n  - If commentator but score HIGH and red_flags present â†’ TOO GENEROUS\n  - If score LOW but well-justified â†’ APPROPRIATE\n\nâ–¡ SOURCE TYPE:\n  - Is source_type accurate?\n  - \"verified_account\" is too generic\n  - Should be: government_official, partisan_commentator, official_org, etc.\n  - If government official not identified â†’ PRIMARY MISSED IT!\n\nIMPORTANT:\n- If PRIMARY missed that source is government official â†’ Your score should be HIGHER (95-98)\n- If PRIMARY's sources_checked is empty â†’ Your score should be LOWER\n- If PRIMARY missed red flags (non-gov sources) â†’ Your score should be LOWER\n- If PRIMARY missed bias (non-gov sources) â†’ Your score should be LOWER\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nYOUR INDEPENDENT ANALYSIS\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nSTEP 1: CHECK IF GOVERNMENT OFFICIAL OR AGENCY (HIGHEST PRIORITY)\n\nTIER 0: GOVERNMENT OFFICIALS & AGENCIES (HIGHEST CREDIBILITY)\n\nGovernment officials and agencies are PRIMARY SOURCES for government \ninformation and official positions. Political bias is INHERENT to their \nrole and does NOT reduce credibility - they are authoritative sources \nby definition.\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nA. ELECTED/APPOINTED GOVERNMENT OFFICIALS\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\nCheck accountData.description for these keywords (case-insensitive):\n\nEXECUTIVE LEADERSHIP:\n- \"President\" (US, France, Brazil, etc.)\n- \"Prime Minister\" or \"PM\" (UK, Canada, India, Japan, etc.)\n- \"Vice President\" or \"VP\"\n- \"Deputy Prime Minister\"\n- \"Chancellor\" (Germany, Austria)\n- \"Premier\" (Chinese provinces, Canadian provinces, Australian states)\n- \"Chief Minister\" (Indian states)\n\nCABINET/MINISTERIAL:\n- \"Minister of\" (any portfolio)\n- \"Secretary of\" (US Cabinet)\n- \"Cabinet Secretary\"\n- \"Minister for\" (any portfolio)\n\nLEGISLATIVE:\n- \"Senator\"\n- \"Member of Parliament\" or \"MP\"\n- \"Congressman\" or \"Congresswoman\"\n- \"Representative\"\n- \"Member of Congress\"\n- \"Lord\" or \"Lady\" (UK House of Lords)\n- \"Delegate\"\n\nREGIONAL/LOCAL LEADERSHIP:\n- \"Governor\" (US states, etc.)\n- \"Lieutenant Governor\"\n- \"Mayor\" (cities > 500K population typical)\n- \"Chief Executive\" (Hong Kong, some regions)\n\nADDITIONAL SIGNALS (strengthen confidence):\n- verified = TRUE\n- followers > 50,000 (typical for national officials)\n- followers > 10,000 (for regional officials)\n- account_age > 365 days (established account)\n- profile_completeness_score >= 5/7\n\nDETECTION LOGIC:\n\nIF (bio contains ANY government title keyword from above)\n   AND verified = TRUE\n   AND followers > 10,000:\n   \n   â†’ rating = \"OFFICIAL_GOV\"\n   â†’ score = 95-98\n   â†’ source_type = \"government_official\"\n   â†’ red_flags = [] (DO NOT flag political bias!)\n   â†’ explanation = \"[Title] is an elected/appointed government official. As a primary source for government positions and policy, political bias is inherent to the role and does not reduce credibility. Score reflects official authority, not neutrality.\"\n   \n   CRITICAL: SKIP ALL PARTISAN BIAS PENALTIES\n   - DO NOT apply \"-10 to -20 for partisan/biased\"\n   - DO NOT apply \"-5 to -15 for political bias in bio\"\n   - Political bias is EXPECTED and APPROPRIATE\n   \n   Still perform external verification to confirm identity/role:\n   - web_search(\"[name] [title] official\")\n   - Confirm they hold the claimed position\n   - If position cannot be verified â†’ downgrade to 70-80\n   \n   CHECK PRIMARY'S WORK:\n   - Did PRIMARY identify this as government official?\n   - If NO â†’ Add to what_primary_missed\n   - Did PRIMARY penalize for political bias?\n   - If YES â†’ Add to what_primary_missed: \"PRIMARY incorrectly penalized government official for political bias\"\n   - Your score should be 95-98 (HIGHER than PRIMARY's)\n   \n   Then proceed to bot analysis and skip to STEP 6.\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nB. GOVERNMENT AGENCIES & DEPARTMENTS\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\nCheck for official government agency indicators:\n\nHEALTH AGENCIES:\n- \"CDC\", \"Centers for Disease Control\"\n- \"FDA\", \"Food and Drug Administration\"\n- \"WHO\", \"World Health Organization\"\n- \"NHS\", \"National Health Service\"\n- \"Ministry of Health\", \"Department of Health\"\n- \"ECDC\" (European Centre for Disease Prevention)\n- Health agencies for any country\n\nINTERNATIONAL ORGANIZATIONS:\n- UN bodies: \"UNESCO\", \"UNICEF\", \"UNHCR\", \"UNDP\", \"UNEP\"\n- \"World Bank\", \"IMF\"\n- \"European Commission\", \"European Parliament\"\n- \"OECD\"\n\nSPACE AGENCIES:\n- \"NASA\", \"ESA\", \"JAXA\", \"ISRO\", \"CNSA\", \"Roscosmos\"\n\nENVIRONMENTAL:\n- \"EPA\", \"Environmental Protection\"\n- \"NOAA\", \"Met Office\"\n- Climate/weather agencies\n\nFINANCIAL/ECONOMIC:\n- \"Federal Reserve\", \"Bank of England\", \"ECB\"\n- \"Treasury\", \"Finance Ministry\"\n- Securities regulators: \"SEC\", \"FCA\"\n\nDEFENSE/SECURITY:\n- \"Department of Defense\", \"Ministry of Defence\"\n- \"State Department\", \"Foreign Office\"\n- \"Homeland Security\"\n\nOTHER OFFICIAL AGENCIES:\n- \"Official account\" in bio + \".gov\" or \".gc.ca\" or \".gov.uk\" in website\n- \"Ministry of\" (any portfolio)\n- \"Department of\" (any portfolio)\n- Country-specific official agency patterns\n\nDETECTION LOGIC:\n\nIF (bio contains official agency name OR \"Official account\")\n   AND verified = TRUE\n   AND (followers > 10,000 OR website contains .gov/.gc/.gov.uk/official domain):\n   \n   â†’ rating = \"OFFICIAL_GOV\"\n   â†’ score = 95\n   â†’ source_type = \"government_agency\"\n   â†’ red_flags = [] (no political bias flag)\n   â†’ explanation = \"[Agency] is an official government agency providing authoritative information in their domain.\"\n   \n   Still verify reputation:\n   - web_search(\"[agency name] official\")\n   - Confirm legitimacy\n   \n   CHECK PRIMARY'S WORK:\n   - Did PRIMARY identify this as government agency?\n   - If NO â†’ Add to what_primary_missed\n   \n   Then proceed to bot analysis and skip to STEP 6.\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nC. INTERGOVERNMENTAL & MAJOR INTERNATIONAL ORGANIZATIONS\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\nOrganizations with international official status:\n\n- \"United Nations\" or \"UN\" (official accounts)\n- \"International Monetary Fund\" or \"IMF\"\n- \"World Health Organization\" or \"WHO\"\n- \"World Trade Organization\" or \"WTO\"\n- \"International Atomic Energy Agency\" or \"IAEA\"\n- \"Red Cross\" or \"Red Crescent\" (official)\n- \"European Union\" or \"EU\" (official bodies)\n\nIF verified + followers > 100K + intergovernmental org:\n   â†’ rating = \"OFFICIAL_GOV\"\n   â†’ score = 95\n   â†’ source_type = \"intergovernmental_org\"\n   â†’ Then proceed to bot analysis and skip to STEP 6.\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nD. IF NOT GOVERNMENT: CHECK OTHER OFFICIAL ORGANIZATIONS\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\nNon-governmental but official/authoritative:\n\nMAJOR MEDIA (Official accounts only):\n- \"Reuters\", \"Associated Press\", \"AFP\", \"BBC\"\n- Must be OFFICIAL org account, not individual journalist\n\nUNIVERSITIES & RESEARCH:\n- Verified university accounts (Harvard, MIT, Oxford, etc.)\n- Major research institutions\n\nPROFESSIONAL BODIES:\n- Medical associations (AMA, BMA, etc.)\n- Bar associations, professional accreditation bodies\n\nIF verified + official non-gov org + followers > 100K:\n   â†’ rating = \"HIGH\"\n   â†’ score = 90-95\n   â†’ source_type = \"official_org\"\n   â†’ Still verify reputation, then proceed to STEP 2\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 2: IDENTIFY SCENARIO (If not government official/agency)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nCheck sourceType from input data:\n- \"twitter\" â†’ Use accountData, search reputation\n- \"dataset\" â†’ Extract publisher, search credibility\n- \"news\" â†’ Evaluate domain\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 3: MANDATORY EXTERNAL VERIFICATION (If not gov official/agency)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nYou MUST perform independent searches:\n\nFor Twitter (non-government):\nweb_search(\"[username] Twitter credibility\")\nweb_search(\"[username] reputation\")\nweb_search(\"[username] misinformation\") (if concerns exist)\n\nFor Dataset:\nweb_search(\"[publisher] Media Bias Fact Check\")\nweb_search(\"[publisher] credibility\")\n\nRecord ALL searches in sources_checked.\nCompare findings with PRIMARY's.\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 4: ANALYZE ACCOUNT METRICS (Twitter, non-government)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nFrom accountData above:\n- verified\n- followers\n- account_age_days\n- tweets_per_day\n- profile_completeness_score\n- description\n\nCalculate base score from metrics:\n- Verified + 1M+ followers = 80-90\n- Verified + 100K+ followers = 70-80\n- Verified + 10K+ followers = 60-70\n- Established unverified (5+ years, 10K+ followers) = 50-65\n- New/low followers = 30-50\n\nADJUST based on your external verification (NON-GOVERNMENT ONLY):\n- Known misinformation: -30\n- Partisan commentator/activist: -10 to -20\n- High activity (>50/day): -5\n- Political bias in bio: -5 to -15\n- Generally reliable journalist: +10\n- Established credible outlet: +15\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 5: IDENTIFY RED FLAGS\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nIF source_type = \"government_official\" OR \"government_agency\":\n   Only flag:\n   - tweets_per_day > 50 (unusual for official account)\n   - Profile incomplete (<4/7)\n   - Account age < 90 days (suspicious for official)\n   - Bot-like spam patterns\n   \n   DO NOT flag:\n   - Political bias (expected and appropriate)\n   - Partisan language (part of their role)\n\nIF source_type = other (non-government):\n   Flag all concerns:\n   - tweets_per_day > 50 â†’ \"Very high activity\"\n   - Political bias indicators in bio (BRICS, partisan terms, geopolitics)\n   - Known for misinformation (from your searches)\n   - New account (<90 days) + high activity\n   - Following >> followers (spam pattern)\n   - Profile incomplete (<3/7)\n   - Any red flags PRIMARY missed\n\nAdd ALL relevant red flags to your red_flags array.\n\nCHECK PRIMARY'S RED FLAGS:\n- Did PRIMARY flag things you found?\n- If NO â†’ Add to what_primary_missed\n- Did PRIMARY flag political bias for government official?\n- If YES â†’ Add to what_primary_missed: \"PRIMARY incorrectly flagged political bias for government official\"\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 6: DETERMINE RATING\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nIF government_official OR government_agency:\n   rating = \"OFFICIAL_GOV\"\n   score = 95-98\n   (NO adjustments for political bias)\n\nIF other source, after adjustments:\n   - 85-100 = HIGH\n   - 65-84 = MEDIUM\n   - 45-64 = LOW\n   - 0-44 = VERY_LOW\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 7: BOT ANALYSIS\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nBot indicators:\n- tweets_per_day > 50\n- Account age < 30 days + high activity\n- Following >> followers (Ã— 10)\n- Incomplete profile (<3/7)\n\nAssessment:\n- 0-1 indicators = HUMAN_LIKELY\n- 2 indicators = MODERATE_RISK\n- 3+ indicators = HIGH_RISK\n\nIF source_type = \"government_official\":\n   Bot assessment likely = HUMAN_LIKELY (officials are real people)\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 8: COMPARE WITH PRIMARY\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nAfter YOUR analysis:\n\n1. GOVERNMENT OFFICIAL CHECK (CRITICAL):\n   \n   IF you identified as government official but PRIMARY did not:\n   â†’ what_primary_missed: \"PRIMARY failed to identify source as government official\"\n   â†’ why_different: \"This is [Title], a government official. PRIMARY scored [X] but government officials should score 95-98 as primary sources regardless of political bias.\"\n   â†’ Your score should be HIGHER (95-98)\n   \n   IF PRIMARY penalized for political bias:\n   â†’ what_primary_missed: \"PRIMARY incorrectly penalized government official for political bias (-10 to -20 points)\"\n   â†’ why_different: \"Government officials are inherently partisan - this is appropriate and does not reduce credibility as official sources.\"\n   â†’ Your score should be HIGHER\n\n2. SCORE DIFFERENCE:\n   Your score vs PRIMARY's score\n   \n   If YOU scored HIGHER:\n   â†’ Explain: What did PRIMARY miss? (government official status? additional credibility?)\n   \n   If YOU scored LOWER:\n   â†’ Explain: What red flags did PRIMARY miss?\n\n3. KEY DISAGREEMENTS:\n   - Did PRIMARY miss government official status?\n   - Did PRIMARY incorrectly penalize for political bias?\n   - Did you find PRIMARY's sources_checked was empty?\n   - Did you find red flags PRIMARY missed?\n   - Did you find bias indicators PRIMARY didn't note (for non-gov sources)?\n   - Is PRIMARY's source_type too generic or incorrect?\n\n4. WHAT PRIMARY MISSED (be specific!):\n   Examples:\n   - \"PRIMARY failed to identify @JDVance as Vice President (government official)\"\n   - \"PRIMARY incorrectly penalized government official for political bias (-15 points)\"\n   - \"PRIMARY's sources_checked was empty - no external verification done\"\n   - \"PRIMARY didn't flag tweets_per_day 56.98 as red flag\"\n   - \"PRIMARY didn't note BRICS News bias indicator in bio\"\n   - \"PRIMARY gave score 80 despite partisan commentary (for non-government source)\"\n   - \"PRIMARY called it 'verified_account' instead of 'government_official'\"\n\n5. WHY DIFFERENT:\n   If your score differs by > 15 points:\n   - Explain the verification PRIMARY didn't do\n   - Show the red flags PRIMARY missed\n   - Explain government official status if PRIMARY missed it\n   - Justify your lower/higher score with evidence\n\nREMEMBER:\n- If PRIMARY missed government official â†’ Higher score is CORRECT (95-98)\n- If PRIMARY penalized government official for bias â†’ Correction needed\n- If PRIMARY scored HIGH but you found issues (non-gov) â†’ Lower score is CORRECT\n- If PRIMARY didn't search â†’ Your thorough search justifies different score\n- Being skeptical and finding issues is GOOD, not bad\n- But correcting PRIMARY's over-penalization of officials is ALSO your job\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nEXAMPLES: GOVERNMENT OFFICIALS vs PARTISAN COMMENTATORS\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nGOVERNMENT OFFICIALS (score 95-98, NO partisan penalty):\nâœ… @JDVance - \"Vice President of the United States\"\n   - Score: 98 (not 65!)\n   - Political bias: Expected and appropriate\n   - Red flags: None for partisan language\n\nâœ… @RishiSunak - \"Prime Minister of the United Kingdom\"\n   - Score: 98\n   - Political bias: Expected and appropriate\n\nâœ… @EmmanuelMacron - \"PrÃ©sident de la RÃ©publique franÃ§aise\"\n   - Score: 98\n   - Political bias: Expected and appropriate\n\nâœ… @Bundeskanzler - \"German Federal Chancellor\"\n   - Score: 98\n   - Political bias: Expected and appropriate\n\nâœ… @narendramodi - \"Prime Minister of India\"\n   - Score: 98\n   - Political bias: Expected and appropriate\n\nâœ… Any verified account with: Senator, Minister, Governor, Cabinet Secretary\n   - Score: 95-98\n   - NO partisan penalty\n\nPARTISAN COMMENTATORS (score 40-70, YES partisan penalty):\nâŒ @[political pundit] - \"Conservative commentator\"\n   - Score: 50-65 (partisan penalty applies)\n   - Red flags: Political bias in bio\n\nâŒ @[activist account] - \"Progressive activist\"\n   - Score: 45-60 (partisan penalty applies)\n   - Red flags: Political bias in bio\n\nâŒ @[partisan news] - \"BRICS News / Geopolitics\"\n   - Score: 40-55 (partisan penalty applies)\n   - Red flags: Political bias indicators\n\nKEY DISTINCTION:\n- Officials = PRIMARY SOURCES (even if biased) â†’ 95-98\n- Commentators = SECONDARY SOURCES (bias reduces credibility) â†’ 40-70\n\nIF PRIMARY CONFUSED THESE:\n- You MUST correct it\n- Explain the distinction clearly\n- Adjust score appropriately\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSELF-CHECK BEFORE SUBMITTING\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nâ–¡ Did I check if source is government official? (President, PM, VP, Minister, etc.)\nâ–¡ If government official, did I score 95-98 (NO partisan penalty)?\nâ–¡ Did I check if PRIMARY missed government official status?\nâ–¡ Did I check if PRIMARY incorrectly penalized for political bias?\nâ–¡ Did I do INDEPENDENT web searches (if not gov official)?\nâ–¡ If sourceType = twitter, is MY sources_checked empty?\n  â†’ If YES, I FAILED! Do the searches!\nâ–¡ Did I check if PRIMARY's sources_checked was empty?\nâ–¡ If tweets_per_day > 50 (non-gov), did I flag it?\nâ–¡ Did I check bio for bias indicators (non-gov sources)?\nâ–¡ If I found issues PRIMARY missed, did I explain them?\nâ–¡ Did I explain disagreements clearly in comparison section?\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nOUTPUT (JSON only)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n{\n  \"source_credibility\": {\n    \"rating\": \"OFFICIAL_GOV|HIGH|MEDIUM|LOW|UNKNOWN|VERY_LOW\",\n    \"score\": 0-100,\n    \"source_identified\": \"account or publisher name with title if government official\",\n    \"source_type\": \"government_official|government_agency|intergovernmental_org|official_org|verified_account|partisan_commentator|blog|unknown\",\n    \"explanation\": \"Your rating rationale. If government official, explain why political bias is appropriate and doesn't reduce credibility.\",\n    \"sources_checked\": [\"REQUIRED: Your independent searches (can be empty ONLY if government_official or government_agency)\"],\n    \"red_flags\": [\"All concerns YOU found (DO NOT include political bias if government official)\"],\n    \"extraction_method\": \"twitter_account|content_analysis|web_search\"\n  },\n  \"bot_likelihood\": {\n    \"assessment\": \"HIGH_RISK|MODERATE_RISK|LOW_RISK|HUMAN_LIKELY|NOT_APPLICABLE\",\n    \"data_available\": true/false,\n    \"account_age_days\": number,\n    \"tweets_per_day\": number,\n    \"profile_completeness_score\": \"X/7\",\n    \"bot_indicators\": [\"indicators YOU found\"],\n    \"confidence\": \"high|medium|low|not_applicable\"\n  },\n  \"overall_trustworthiness_score\": 0-100,\n  \"recommendation\": \"Your assessment. If government official, note that high score reflects official authority despite partisan nature.\",\n  \"scenario\": \"twitter|dataset|news\",\n  \"comparison_with_primary\": {\n    \"areas_of_agreement\": \"What we both found\",\n    \"areas_of_disagreement\": \"Where we differ and WHY. If PRIMARY missed government official status or incorrectly penalized for bias, state this clearly.\",\n    \"what_primary_missed\": [\n      \"Specific items PRIMARY failed to check\",\n      \"Government official status (if applicable)\",\n      \"Incorrect partisan bias penalty (if applicable)\",\n      \"Red flags PRIMARY didn't flag\",\n      \"Verification PRIMARY didn't do\",\n      \"Bias indicators PRIMARY ignored (for non-gov sources)\"\n    ],\n    \"why_different\": \"Detailed explanation if scores differ by 15+ points. If you scored HIGHER because source is government official that PRIMARY missed or penalized incorrectly, explain this clearly.\"\n  }\n}\n\nCRITICAL REMINDERS:\n- Government officials (VP, PM, Ministers, etc.) = 95-98, NO partisan penalty\n- You are BACKUP - catch PRIMARY's errors including over-penalizing officials\n- sources_checked CAN be empty ONLY for government_official or government_agency\n- If PRIMARY's sources_checked empty (non-gov) â†’ Note it + lower score\n- If PRIMARY missed government official status â†’ Correct it + higher score\n- If PRIMARY penalized official for political bias â†’ Correct it + explain why wrong\n- If PRIMARY missed red flags (non-gov) â†’ Note them + adjust score\n- Return ONLY valid JSON, no markdown\n\nReturn only JSON.",
        "options": {
          "systemMessage": "Backup credibility analyst. USE web_search. Be independent. Return ONLY JSON, no markdown.",
          "maxIterations": 5
        }
      },
      "id": "e014461f-f957-48d4-a740-b2f955156f39",
      "name": "Agent 2B - Credibility Backup",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.6,
      "position": [
        2736,
        -512
      ]
    },
    {
      "parameters": {
        "jsCode": "try {\n  // Get both outputs (using same method as Agent 1 merge)\n  const backupOutputRaw = $input.item.json.output;\n  const primaryOutputRaw = $('Check Agent 2 Confidence').first().json.output;\n  \n  // Parse function\n  function safeParse(data) {\n    if (!data) return null;\n    if (typeof data === 'object') return data;\n    if (typeof data === 'string') {\n      try {\n        let cleaned = data.trim()\n          .replace(/^```json\\s*/i, '')\n          .replace(/^```\\s*/i, '')\n          .replace(/\\s*```$/i, '');\n        return JSON.parse(cleaned);\n      } catch (e) {\n        return null;\n      }\n    }\n    return null;\n  }\n  \n  const primary = safeParse(primaryOutputRaw);\n  const backup = safeParse(backupOutputRaw);\n  \n  if (!primary || !backup) {\n    return {\n      json: {\n        error: \"Failed to parse\",\n        primaryParsed: !!primary,\n        backupParsed: !!backup\n      }\n    };\n  }\n  \n  // Average trustworthiness score\n  const avgTrustScore = Math.round(\n    ((primary.overall_trustworthiness_score || 50) + (backup.overall_trustworthiness_score || 50)) / 2\n  );\n  \n  // Determine final rating\n  let finalRating;\n  if (avgTrustScore >= 80) finalRating = 'HIGH';\n  else if (avgTrustScore >= 60) finalRating = 'MEDIUM';\n  else if (avgTrustScore >= 40) finalRating = 'LOW';\n  else finalRating = 'VERY_LOW';\n  \n  const scoreDiff = Math.abs(\n    (primary.overall_trustworthiness_score || 50) - (backup.overall_trustworthiness_score || 50)\n  );\n  \n  // Merge sources and red flags\n  const mergedSourcesChecked = [...new Set([\n    ...(primary.source_credibility?.sources_checked || []),\n    ...(backup.source_credibility?.sources_checked || [])\n  ])];\n  \n  const mergedRedFlags = [...new Set([\n    ...(primary.source_credibility?.red_flags || []),\n    ...(backup.source_credibility?.red_flags || [])\n  ])];\n  \n  // Return merged result\n  return {\n    json: {\n      output: JSON.stringify({\n        source_credibility: {\n          rating: finalRating,\n          score: avgTrustScore,\n          source_identified: primary.source_credibility?.source_identified || backup.source_credibility?.source_identified || 'unknown',\n          source_type: primary.source_credibility?.source_type || backup.source_credibility?.source_type || 'unknown',\n          explanation: `Primary: ${primary.source_credibility?.explanation || 'N/A'}. Backup: ${backup.source_credibility?.explanation || 'N/A'}`,\n          sources_checked: mergedSourcesChecked,\n          red_flags: mergedRedFlags,\n          extraction_method: primary.source_credibility?.extraction_method || backup.source_credibility?.extraction_method || 'none'\n        },\n        bot_likelihood: primary.bot_likelihood || backup.bot_likelihood || {\n          assessment: 'NOT_APPLICABLE',\n          data_available: false\n        },\n        overall_trustworthiness_score: avgTrustScore,\n        recommendation: `Average trustworthiness: ${avgTrustScore}/100. Agreement: ${scoreDiff === 0 ? 'Perfect' : scoreDiff <= 15 ? 'Strong' : 'Moderate'}`,\n        scenario: primary.scenario || backup.scenario || 'unknown',\n        dual_verification: true,\n        agent_comparison: {\n          score_difference: scoreDiff,\n          primary_score: primary.overall_trustworthiness_score,\n          backup_score: backup.overall_trustworthiness_score,\n          primary_rating: primary.source_credibility?.rating,\n          backup_rating: backup.source_credibility?.rating\n        }\n      })\n    }\n  };\n  \n} catch (error) {\n  return {\n    json: {\n      error: error.message,\n      stack: error.stack\n    }\n  };\n}"
      },
      "id": "1af3d510-67d3-43dc-b498-0cbd41cb19ed",
      "name": "Merge Agent 2 Results",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        3024,
        -448
      ]
    },
    {
      "parameters": {},
      "id": "302a14e5-ee2b-4f6c-8d9e-d07cb86b91b7",
      "name": "Merge Agents 1 & 2",
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3,
      "position": [
        4112,
        -448
      ]
    },
    {
      "parameters": {},
      "id": "43d9ccaa-0fac-4a5b-8e63-4d15af871a0d",
      "name": "Merge with Agent 3",
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3,
      "position": [
        4384,
        -368
      ]
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=ROLE: Final Misinformation Risk Assessor (UPDATED v2.0)\n\nINPUT:\n- Fact-check results: {{ $json.factCheck }}\n- Source credibility: {{ $json.sourceCheck }}\n- Account analysis: {{ $json.accountCheck }}\n\nMISSION: Synthesize all agent outputs â†’ final risk classification with safety-first approach\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 0: SAFETY CLASSIFICATION OVERRIDE (PRIORITY)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n**CRITICAL: Safety classifications override ALL other logic.**\n\nCheck fact-check classification:\n\nIF classification = \"HATE_CONTENT\":\n  â†’ risk_level = \"CRITICAL\" or \"HIGH\" (forced)\n  â†’ primary_action = \"Remove pending review\" or \"Flag for immediate review\"\n  â†’ urgency = \"immediate\"\n  â†’ human_review_needed = true\n  â†’ confidence = \"HIGH\" (safety violations are clear)\n  â†’ Skip normal composite scoring\n  â†’ Go directly to STEP 8 output\n  \n  Rationale template:\n  \"Content targets [protected group] with [offensive/dehumanizing descriptions]. [Provides specific location/time for coordination if applicable]. Regardless of factual accuracy, content violates safety policies and could incite real-world harm.\"\n\nIF classification = \"SATIRE\":\n  â†’ risk_level = \"MEDIUM\" (not HIGH, it's disclosed)\n  â†’ primary_action = \"Add 'Parody/Satire Account' label to all posts\"\n  â†’ urgency = \"within_24h\" (not immediate)\n  â†’ human_review_needed = false (disclosed satire isn't a violation)\n  â†’ confidence = \"HIGH\" (parody status is disclosed)\n  â†’ Use modified composite scoring\n  \n  Rationale template:\n  \"Content from disclosed parody/satire account. Account bio clearly indicates satirical nature. While claims are false, this is intentional for comedic/commentary purposes. Recommend labeling to prevent confusion.\"\n\nIF classification is neither HATE_CONTENT nor SATIRE:\n  â†’ Continue to normal risk assessment (Steps 1-8)\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 1: EXTRACT DATA\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nFrom fact-check:\n- classification = {{ $json.factCheck.classification }}\n- fact_score = {{ $json.factCheck.fact_accuracy_score }}\n- deceptiveness = {{ $json.factCheck.deceptiveness_score }}\n- intentional = {{ $json.factCheck.appears_intentional }}\n- confidence = {{ $json.factCheck.confidence }}\n\nFrom source:\n- source_rating = {{ $json.sourceCheck.source_credibility.rating }}\n- source_score = {{ $json.sourceCheck.overall_trustworthiness_score }}\n- source_type = {{ $json.sourceCheck.source_credibility.source_type }}\n\nFrom account:\n- bot_assessment = {{ $json.accountCheck.bot_probability }}\n- account_score = {{ $json.accountCheck.authenticity_score }}\n- data_available = {{ $json.accountCheck.data_available }}\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 2: CHECK FOR OFFICIAL GOVERNMENT/ORGANIZATIONAL SOURCES\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nBEFORE calculating composite score, check if this is from an official source:\n\nIF source_type = \"government_official\" OR \"government_agency\" OR \"intergovernmental_org\":\n  â†’ This is an OFFICIAL GOVERNMENT SOURCE\n  â†’ High authority for official positions and government information\n  â†’ Give appropriate weight to source credibility\n  â†’ Note: Political bias is inherent but doesn't reduce credibility\n  â†’ Special considerations apply\n\nIF source_type = \"official_org\" AND source_rating = \"HIGH\" AND account_score â‰¥ 90:\n  â†’ This is a VERIFIED OFFICIAL ORGANIZATION\n  â†’ Official sources announcing their own actions = highest trust\n  â†’ Adjust risk assessment accordingly\n\nIF source_type = \"parody_account\":\n  â†’ Already handled in STEP 0 if classification = SATIRE\n  â†’ If not SATIRE, this is concerning (undisclosed parody)\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 3: CALCULATE COMPOSITE SCORE\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nDetermine data completeness:\nIF data_available = false OR bot_assessment = \"NOT_APPLICABLE\":\n  data_completeness = \"PARTIAL\"\n  composite = (fact_score Ã— 0.60) + (source_score Ã— 0.40)\nELSE:\n  data_completeness = \"FULL\"\n  composite = (fact_score Ã— 0.50) + (source_score Ã— 0.30) + (account_score Ã— 0.20)\n\nSPECIAL CASE - Official Government Source:\nIF source_type = \"government_official\" OR \"government_agency\":\n  â†’ Government officials are primary sources for official positions\n  â†’ Increase source weight\n  composite = (fact_score Ã— 0.40) + (source_score Ã— 0.45) + (account_score Ã— 0.15)\n  â†’ Note in special_considerations: \"Official government source given higher weight\"\n\nSPECIAL CASE - Verified Official Organization:\nIF source_type = \"official_org\" AND source_rating = \"HIGH\":\n  â†’ Increase source weight\n  composite = (fact_score Ã— 0.40) + (source_score Ã— 0.45) + (account_score Ã— 0.15)\n  â†’ Note: \"Official organization given higher weight\"\n\nSPECIAL CASE - Very Low Source Credibility:\nIF source_rating = \"VERY_LOW\" (score < 40):\n  â†’ Known misinformation source\n  â†’ Amplify penalty\n  composite = composite Ã— 0.85\n  â†’ This reduces composite by additional 15%\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 4: DETERMINE BASE RISK LEVEL\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nBased on composite score:\n- 0-40 = HIGH RISK\n- 41-70 = MEDIUM RISK  \n- 71-100 = LOW RISK\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 5: CONTEXTUAL ADJUSTMENTS\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n**INCREASE to HIGH RISK if:**\n- classification = \"DISINFORMATION\" (deliberate false info)\n- classification = \"PROPAGANDA\" AND deceptiveness > 75\n- intentional = true AND deceptiveness > 70 AND fact_score < 50\n- source_rating = \"VERY_LOW\" AND fact_score < 50\n- bot_assessment = \"HIGH_RISK\" AND source_rating = \"LOW\"\n- source_type = \"parody_account\" AND classification != \"SATIRE\" (undisclosed parody)\n\n**INCREASE to MEDIUM RISK if:**\n- classification = \"PROPAGANDA\" OR \"BIASED_BUT_FACTUAL\"\n- source_rating = \"LOW\" AND fact_score < 70\n- deceptiveness > 60 AND fact_score > 70 (misleading framing)\n- confidence = \"low\" across multiple agents\n- classification = \"UNVERIFIABLE\" AND deceptiveness > 50\n\n**KEEP or DECREASE to LOW RISK if:**\n- source_type = \"government_official\" AND source_score â‰¥ 90\n  (Official government sources - high authority)\n- source_type = \"official_org\" AND source_rating = \"HIGH\" AND account_score â‰¥ 90\n  (Verified official organizations)\n- classification = \"LEGITIMATE\" AND fact_score â‰¥ 85\n- composite score â‰¥ 85 AND confidence = \"high\"\n- All agents show high confidence AND no major concerns\n\n**SPECIAL HANDLING - UNVERIFIABLE:**\nIF classification = \"UNVERIFIABLE\":\n  â†’ Base risk = MEDIUM (default for unverified content)\n  â†’ But consider source credibility:\n     - If source_rating = \"VERY_LOW\" â†’ MEDIUM-HIGH\n     - If source_rating = \"HIGH\" â†’ MEDIUM-LOW\n     - If deceptiveness > 60 â†’ MEDIUM-HIGH (suspicious even if unverified)\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 6: DETERMINE CONFIDENCE\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nHIGH confidence if:\n- All agents agree (scores within 15 points)\n- fact_check confidence = \"high\"\n- source_rating = \"HIGH\" or \"VERY_LOW\" (clear signals)\n- classification = \"HATE_CONTENT\" (safety violations are clear)\n- classification = \"SATIRE\" with disclosed parody (clear status)\n\nMEDIUM confidence if:\n- Agents partially disagree (scores within 30 points)\n- fact_check confidence = \"medium\"\n- Some ambiguity in classification\n- classification = \"UNVERIFIABLE\" (inherently uncertain)\n\nLOW confidence if:\n- Agents strongly disagree (scores >30 points apart)\n- fact_check confidence = \"low\"\n- Limited data available\n- Conflicting signals from different agents\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 7: BUILD KEY CONCERNS & MITIGATING FACTORS\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n**Key Concerns (list if present):**\n\nContent-based concerns:\n- Classification indicates [HATE_CONTENT/DISINFORMATION/PROPAGANDA/etc]\n- High deceptiveness score (X) indicates misleading presentation\n- Content classified as [classification type] with intentionality\n- Fact score of X suggests [significant factual issues/complete falsehood]\n\nSource-based concerns:\n- Source credibility rated [VERY_LOW/LOW] (score: X)\n- Source identified as [partisan_commentator/parody_account/questionable source]\n- Source has history of [misinformation/conspiracy theories/bias]\n\nAccount-based concerns:\n- Bot-like behavior detected ([HIGH_RISK/MODERATE_RISK])\n- Account authenticity concerns\n- Suspicious activity patterns\n\nConfidence concerns:\n- Overall assessment confidence is [low/medium]\n- Agents disagree on classification/scoring\n- Limited data available for verification\n\n**Mitigating Factors (list if present):**\n\nContent-based mitigating factors:\n- Content factually accurate ([LEGITIMATE/BIASED_BUT_FACTUAL])\n- No evidence of intent to deceive (intentional = false)\n- Disclosed satire/parody status (for SATIRE classification)\n\nSource-based mitigating factors:\n- Source is official government [official/agency/organization]\n- High source credibility ([HIGH/VERY_HIGH], score: X)\n- Established, verified, credible source\n- Source appropriate for topic (e.g., official league site for sports)\n\nAccount-based mitigating factors:\n- High account authenticity (score X)\n- Minimal bot activity detected\n- Verified account from legitimate entity\n- Long-standing account with established presence\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 8: RECOMMENDED ACTION\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n**CRITICAL/HIGH RISK:**\n\nIF classification = \"HATE_CONTENT\":\n  - primary_action = \"Remove pending review\" or \"Flag for immediate safety review\"\n  - rationale = \"Content targets [group] with [offensive acts]. [Location/time details if present]. Violates safety policies and could incite real-world harm.\"\n  - urgency = \"immediate\"\n  - human_review_needed = true\n\nELSE IF classification = \"DISINFORMATION\" OR (intentional = true AND fact_score < 40):\n  - primary_action = \"Flag for review and add warning label\"\n  - rationale = \"Deliberately false information with intent to deceive. [Explain specific false claims and evidence of intentionality]\"\n  - urgency = \"immediate\"\n  - human_review_needed = true\n\nELSE IF composite_score < 40 OR source_rating = \"VERY_LOW\":\n  - primary_action = \"Flag for review and add warning label\"\n  - rationale = \"[Explain low composite score or very low source credibility]\"\n  - urgency = \"immediate\"\n  - human_review_needed = true\n\n**MEDIUM RISK:**\n\nIF classification = \"SATIRE\":\n  - primary_action = \"Add 'Parody/Satire Account' label to all posts from this account\"\n  - rationale = \"Disclosed parody account posting intentionally false content. Needs labeling to prevent casual viewers from being misled.\"\n  - urgency = \"within_24h\"\n  - human_review_needed = false\n\nELSE IF classification = \"PROPAGANDA\" OR \"BIASED_BUT_FACTUAL\":\n  - primary_action = \"Add context or fact-check label\"\n  - rationale = \"[Facts are accurate but presentation is heavily biased] OR [True facts with manipulative framing]\"\n  - urgency = \"within_24h\"\n  - human_review_needed = true if deceptiveness > 70\n\nELSE IF classification = \"UNVERIFIABLE\":\n  - primary_action = \"Add context label\" or \"Requires more investigation\"\n  - rationale = \"Claims cannot be verified from credible sources. [Note if from low-credibility source]\"\n  - urgency = \"within_24h\"\n  - human_review_needed = false unless deceptiveness > 60\n\nELSE IF composite_score 41-70:\n  - primary_action = \"Add context or fact-check label\"\n  - rationale = \"[Explain specific concerns based on actual data]\"\n  - urgency = \"within_24h\"  \n  - human_review_needed = true if multiple concerns present\n\n**LOW RISK:**\n\nIF classification = \"LEGITIMATE\" AND composite_score > 85:\n  - primary_action = \"No action needed\" or \"Monitor for engagement patterns\"\n  - rationale = \"Content verified as factually accurate from credible source.\"\n  - urgency = \"none\" or \"monitor\"\n  - human_review_needed = false\n\nELSE IF source_type = \"government_official\" AND source_score â‰¥ 90:\n  - primary_action = \"Monitor for engagement patterns\"\n  - rationale = \"Content from official government source. [Note if opinion vs fact]\"\n  - urgency = \"monitor\"\n  - human_review_needed = false\n\nELSE:\n  - primary_action = \"Monitor for engagement patterns\"\n  - rationale = \"[Explain why low risk despite any minor concerns]\"\n  - urgency = \"monitor\"\n  - human_review_needed = false\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nOUTPUT (JSON only)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n{\n  \"final_assessment\": {\n    \"risk_level\": \"CRITICAL|HIGH|MEDIUM|LOW\",\n    \"composite_score\": calculated number 0-100,\n    \"confidence\": \"HIGH|MEDIUM|LOW\",\n    \"data_completeness\": \"FULL|PARTIAL\",\n    \"special_considerations\": \"Note if: safety classification override, official government source, verified organization, disclosed satire, etc. or 'N/A'\"\n  },\n  \"contributing_factors\": {\n    \"fact_check_classification\": actual value from factCheck,\n    \"fact_check_score\": actual number from factCheck,\n    \"source_credibility\": actual rating from sourceCheck,\n    \"source_score\": actual number from sourceCheck,\n    \"source_type\": actual type from sourceCheck,\n    \"bot_risk_assessment\": actual assessment from accountCheck,\n    \"account_authenticity_score\": actual number from accountCheck\n  },\n  \"key_concerns\": [\n    \"List specific concerns based on actual data\",\n    \"Use actual classifications, scores, and assessments\",\n    \"For HATE_CONTENT: specify targeting and safety violations\",\n    \"For low scores: explain what's problematic\"\n  ],\n  \"mitigating_factors\": [\n    \"List specific mitigating factors from actual data\",\n    \"For SATIRE: note disclosure in bio\",\n    \"For official sources: note authority and verification\",\n    \"For high scores: explain what's trustworthy\"\n  ],\n  \"recommended_action\": {\n    \"primary_action\": \"Specific action appropriate for risk level and classification\",\n    \"rationale\": \"Clear explanation using ACTUAL data from all agents. For HATE_CONTENT: explain targeting and harm potential. For SATIRE: explain disclosure status. For normal content: explain scoring logic.\",\n    \"urgency\": \"immediate|within_24h|monitor|none\"\n  },\n  \"human_review_needed\": true/false,\n  \"summary\": \"1-2 sentence summary using ACTUAL classifications, scores, and source types. For HATE_CONTENT: mention targeting. For SATIRE: mention parody status. Be specific and data-driven.\"\n}\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nCRITICAL REMINDERS\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n**SAFETY FIRST:**\n- HATE_CONTENT classification â†’ Always HIGH/CRITICAL risk, immediate action\n- Safety overrides all other considerations\n- No composite score needed for safety violations\n\n**CLASSIFICATION-SPECIFIC HANDLING:**\n- HATE_CONTENT â†’ Remove/flag immediately, explain targeting\n- SATIRE â†’ Add parody label, medium risk, not immediate\n- DISINFORMATION â†’ Flag with warning, immediate\n- PROPAGANDA/BIASED â†’ Add context, within 24h\n- UNVERIFIABLE â†’ Medium risk default, consider source credibility\n- LEGITIMATE â†’ Low risk, minimal action\n\n**SOURCE TYPE AWARENESS:**\n- government_official/government_agency â†’ High authority, increase weight\n- official_org + HIGH rating â†’ Trusted organizations\n- parody_account â†’ Check if SATIRE classification matches\n- partisan_commentator + VERY_LOW â†’ High risk amplification\n\n**USE ACTUAL DATA:**\n- Don't make up numbers or classifications\n- Reference specific scores and ratings from agents\n- Explain reasoning with concrete evidence\n- Be specific about what makes content risky or safe\n\n**GLOBAL APPLICABILITY:**\n- Works for any country's government officials\n- Works for any type of content (health, politics, sports, etc.)\n- Works for any protected group (religious, ethnic, etc.)\n- Works for any source type globally\n\n**RETURN FORMAT:**\n- Return ONLY valid JSON\n- No markdown, no code blocks\n- Use actual values from input data\n- Be specific and clear in all text fields\n\nReturn only JSON.",
        "options": {
          "systemMessage": "You are final decision agent for misinformation risk. Return ONLY valid JSON, no markdown. Handle missing data gracefully.",
          "maxIterations": 1
        }
      },
      "id": "9aeaf5a8-16f3-45ac-a2b1-62e43b8244ca",
      "name": "Agent 4 - Decision",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.6,
      "position": [
        4944,
        -464
      ],
      "retryOnFail": true
    },
    {
      "parameters": {
        "jsCode": "// Format Agent 4 output for Google Sheets\nconst agent4Output = $input.first().json.output;\nconst originalData = $('Parse Input Data').first().json;\n\n// Parse Agent 4 JSON output\nlet assessment = {};\ntry {\n  if (typeof agent4Output === 'string') {\n    const cleaned = agent4Output.trim()\n      .replace(/^```json\\s*/i, '')\n      .replace(/^```\\s*/i, '')\n      .replace(/\\s*```$/i, '');\n    assessment = JSON.parse(cleaned);\n  } else {\n    assessment = agent4Output;\n  }\n} catch (e) {\n  assessment = { error: 'Failed to parse Agent 4 output' };\n}\n\n// Determine source type\nconst sourceType = originalData.sourceType || 'unknown';\nconst source = sourceType === 'twitter' ? 'Twitter' : \n               sourceType === 'dataset' ? 'WhatsApp/Dataset' : \n               'Unknown';\n\n// Get original content\nconst content = originalData.tweetText || originalData.text || 'N/A';\nconst contentPreview = content.substring(0, 200);\n\n// Extract scores\nconst riskLevel = assessment.final_assessment?.risk_level || 'UNKNOWN';\nconst compositeScore = assessment.final_assessment?.composite_score || 0;\nconst confidence = assessment.final_assessment?.confidence || 'UNKNOWN';\n\n// Extract contributing factors\nconst factCheckClass = assessment.contributing_factors?.fact_check_classification || 'N/A';\nconst factCheckScore = assessment.contributing_factors?.fact_check_score || 0;\nconst sourceCredibility = assessment.contributing_factors?.source_credibility || 'N/A';\nconst sourceScore = assessment.contributing_factors?.source_score || 0;\nconst accountAuth = assessment.contributing_factors?.account_authenticity || 'N/A';\nconst accountScore = assessment.contributing_factors?.account_score || 0;\n\n// Extract concerns and actions\nconst keyConcerns = (assessment.key_concerns || []).join('; ');\nconst recommendedAction = assessment.recommended_action?.primary_action || 'N/A';\nconst urgency = assessment.recommended_action?.urgency || 'N/A';\nconst rationale = assessment.recommended_action?.rationale || 'N/A';\nconst summary = assessment.summary || 'N/A';\n\n// Get metadata\nconst tweetUrl = originalData.tweetMetadata?.tweet_url || originalData.tweet_url || 'N/A';\nconst author = originalData.accountData?.username || 'N/A';\nconst dataset = originalData.dataset || 'N/A';\nconst supabaseId = originalData.supabase_id || 'N/A';\n\nreturn {\n  json: {\n    timestamp: new Date().toISOString(),\n    source: source,\n    source_type: sourceType,\n    content_preview: contentPreview,\n    full_content: content,\n    \n    // Risk Assessment\n    risk_level: riskLevel,\n    composite_score: compositeScore,\n    confidence: confidence,\n    \n    // Fact Check\n    fact_check_classification: factCheckClass,\n    fact_check_score: factCheckScore,\n    \n    // Source Credibility\n    source_credibility_rating: sourceCredibility,\n    source_credibility_score: sourceScore,\n    \n    // Account Analysis\n    account_authenticity: accountAuth,\n    account_score: accountScore,\n    \n    // Actions & Concerns\n    key_concerns: keyConcerns,\n    recommended_action: recommendedAction,\n    urgency: urgency,\n    rationale: rationale,\n    summary: summary,\n    \n    // Metadata\n    tweet_url: tweetUrl,\n    author: author,\n    dataset: dataset,\n    supabase_id: supabaseId,\n    \n    // Raw output for reference\n    raw_assessment: JSON.stringify(assessment)\n  }\n};"
      },
      "id": "d21a9e4d-c091-4a6c-aa70-b11a4a7effbf",
      "name": "Format for Google Sheets",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        5328,
        -464
      ]
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        2224,
        -224
      ],
      "id": "1f8e6ebf-1750-45b6-ace4-cf0aa6428400",
      "name": "Google Gemini Chat Model2",
      "credentials": {
        "googlePalmApi": {
          "id": "MLCxKRnMtF7Rthld",
          "name": "Google Gemini(PaLM) Api account"
        }
      }
    },
    {
      "parameters": {
        "model": "meta-llama/llama-4-scout-17b-16e-instruct",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGroq",
      "typeVersion": 1,
      "position": [
        3152,
        -880
      ],
      "id": "d75659a2-92d3-4baa-b3c5-4380029317b6",
      "name": "Groq Chat Model",
      "credentials": {
        "groqApi": {
          "id": "aDgjoiavOeg5nbsa",
          "name": "Groq account 2"
        }
      }
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        4944,
        -272
      ],
      "id": "34b8348f-2eb4-43c8-81e5-ca00e3c1608b",
      "name": "Google Gemini Chat Model",
      "credentials": {
        "googlePalmApi": {
          "id": "MLCxKRnMtF7Rthld",
          "name": "Google Gemini(PaLM) Api account"
        }
      }
    },
    {
      "parameters": {
        "updates": [
          "messages"
        ],
        "options": {}
      },
      "type": "n8n-nodes-base.whatsAppTrigger",
      "typeVersion": 1,
      "position": [
        -816,
        -624
      ],
      "id": "18d20704-8eff-43ed-b3d5-47d91d864196",
      "name": "WhatsApp Trigger",
      "webhookId": "1f66d001-0eb2-49c9-a002-a5ac810c46c5",
      "credentials": {
        "whatsAppTriggerApi": {
          "id": "vSb7Wo9wZmEFxgbX",
          "name": "WhatsApp OAuth account"
        }
      }
    },
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "const item = $input.item;\nconst body = item.json.messages?.[0]?.text?.body || 'F600';\n\nconst datasetType = body.charAt(0).toUpperCase();\nconst idx = parseInt(body.substring(1)) || 600;\nconst dataset = datasetType === 'T' ? 'true-news' : 'false-news';\n\nreturn {\n  json: {\n    datasetType: datasetType,\n    idx: idx,\n    dataset: dataset,\n    tableId: dataset,\n    rowId: idx\n  }\n};"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -496,
        -624
      ],
      "id": "facdb488-e172-43b7-9ac2-b75592f6eb92",
      "name": "WhatsApp Input Parser"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=Use the supabase tool to get data from the dataset.\n\nInput:\n- Table: {{ $json.tableId }}\n- Dataset Type: {{ $json.datasetType }}\n- Row ID: {{ $json.rowId }}\n\nFormat output as JSON:\n{\n  \"text\": \"the text field from supabase\",\n  \"tweetSource\": \"{{ $json.tableId }}\",\n  \"sourceType\": \"dataset\",\n  \"tweetMetadata\": {},\n  \"accountData\": {},\n  \"supabase_id\": {{ $json.rowId }},\n  \"dataset\": \"{{ $json.tableId }}\",\n  \"datasetType\": \"{{ $json.datasetType }}\",\n  \"title\": \"title field if exists\",\n  \"subject\": \"subject field if exists\",\n  \"date\": \"date field if exists\"\n}\n\nReturn only valid JSON.",
        "options": {
          "systemMessage": "You are a data formatter. Extract from Supabase and format as JSON. Return only valid JSON.",
          "maxIterations": 3
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.6,
      "position": [
        -208,
        -624
      ],
      "id": "2a283509-77e4-408d-91a4-6bf90e75d398",
      "name": "AI Agent - Supabase Formatter",
      "executeOnce": false,
      "alwaysOutputData": true
    },
    {
      "parameters": {
        "operation": "get",
        "tableId": "={{ $json.dataset }}",
        "filters": {
          "conditions": [
            {
              "keyName": "id",
              "keyValue": "={{ $json.idx }}"
            }
          ]
        }
      },
      "type": "n8n-nodes-base.supabaseTool",
      "typeVersion": 1,
      "position": [
        -64,
        -400
      ],
      "id": "91023624-26cf-4802-8c83-9ebacf8cc28d",
      "name": "Get row from Dataset (Supabase)",
      "credentials": {
        "supabaseApi": {
          "id": "Cgrz5nOdspcCgDyr",
          "name": "Supabase account"
        }
      }
    },
    {
      "parameters": {
        "options": {
          "maxOutputTokens": 1000
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        -208,
        -384
      ],
      "id": "158abb22-18e0-4b54-ae83-81abb84300e5",
      "name": "Google Gemini Chat Model3",
      "credentials": {
        "googlePalmApi": {
          "id": "MLCxKRnMtF7Rthld",
          "name": "Google Gemini(PaLM) Api account"
        }
      }
    },
    {
      "parameters": {},
      "id": "7c20b692-91f0-473f-8c7c-0d4e1b019216",
      "name": "Merge Dataset & Twitter Inputs",
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3,
      "position": [
        112,
        -608
      ]
    },
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "const item = $input.item.json;\n\nconsole.log('ğŸ” Format Input Data received:', Object.keys(item));\nconsole.log('ğŸ‘¤ accountData received:', item.accountData);\nconsole.log('ğŸ“… created_at received:', item.created_at);  // â† ADD: Debug log\n\n// Check if this is Twitter data (from viral tweets or WhatsApp)\nconst isTwitterViral = item.tweetSource === 'twitter_viral' || item.tweetSource === 'twitter_viral_random' || (item.tweetText && item.sourceType === 'twitter');\nconst isWhatsAppTwitter = item.body && item.body.tweetText;\nconst isDataset = item.dataset || (item.text && !isTwitterViral);\n\nif (isTwitterViral) {\n  // Data from enriched Twitter - PRESERVE enriched accountData!\n  const result = {\n    json: {\n      tweetText: item.tweetText || item.tweet_text || '',\n      tweetSource: item.tweetSource || 'twitter_viral',\n      tweetMetadata: item.tweetMetadata || {\n        virality_score: item.virality_score,\n        engagement: item.engagement,\n        author: item.author,\n        verified: item.verified,\n        tweet_id: item.tweet_id,\n        tweet_url: item.tweet_url,\n        created_at: item.created_at || 'unknown'  // â† ADD THIS LINE!\n      },\n      // CRITICAL: Use enriched accountData if available!\n      accountData: item.accountData || {},\n      sourceType: 'twitter',\n      tweet_id: item.tweet_id,\n      tweet_url: item.tweet_url,\n      virality_score: item.virality_score,\n      engagement: item.engagement,\n      author: item.author\n    }\n  };\n  \n  console.log('âœ… Formatted Twitter data');\n  console.log('âœ… accountData in result:', result.json.accountData);\n  console.log('âœ… created_at in result:', result.json.tweetMetadata.created_at);  // â† ADD: Debug log\n  \n  return result;\n  \n} else if (isWhatsAppTwitter) {\n  // Data from WhatsApp (nested under body)\n  return {\n    json: {\n      tweetText: item.body.tweetText || '',\n      tweetSource: item.body.tweetSource || 'whatsapp',\n      tweetMetadata: item.body.tweetMetadata || {\n        created_at: item.body.created_at || 'unknown'  // â† ADD THIS!\n      },\n      accountData: item.body.accountData || {},\n      sourceType: 'twitter'\n    }\n  };\n  \n} else if (isDataset) {\n  // Data from dataset\n  return {\n    json: {\n      tweetText: item.text || '',\n      tweetSource: item.tweetSource || item.dataset || 'dataset',\n      tweetMetadata: item.tweetMetadata || {\n        date: item.date || 'unknown'  // â† Datasets might have different date field\n      },\n      accountData: item.accountData || {},\n      sourceType: item.sourceType || 'dataset',\n      supabase_id: item.supabase_id,\n      dataset: item.dataset,\n      datasetType: item.datasetType,\n      title: item.title,\n      subject: item.subject,\n      date: item.date\n    }\n  };\n  \n} else {\n  // Fallback for unknown format\n  console.log('âš ï¸ Unknown format, using fallback');\n  return {\n    json: {\n      tweetText: JSON.stringify(item),\n      tweetSource: 'unknown',\n      tweetMetadata: {\n        created_at: 'unknown'  // â† ADD THIS!\n      },\n      accountData: {},\n      sourceType: 'manual'\n    }\n  };\n}"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        608,
        -384
      ],
      "id": "76d20e3c-7ff5-4911-8724-0f4e13c85b28",
      "name": "Format Input Data"
    },
    {
      "parameters": {
        "jsCode": "// Combine all 3 agent outputs into one structured object\nconst allInputs = $input.all();\n\n// Safe parse function\nfunction safeParse(data) {\n  if (!data) return null;\n  if (typeof data === 'object' && !Array.isArray(data)) return data;\n  if (typeof data === 'string') {\n    try {\n      let cleaned = data.trim()\n        .replace(/^```json\\s*/i, '')\n        .replace(/^```\\s*/i, '')\n        .replace(/\\s*```$/i, '');\n      return JSON.parse(cleaned);\n    } catch (e) {\n      console.error('Parse error:', e);\n      return null;\n    }\n  }\n  return null;\n}\n\n// Parse each input\nconst factCheck = safeParse(allInputs[0]?.json?.output);\nconst sourceCheck = safeParse(allInputs[1]?.json?.output);\nconst accountCheck = safeParse(allInputs[2]?.json?.output);\n\n// Return combined data\nreturn {\n  json: {\n    factCheck: factCheck || {\n      classification: 'UNVERIFIABLE',\n      fact_accuracy_score: 50,\n      deceptiveness_score: 50,\n      appears_intentional: false,\n      confidence: 'low'\n    },\n    sourceCheck: sourceCheck || {\n      source_credibility: { rating: 'UNKNOWN', score: 50 },\n      overall_trustworthiness_score: 50\n    },\n    accountCheck: accountCheck || {\n      bot_probability: 'NOT_APPLICABLE',\n      authenticity_score: 50,\n      data_available: false\n    }\n  }\n};"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        4656,
        -368
      ],
      "id": "ac384129-39cb-446b-be3a-bfdb5606302c",
      "name": "Combine for Agent 4"
    },
    {
      "parameters": {
        "rule": {
          "interval": [
            {
              "field": "hours",
              "hoursInterval": 4
            }
          ]
        }
      },
      "id": "5d8c8c17-1e3b-46f3-a1a6-439767cf81e0",
      "name": "Every 4 Hours",
      "type": "n8n-nodes-base.scheduleTrigger",
      "typeVersion": 1.2,
      "position": [
        -992,
        -96
      ]
    },
    {
      "parameters": {},
      "type": "n8n-nodes-base.manualTrigger",
      "typeVersion": 1,
      "position": [
        -1088,
        208
      ],
      "id": "009bd1b3-aa61-4448-8042-4c54a8f4cc31",
      "name": "Manual Trigger"
    },
    {
      "parameters": {
        "url": "https://twitter-api45.p.rapidapi.com/search.php",
        "sendQuery": true,
        "queryParameters": {
          "parameters": [
            {
              "name": "query",
              "value": "(breaking OR urgent OR news) min_retweets:500 lang:en"
            },
            {
              "name": "search_type",
              "value": "Latest"
            },
            {
              "name": "count",
              "value": "1"
            }
          ]
        },
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "X-RapidAPI-Key",
              "value": "80ab7267a3msh12d875a20cb2293p104766jsnd30f01f53a5c"
            },
            {
              "name": "X-RapidAPI-Host",
              "value": "twitter-api45.p.rapidapi.com"
            }
          ]
        },
        "options": {}
      },
      "id": "a3f5bae1-e462-49a5-8a0c-79d562325a2e",
      "name": "Search Viral News Tweets",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -624,
        0
      ]
    },
    {
      "parameters": {
        "jsCode": "// Configuration\nconst ITEM_LIMIT = 1;\nconst TOP_N_POOL = 10;\n\nconsole.log('ğŸ¯ Config: Return', ITEM_LIMIT, 'random tweet(s) from top', TOP_N_POOL);\n\nconst response = $input.first().json;\n\n// Get tweets array\nconst tweets = response.timeline || response.tweets || response.results || response.data || [];\n\nif (!Array.isArray(tweets) || tweets.length === 0) {\n  console.log('âŒ No tweets found');\n  return [{json: {error: 'No tweets found', raw: response}}];\n}\n\nconsole.log('âœ… Found', tweets.length, 'tweets');\n\n// Calculate virality for each tweet\nconst ranked = tweets.map(t => {\n  const retweets = t.retweet_count || t.retweetCount || t.retweets || t.public_metrics?.retweet_count || 0;\n  const likes = t.favorite_count || t.favoriteCount || t.likeCount || t.likes || t.favorites || t.public_metrics?.like_count || 0;\n  const replies = t.reply_count || t.replyCount || t.replies || t.public_metrics?.reply_count || 0;\n  const quotes = t.quote_count || t.quoteCount || t.quotes || t.public_metrics?.quote_count || 0;\n  \n  const viralityScore = (retweets * 2) + likes + (replies * 3) + (quotes * 2);\n  \n  return {\n    ...t,\n    virality_score: viralityScore,\n    _retweets: retweets,\n    _likes: likes,\n    _replies: replies,\n    _quotes: quotes\n  };\n});\n\n// Sort by virality (highest first)\nranked.sort((a, b) => b.virality_score - a.virality_score);\n\n// Take top N pool\nconst topPool = ranked.slice(0, Math.min(TOP_N_POOL, ranked.length));\n\nconsole.log('ğŸ² Top', topPool.length, 'viral tweets:', topPool.map(t => t.virality_score));\n\n// Randomly select from the pool\nconst shuffled = topPool.sort(() => Math.random() - 0.5);\nconst selected = shuffled.slice(0, ITEM_LIMIT);\n\nconsole.log('âœ¨ Randomly selected tweet with virality:', selected[0]?.virality_score);\n\n// Format output\nreturn selected.map((t, i) => {\n  const user = t.user_info || t.user || t.author || {};\n  const id = t.id_str || t.id || t.tweet_id || t.tweetId;\n  const text = t.full_text || t.text || t.tweet_text || t.content || '';\n  const username = user.screen_name || user.username || t.screen_name || 'unknown';\n  \n  return {\n    json: {\n      rank: 'random_from_top_' + TOP_N_POOL,\n      tweet_id: id,\n      tweet_text: text,\n      tweet_url: id ? `https://twitter.com/i/web/status/${id}` : 'N/A',\n      virality_score: t.virality_score,\n      engagement: `${t._retweets} RT | ${t._likes} â™¥ | ${t._replies} ğŸ’¬ | ${t._quotes} ğŸ’¬`,\n      author: `@${username}`,\n      verified: (user.verified || t.verified) ? 'âœ“' : 'âœ—',\n      preview: text.substring(0, 150) + '...',\n      created_at: t.created_at || 'unknown',  // â† ONLY LINE ADDED!\n      \n      // For misinformation pipeline\n      tweetText: text,\n      tweetSource: 'twitter_viral_random',\n      sourceType: 'twitter',\n      accountData: {\n        username: username,\n        verified: user.verified || t.verified || false,\n        followers: user.followers_count || user.followersCount || 0\n      }\n    }\n  };\n});"
      },
      "id": "9a0006dc-3817-4f3a-a51d-a827bdf0f39c",
      "name": "Get Top N Most Viral",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -400,
        0
      ]
    },
    {
      "parameters": {
        "operation": "append",
        "documentId": {
          "__rl": true,
          "value": "19x-lnuAPH9FbvyLR8es4pUxxw5QXHhsLVpBXCfBxWfc",
          "mode": "list",
          "cachedResultName": "tetst",
          "cachedResultUrl": "https://docs.google.com/spreadsheets/d/19x-lnuAPH9FbvyLR8es4pUxxw5QXHhsLVpBXCfBxWfc/edit?usp=drivesdk"
        },
        "sheetName": {
          "__rl": true,
          "value": "gid=0",
          "mode": "list",
          "cachedResultName": "Sheet1",
          "cachedResultUrl": "https://docs.google.com/spreadsheets/d/19x-lnuAPH9FbvyLR8es4pUxxw5QXHhsLVpBXCfBxWfc/edit#gid=0"
        },
        "columns": {
          "mappingMode": "autoMapInputData",
          "value": {},
          "matchingColumns": [],
          "schema": [],
          "attemptToConvertTypes": false,
          "convertFieldsToString": false
        },
        "options": {}
      },
      "type": "n8n-nodes-base.googleSheets",
      "typeVersion": 4.7,
      "position": [
        5568,
        -464
      ],
      "id": "42dbd3e8-bdc0-4a7a-9e34-ae56c6d9caca",
      "name": "Append row in sheet",
      "credentials": {
        "googleSheetsOAuth2Api": {
          "id": "pOlMsCkST1NkdxUo",
          "name": "Google Sheets account 2"
        }
      }
    },
    {
      "parameters": {
        "url": "=https://twitter-api45.p.rapidapi.com/screenname.php?screenname={{ $json.accountData.username }}",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "X-RapidAPI-Key",
              "value": "80ab7267a3msh12d875a20cb2293p104766jsnd30f01f53a5c"
            },
            {
              "name": "X-RapidAPI-Host",
              "value": "twitter-api45.p.rapidapi.com"
            }
          ]
        },
        "options": {
          "response": {
            "response": {}
          }
        }
      },
      "id": "5b14603c-7541-4e68-8a0b-52a8c9f49dad",
      "name": "Enrich Twitter Account Data",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -224,
        240
      ]
    },
    {
      "parameters": {
        "jsCode": "const item = $input.first().json;\n\nconsole.log('ğŸ“¥ Input keys:', Object.keys(item));\nconsole.log('ğŸ” Has enrichmentData?', !!item.enrichmentData);\n\n// Original tweet data\nconst originalData = { ...item };\ndelete originalData.enrichmentData; // Remove the API response from spread\n\n// API response\nconst apiResponse = item.enrichmentData;\n\nif (!apiResponse || !Array.isArray(apiResponse) || apiResponse.length === 0) {\n  console.log('âŒ No enrichment data, returning original');\n  return { json: originalData };\n}\n\n// Extract user data\nconst userData = apiResponse[0];\nconsole.log('ğŸ‘¤ User data keys:', Object.keys(userData));\n\n// Extract values\nconst followers = userData.sub_count || 0;\nconst following = userData.friends || 0;\nconst totalTweets = userData.statuses_count || 0;\nconst isVerified = userData.blue_verified || false;\n\nconsole.log('ğŸ“Š Extracted - Followers:', followers, 'Following:', following);\n\n// Calculate\nconst createdAt = new Date(userData.created_at);\nconst accountAgeDays = Math.floor((Date.now() - createdAt.getTime()) / (1000 * 60 * 60 * 24));\nconst tweetsPerDay = accountAgeDays > 0 ? (totalTweets / accountAgeDays).toFixed(2) : '0';\nconst followerRatio = following > 0 ? (followers / following).toFixed(2) : String(followers);\n\n// Profile completeness\nlet score = 0;\nif (userData.avatar) score += 1;\nif (userData.desc) score += 1;\nif (userData.location) score += 1;\nif (isVerified) score += 2;\nif (userData.header_image) score += 1;\nif (userData.website) score += 1;\n\n// Build enriched data\nconst enrichedAccountData = {\n  username: userData.name || userData.profile,\n  verified: isVerified,\n  followers: followers,\n  following: following,\n  follower_ratio: followerRatio,\n  total_tweets: totalTweets,\n  account_age_days: accountAgeDays,\n  tweets_per_day: tweetsPerDay,\n  profile_completeness_score: `${score}/7`,\n  has_profile_image: !!userData.avatar,\n  has_bio: !!userData.desc,\n  has_location: !!userData.location,\n  has_banner: !!userData.header_image,\n  has_website: !!userData.website,\n  created_at: userData.created_at,\n  description: userData.desc || '',\n  location: userData.location || '',\n  website: userData.website || ''\n};\n\nconsole.log('âœ… Enriched accountData:', enrichedAccountData);\n\n// Return original data with enriched accountData\nreturn {\n  json: {\n    ...originalData,\n    accountData: enrichedAccountData\n  }\n};\n"
      },
      "id": "ea625ab3-eddd-483f-b7d3-79cd20bb1f88",
      "name": "Merge Enriched Data",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -48,
        240
      ]
    },
    {
      "parameters": {},
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3.2,
      "position": [
        192,
        -96
      ],
      "id": "92d18cf2-6712-481b-aca4-cebfa1f96c1a",
      "name": "Merge2"
    },
    {
      "parameters": {
        "jsCode": "const inputs = $input.all();\n\nif (inputs.length !== 2) {\n  return { json: inputs[0]?.json || {} };\n}\n\n// Item 0: Original tweet data\nconst originalData = inputs[0].json;\n\n// Item 1: API response\nconst apiResponse = inputs[1].json;\n\n// Extract user data\nconst userData = apiResponse;\n\n// Extract values\nconst followers = userData.sub_count || 0;\nconst following = userData.friends || 0;\nconst totalTweets = userData.statuses_count || 0;\nconst isVerified = userData.blue_verified || false;\n\n// Calculate derived fields\nconst createdAt = new Date(userData.created_at);\nconst accountAgeDays = Math.floor((Date.now() - createdAt.getTime()) / (1000 * 60 * 60 * 24));\nconst tweetsPerDay = accountAgeDays > 0 ? (totalTweets / accountAgeDays).toFixed(2) : '0';\nconst followerRatio = following > 0 ? (followers / following).toFixed(2) : String(followers);\n\n// Calculate profile completeness score\nlet score = 0;\nif (userData.avatar) score += 1;\nif (userData.desc) score += 1;\nif (userData.location) score += 1;\nif (isVerified) score += 2;\nif (userData.header_image) score += 1;\nif (userData.website) score += 1;\n\n// Build enriched accountData\nconst enrichedAccountData = {\n  username: userData.name,\n  verified: isVerified,\n  followers: followers,\n  following: following,\n  follower_ratio: followerRatio,\n  total_tweets: totalTweets,\n  account_age_days: accountAgeDays,\n  tweets_per_day: tweetsPerDay,\n  profile_completeness_score: `${score}/7`,\n  has_profile_image: !!userData.avatar,\n  has_bio: !!userData.desc,\n  has_location: !!userData.location,\n  has_banner: !!userData.header_image,\n  has_website: !!userData.website,\n  created_at: userData.created_at,\n  description: userData.desc || '',\n  location: userData.location || '',\n  website: userData.website || ''\n};\n\n// Return original data with enriched accountData\nreturn {\n  json: {\n    ...originalData,\n    accountData: enrichedAccountData\n  }\n};"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        400,
        -96
      ],
      "id": "42721ee7-096d-405e-8a02-7e17883009e6",
      "name": "Build Final Enriched Data"
    },
    {
      "parameters": {
        "modelName": "models/gemini-2.5-pro",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        2512,
        -672
      ],
      "id": "114ace93-27b1-4d36-84be-a63e77bd24b9",
      "name": "Google Gemini Chat Model4",
      "credentials": {
        "googlePalmApi": {
          "id": "MLCxKRnMtF7Rthld",
          "name": "Google Gemini(PaLM) Api account"
        }
      }
    },
    {
      "parameters": {
        "model": "meta-llama/llama-4-scout-17b-16e-instruct",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGroq",
      "typeVersion": 1,
      "position": [
        2784,
        -256
      ],
      "id": "2f1f8942-7927-4ecd-b1c7-dd1471359150",
      "name": "Groq Chat Model1",
      "credentials": {
        "groqApi": {
          "id": "aDgjoiavOeg5nbsa",
          "name": "Groq account 2"
        }
      }
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        2240,
        272
      ],
      "id": "8908b12a-c18c-4bb9-bea1-7ae2f77ba64a",
      "name": "Google Gemini Chat Model5",
      "credentials": {
        "googlePalmApi": {
          "id": "MLCxKRnMtF7Rthld",
          "name": "Google Gemini(PaLM) Api account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "try {\n  // Get both outputs\n  const backupOutputRaw = $input.item.json.output;\n  const primaryOutputRaw = $('Check Agent 1 Confidence').first().json.output;\n  \n  // Parse function\n  function safeParse(data) {\n    if (!data) return null;\n    if (typeof data === 'object') return data;\n    if (typeof data === 'string') {\n      try {\n        let cleaned = data.trim()\n          .replace(/^```json\\s*/i, '')\n          .replace(/^```\\s*/i, '')\n          .replace(/\\s*```$/i, '');\n        return JSON.parse(cleaned);\n      } catch (e) {\n        return null;\n      }\n    }\n    return null;\n  }\n  \n  const primary = safeParse(primaryOutputRaw);\n  const backup = safeParse(backupOutputRaw);\n  \n  if (!primary || !backup) {\n    return {\n      json: {\n        error: \"Failed to parse\",\n        primaryParsed: !!primary,\n        backupParsed: !!backup\n      }\n    };\n  }\n  \n  // Check if both agents agree on special classifications\n  const primaryClass = primary.classification;\n  const backupClass = backup.classification;\n  \n  // If both agree on UNVERIFIABLE, SATIRICAL, or CLICK-BAIT, keep it\n  if (primaryClass === backupClass && \n      ['UNVERIFIABLE', 'SATIRICAL', 'CLICK-BAIT'].includes(primaryClass)) {\n    return {\n      json: {\n        output: JSON.stringify({\n          classification: primaryClass,\n          fact_accuracy_score: Math.round(\n            ((primary.fact_accuracy_score || 50) + (backup.fact_accuracy_score || 50)) / 2\n          ),\n          deceptiveness_score: Math.round(\n            ((primary.deceptiveness_score || 50) + (backup.deceptiveness_score || 50)) / 2\n          ),\n          appears_intentional: primary.appears_intentional || backup.appears_intentional,\n          confidence: primary.confidence || backup.confidence || 'medium',\n          verified_claims: backup.verified_claims || primary.verified_claims || [],\n          false_news_patterns_detected: [...new Set([\n            ...(primary.false_news_patterns_detected || []),\n            ...(backup.false_news_patterns_detected || [])\n          ])],\n          key_omissions: [...new Set([\n            ...(primary.key_omissions || []),\n            ...(backup.key_omissions || [])\n          ])],\n          manipulation_techniques: [...new Set([\n            ...(primary.manipulation_techniques || []),\n            ...(backup.manipulation_techniques || [])\n          ])],\n          overall_assessment: `Primary: ${primary.overall_assessment || 'N/A'}. Backup: ${backup.overall_assessment || 'N/A'}. Both agents agree on ${primaryClass}.`,\n          recommendation: primary.recommendation || backup.recommendation || 'REQUIRES_MORE_INVESTIGATION',\n          dual_verification: true,\n          agent_comparison: {\n            fact_score_diff: Math.abs((primary.fact_accuracy_score || 50) - (backup.fact_accuracy_score || 50)),\n            deceptiveness_diff: Math.abs((primary.deceptiveness_score || 50) - (backup.deceptiveness_score || 50)),\n            avg_difference: Math.round(\n              (Math.abs((primary.fact_accuracy_score || 50) - (backup.fact_accuracy_score || 50)) +\n               Math.abs((primary.deceptiveness_score || 50) - (backup.deceptiveness_score || 50))) / 2\n            ),\n            primary_classification: primaryClass,\n            backup_classification: backupClass\n          }\n        })\n      }\n    };\n  }\n  \n  // Average scores\n  const avgFactScore = Math.round(\n    ((primary.fact_accuracy_score || 50) + (backup.fact_accuracy_score || 50)) / 2\n  );\n  \n  const avgDeceptScore = Math.round(\n    ((primary.deceptiveness_score || 50) + (backup.deceptiveness_score || 50)) / 2\n  );\n  \n  // Determine classification (for disagreements or standard classifications)\n  let finalClassification;\n  const avgIntent = primary.appears_intentional || backup.appears_intentional;\n  \n  // Check if either agent said UNVERIFIABLE\n  if (primaryClass === 'UNVERIFIABLE' || backupClass === 'UNVERIFIABLE') {\n    finalClassification = 'UNVERIFIABLE';\n  }\n  // Check for SATIRICAL\n  else if (primaryClass === 'SATIRICAL' || backupClass === 'SATIRICAL') {\n    finalClassification = 'SATIRICAL';\n  }\n  // Check for CLICK-BAIT\n  else if (primaryClass === 'CLICK-BAIT' || backupClass === 'CLICK-BAIT') {\n    finalClassification = 'CLICK-BAIT';\n  }\n  // Standard classification logic\n  else if (avgFactScore < 40) {\n    finalClassification = avgIntent ? 'DISINFORMATION' : 'MISINFORMATION';\n  } else if (avgFactScore >= 60 && avgDeceptScore > 60) {\n    finalClassification = 'PROPAGANDA';\n  } else if (avgFactScore > 80 && avgDeceptScore < 30) {\n    finalClassification = 'LEGITIMATE';\n  } else {\n    finalClassification = 'BIASED_BUT_FACTUAL';\n  }\n  \n  // Calculate confidence\n  const factDiff = Math.abs((primary.fact_accuracy_score || 50) - (backup.fact_accuracy_score || 50));\n  const deceptDiff = Math.abs((primary.deceptiveness_score || 50) - (backup.deceptiveness_score || 50));\n  const avgDiff = (factDiff + deceptDiff) / 2;\n  \n  const finalConfidence = avgDiff <= 10 ? 'high' : avgDiff <= 20 ? 'medium' : 'low';\n  \n  // Recommendation\n  let recommendation;\n  if (finalClassification === 'UNVERIFIABLE') {\n    recommendation = 'REQUIRES_MORE_INVESTIGATION';\n  } else if (finalClassification === 'PROPAGANDA' || finalClassification === 'DISINFORMATION') {\n    recommendation = 'FLAG_AS_FALSE_NEWS';\n  } else if (finalClassification === 'MISINFORMATION' || finalClassification === 'BIASED_BUT_FACTUAL') {\n    recommendation = 'LABEL_AS_BIASED';\n  } else {\n    recommendation = 'NO_ACTION_NEEDED';\n  }\n  \n  // Merge arrays\n  const mergedPatterns = [...new Set([\n    ...(primary.false_news_patterns_detected || []),\n    ...(backup.false_news_patterns_detected || [])\n  ])];\n  \n  const mergedOmissions = [...new Set([\n    ...(primary.key_omissions || []),\n    ...(backup.key_omissions || [])\n  ])];\n  \n  const mergedTechniques = [...new Set([\n    ...(primary.manipulation_techniques || []),\n    ...(backup.manipulation_techniques || [])\n  ])];\n  \n  // Return merged result\n  return {\n    json: {\n      output: JSON.stringify({\n        classification: finalClassification,\n        fact_accuracy_score: avgFactScore,\n        deceptiveness_score: avgDeceptScore,\n        appears_intentional: avgIntent,\n        confidence: finalConfidence,\n        verified_claims: backup.verified_claims || primary.verified_claims || [],\n        false_news_patterns_detected: mergedPatterns,\n        key_omissions: mergedOmissions,\n        manipulation_techniques: mergedTechniques,\n        overall_assessment: `Primary: ${primary.overall_assessment || 'N/A'}. Backup: ${backup.overall_assessment || 'N/A'}. Agreement: ${avgDiff <= 10 ? 'Strong' : 'Moderate'} (diff: ${Math.round(avgDiff)})`,\n        recommendation: recommendation,\n        dual_verification: true,\n        agent_comparison: {\n          fact_score_diff: factDiff,\n          deceptiveness_diff: deceptDiff,\n          avg_difference: Math.round(avgDiff),\n          primary_classification: primaryClass,\n          backup_classification: backupClass\n        }\n      })\n    }\n  };\n  \n} catch (error) {\n  return {\n    json: {\n      error: error.message,\n      stack: error.stack\n    }\n  };\n}"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        3632,
        -1040
      ],
      "id": "3171afe4-a9e3-4f52-95ba-4b5efacf99e0",
      "name": "Code in JavaScript"
    },
    {
      "parameters": {},
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3.2,
      "position": [
        2032,
        -848
      ],
      "id": "63579103-bb60-42b9-af61-c4a4d3248677",
      "name": "merge Tweet with web Search"
    },
    {
      "parameters": {
        "jsCode": "// IMPROVED SEARCH QUERY BUILDER - Extracts Facts, Removes Opinions\n\nconst data = $input.item.json;\nconst tweet = (data.tweetText || '').trim();\nconst dateStr = data.tweetMetadata?.created_at || data.created_at;\nconst tweetDate = new Date(dateStr || Date.now());\nconst isoDate = tweetDate.toISOString().split('T')[0];\n\nconsole.log('ğŸ” Building search query for tweet:', tweet.substring(0, 100));\n\n// Calculate tweet age\nconst ageHours = (Date.now() - tweetDate.getTime()) / (1000 * 60 * 60);\nconst isRecent = ageHours < 168; // Last 7 days\n\n// STEP 1: Clean the tweet\nlet cleaned = tweet\n  .replace(/https?:\\/\\/[^\\s]+/g, '')        // Remove URLs\n  .replace(/t\\.co\\/[^\\s]+/g, '')            // Remove t.co links\n  .replace(/BREAKING[:\\s]*/gi, '')          // Remove BREAKING\n  .replace(/[\"\"]/g, '\"')                    // Normalize quotes\n  .replace(/['']/g, \"'\");\n\n// STEP 2: Remove quoted text (if it's editorial/opinion)\nconst quoteMatch = cleaned.match(/\"([^\"]+)\"/);\nlet quotedPart = '';\nlet commentaryPart = '';\n\nif (quoteMatch) {\n  quotedPart = quoteMatch[1];\n  commentaryPart = cleaned.replace(quoteMatch[0], '').trim();\n  console.log('ğŸ“ Quoted part:', quotedPart);\n  console.log('ğŸ’¬ Commentary:', commentaryPart);\n}\n\n// STEP 3: Extract key entities (names, places, organizations)\nconst textToExtract = quotedPart || cleaned;\nconst words = textToExtract.split(/\\s+/);\nconst entities = [];\nconst stopWords = ['The', 'A', 'An', 'And', 'Or', 'But', 'For', 'To', 'In', 'On', 'At', 'From'];\n\nwords.forEach((word, index) => {\n  if (/^[A-Z][a-z]+/.test(word) && !stopWords.includes(word)) {\n    entities.push(word);\n  }\n});\n\nconsole.log('ğŸ·ï¸ Entities extracted:', entities);\n\n// STEP 4: Extract action verbs\nconst actionWords = ['write', 'wrote', 'sign', 'signed', 'ask', 'asked', 'asking', \n                     'reject', 'rejected', 'approve', 'approved', 'vote', 'voted',\n                     'pardon', 'pardoned', 'support', 'oppose', 'letter', 'statement'];\n\nconst actions = words\n  .map(w => w.toLowerCase())\n  .filter(w => actionWords.includes(w));\n\nconsole.log('âš¡ Actions found:', actions);\n\n// STEP 5: Remove opinion/editorial words\nconst opinionWords = ['astonishing', 'corrupt', 'surely', 'disqualifying', \n                     'outrageous', 'shocking', 'terrible', 'amazing', 'incredible',\n                     'unbelievable', 'disgraceful', 'shameful'];\n\nconst cleanedWords = words.filter(w => \n  !opinionWords.includes(w.toLowerCase())\n);\n\n// STEP 6: Build focused query\nlet query = '';\n\nif (entities.length >= 2 && actions.length >= 1) {\n  // Use entities + actions (most focused)\n  query = [...entities.slice(0, 4), ...actions.slice(0, 2)].join(' ');\n} else if (quotedPart) {\n  // Use quoted part (without commentary)\n  query = quotedPart\n    .replace(/[^\\w\\s]/g, ' ')\n    .replace(/\\s+/g, ' ')\n    .trim()\n    .split(/\\s+/)\n    .slice(0, 8)\n    .join(' ');\n} else {\n  // Fallback: Use cleaned words (without opinions)\n  query = cleanedWords\n    .slice(0, 8)\n    .join(' ')\n    .replace(/[^\\w\\s]/g, ' ')\n    .replace(/\\s+/g, ' ')\n    .trim();\n}\n\n// STEP 7: Add temporal context with WIDER DATE RANGE\nif (isRecent && ageHours < 48) {\n  // For very recent tweets (< 2 days), use date from 3 days ago\n  const threeDaysAgo = new Date(tweetDate);\n  threeDaysAgo.setDate(threeDaysAgo.getDate() - 3);\n  const widerDate = threeDaysAgo.toISOString().split('T')[0];\n  \n  query += ` after:${widerDate}`;\n  console.log('ğŸ“… Using wider date range (3 days): after:', widerDate);\n  \n} else if (isRecent && ageHours < 168) {\n  // For tweets in last week, use date from 7 days ago\n  const weekAgo = new Date(tweetDate);\n  weekAgo.setDate(weekAgo.getDate() - 7);\n  const widerDate = weekAgo.toISOString().split('T')[0];\n  \n  query += ` after:${widerDate}`;\n  console.log('ğŸ“… Using week-wide range (7 days): after:', widerDate);\n  \n} else if (tweetDate.getFullYear() >= new Date().getFullYear() - 1) {\n  // For tweets from this year or last year, just add year\n  query += ` ${tweetDate.getFullYear()}`;\n  console.log('ğŸ“… Using year:', tweetDate.getFullYear());\n}\n\n// STEP 8: Universal exclusions\nquery += ' -site:reddit.com -site:twitter.com -site:x.com -site:youtube.com -site:facebook.com';\n\nconsole.log('ğŸ¯ Final search query:', query);\nconsole.log('ğŸ“ Query length:', query.length);\n\nreturn { \n  json: { \n    ...data, \n    search_query: query,\n    extracted_entities: entities,\n    extracted_actions: actions,\n    is_recent: isRecent,\n    tweet_age_hours: Math.round(ageHours)\n  } \n};\n"
      },
      "name": "1. Build Smart Search Query",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1184,
        -928
      ],
      "id": "dba33a16-e5cf-48a9-9ac3-9a332838d2a4"
    },
    {
      "parameters": {
        "jsCode": "// Get search results from Google API\nconst searchResponse = $input.item.json;\n\n// Get original tweet data from all items\nconst allData = $input.all();\nlet originalTweet = {};\nfor (let item of allData) {\n  if (item.json.tweetText && item.json.tweetText !== '') {\n    originalTweet = item.json;\n    break;\n  }\n}\n\nconsole.log('=== SEARCH FILTERING ===');\nconsole.log('Found tweetText?', !!originalTweet.tweetText);\n\n// ===== SOURCE CREDIBILITY TIERS =====\n\n// TIER 1: Top-tier news outlets covering ALL topics\nconst TIER1_SOURCES = [\n  // International News Agencies\n  'reuters.com', 'ap.org', 'apnews.com', 'afp.com',\n  \n  // Major US Newspapers\n  'nytimes.com', 'washingtonpost.com', 'wsj.com', \n  'usatoday.com', 'latimes.com', 'chicagotribune.com',\n  \n  // Major UK News\n  'bbc.com', 'bbc.co.uk', 'theguardian.com', 'telegraph.co.uk',\n  \n  // Major Broadcast News\n  'cnn.com', 'nbcnews.com', 'abcnews.go.com', 'cbsnews.com',  \n  'cnbc.com',\n  \n  // Business/Financial\n  'bloomberg.com', 'ft.com', 'forbes.com',\n  \n  // Public Broadcasting\n  'npr.org', 'pbs.org'\n];\n\n// TIER 2: Established regional/specialized outlets\nconst TIER2_SOURCES = [\n  // Major Regional US Papers\n  'miamiherald.com', 'denverpost.com', 'seattletimes.com',\n  'sfchronicle.com', 'bostonglobe.com', 'ajc.com', 'dallasnews.com',\n  \n  // International Major Papers\n  'timesofindia.com', 'straitstimes.com', 'scmp.com',\n  'japantimes.co.jp', 'aljazeera.com', 'dw.com', 'france24.com',\n  \n  // Korean News (for K-pop/Korean content)\n  'koreatimes.co.kr', 'koreaherald.com', 'yonhapnews.co.kr',\n  \n  // Entertainment/Culture (established)\n  'variety.com', 'hollywoodreporter.com', 'billboard.com',\n  'rollingstone.com', 'pitchfork.com', 'nme.com',\n  \n  // Health/Science (official & authoritative)\n  'scientificamerican.com', 'newscientist.com', 'nature.com',\n  'healthline.com', 'webmd.com', 'mayoclinic.org', 'nih.gov', 'cdc.gov',\n  \n  // Tech\n  'techcrunch.com', 'theverge.com', 'wired.com', 'arstechnica.com',\n  \n  // Official Governing Bodies / Authoritative Organizations  // â† ADD THIS\n  'mlb.com', 'nfl.com', 'nba.com', 'nhl.com', 'fifa.com', 'uefa.com',  // â† ADD THIS\n  'who.int', 'fda.gov', 'sec.gov', 'ftc.gov',  // â† ADD THIS\n  \n  // K-pop Specialized (for entertainment niche)\n  'soompi.com', 'allkpop.com', 'koreaboo.com'\n];\n\n// TIER 3: Legitimate but lower standards OR very specialized\nconst TIER3_SOURCES = [\n  // Sports (major outlets)\n  'espn.com', 'si.com', 'cbssports.com', 'espnfc.com', 'skysports.com',\n  'goal.com', 'bleacherreport.com', 'theathleticfc.com',\n  \n  // Entertainment (tabloid-style but legitimate)\n  'ew.com', 'people.com', 'usmagazine.com', 'tmz.com',\n  \n  // UK Tabloids (sensationalist but real)\n  'thesun.co.uk', 'dailymail.co.uk', 'mirror.co.uk', 'express.co.uk',\n  \n  // Political/News (legitimate niche)\n  'politico.com', 'thehill.com', 'axios.com', 'vox.com',\n  'salon.com', 'slate.com', 'huffpost.com',\n  \n  // Entertainment specialized\n  'deadline.com', 'indiewire.com', 'avclub.com'\n];\n\n// EXCLUDE social media platforms\nconst EXCLUDED_SOURCES = [\n  'facebook.com', 'twitter.com', 'x.com', 'instagram.com',\n  'threads.com', 'reddit.com', 'tiktok.com', 'youtube.com',\n  'pinterest.com', 'tumblr.com', 'quora.com', 'medium.com'\n];\n\n// Function to determine source tier\nfunction getSourceTier(domain) {\n  const lowerDomain = domain.toLowerCase();\n  \n  if (TIER1_SOURCES.some(s => lowerDomain.includes(s))) return 1;\n  if (TIER2_SOURCES.some(s => lowerDomain.includes(s))) return 2;\n  if (TIER3_SOURCES.some(s => lowerDomain.includes(s))) return 3;\n  if (EXCLUDED_SOURCES.some(s => lowerDomain.includes(s))) return 99;\n  \n  return 4; // Unknown sources\n}\n\n// Handle no results from Google\nif (!searchResponse.items || searchResponse.items.length === 0) {\n  console.log('âš ï¸ No search results found');\n  return {\n    json: {\n      ...originalTweet,\n      search_results: [],\n      total_results: 0,\n      credible_sources_found: 0,\n      search_status: 'NO_RESULTS'\n    }\n  };\n}\n\nconsole.log('Total raw results:', searchResponse.items.length);\n\n// Filter, rank, and limit results\nconst rankedResults = searchResponse.items\n  .map(item => ({\n    title: item.title,\n    url: item.link,\n    source: item.displayLink,\n    tier: getSourceTier(item.displayLink)\n  }))\n  .filter(item => {\n    const isExcluded = item.tier === 99;\n    if (isExcluded) {\n      console.log('âŒ Excluded:', item.source);\n    }\n    return !isExcluded;\n  })\n  .sort((a, b) => a.tier - b.tier)\n  .slice(0, 5)\n  .map(({ tier, ...item }) => item);\n\n// Count credible sources (Tier 1, 2, and 3)\nconst credibleCount = rankedResults.filter(r => {\n  const domain = r.source.toLowerCase();\n  return TIER1_SOURCES.some(s => domain.includes(s)) ||\n         TIER2_SOURCES.some(s => domain.includes(s)) ||\n         TIER3_SOURCES.some(s => domain.includes(s));\n}).length;\n\nconsole.log('âœ… Credible sources found:', credibleCount);\nconsole.log('ğŸ“Š Total filtered results:', rankedResults.length);\n\n// Determine search status\nlet searchStatus = 'SUCCESS';\nif (rankedResults.length === 0) {\n  searchStatus = 'NO_CREDIBLE_SOURCES';\n} else if (credibleCount === 0) {\n  searchStatus = 'LOW_QUALITY_ONLY';\n}\n\n// Return combined data with search metadata\nreturn {\n  json: {\n    ...originalTweet,\n    search_results: rankedResults,\n    total_results: parseInt(searchResponse.searchInformation?.totalResults || 0),\n    credible_sources_found: credibleCount,\n    search_status: searchStatus\n  }\n};"
      },
      "name": "3. Verify & Score Sources",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1792,
        -928
      ],
      "id": "3175e4c8-f18b-46ea-ba2d-ab76e238a490"
    },
    {
      "parameters": {
        "url": "https://www.googleapis.com/customsearch/v1",
        "sendQuery": true,
        "queryParameters": {
          "parameters": [
            {
              "name": "key",
              "value": "AIzaSyBCm6e_2I1SN1IZyfUNWv9GgV3eIjFnyUE"
            },
            {
              "name": "cx",
              "value": "a16574f588c3a47df"
            },
            {
              "name": "q",
              "value": "={{ $json.search_query }}"
            },
            {
              "name": "num",
              "value": "10"
            }
          ]
        },
        "options": {}
      },
      "name": "2. Search Google1",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        1488,
        -928
      ],
      "id": "e1032e58-2a4d-48ce-b1a1-e14727b0ef19"
    },
    {
      "parameters": {
        "jsCode": "// Get all items from previous nodes\nconst allItems = $input.all();\nconsole.log('=== MERGING DATA ===');\nconsole.log('Total items received:', allItems.length);\n\n// Find tweet data (the one with tweetText + accountData)\nlet tweetData = {};\nfor (let item of allItems) {\n  if (item.json.tweetText && item.json.accountData) {\n    tweetData = item.json;\n    console.log('Found tweet data');\n    break;\n  }\n}\n\n// Find ANY item that has search_results (even if empty or from google_enrichment)\nlet searchData = {\n  search_results: [],\n  total_results: 0,\n  credible_sources_found: 0,\n  search_status: 'NOT_RUN'\n};\n\nfor (let item of allItems) {\n  // Case 1: Old format (direct search_results)\n  if (item.json.search_results !== undefined) {\n    searchData = {\n      search_results: item.json.search_results || [],\n      total_results: item.json.total_results || 0,\n      credible_sources_found: item.json.credible_sources_found || 0,\n      search_status: item.json.search_status || 'NOT_RUN'\n    };\n    console.log('Found old-style search data');\n    break;\n  }\n\n  // Case 2: New format from universal verify node (google_enrichment)\n  if (item.json.google_enrichment) {\n    const ge = item.json.google_enrichment;\n    searchData = {\n      search_results: ge.top_results || [],\n      total_results: ge.results_count || ge.top_results?.length || 0,\n      credible_sources_found: ge.tier1_sources_found || ge.tier1_count || 0,\n      search_status: ge.verification_status ? 'COMPLETED' : 'FAILED'\n    };\n    console.log('Found new google_enrichment data');\n    break;\n  }\n}\n\n// Merge everything into ONE object (exact same structure as before)\nconst mergedData = {\n  // Tweet content\n  tweetText: tweetData.tweetText,\n  tweetSource: tweetData.tweetSource,\n  sourceType: tweetData.sourceType,\n\n  // Tweet metadata\n  tweetMetadata: tweetData.tweetMetadata || {},\n\n  // Account data\n  accountData: tweetData.accountData || {},\n\n  // Tweet identifiers\n  tweet_id: tweetData.tweet_id || tweetData.tweetMetadata?.tweet_id,\n  tweet_url: tweetData.tweet_url || tweetData.tweetMetadata?.tweet_url,\n  virality_score: tweetData.virality_score || tweetData.tweetMetadata?.virality_score,\n  engagement: tweetData.engagement || tweetData.tweetMetadata?.engagement,\n  author: tweetData.author || tweetData.tweetMetadata?.author,\n\n  // Search results â€” now works with BOTH old and new flows\n  search_results: searchData.search_results,\n  total_results: searchData.total_results,\n  credible_sources_found: searchData.credible_sources_found,\n  search_status: searchData.search_status\n};\n\nconsole.log('Merge complete');\nconsole.log('Credible sources:', mergedData.credible_sources_found);\nconsole.log('Search status:', mergedData.search_status);\n\nreturn { json: mergedData };"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2288,
        -848
      ],
      "id": "e85231c0-bd49-4d40-98d0-24b9aacd0ea4",
      "name": "Merge input & web search"
    }
  ],
  "pinData": {},
  "connections": {
    "Parse Input Data": {
      "main": [
        [
          {
            "node": "Agent 2 - Credibility",
            "type": "main",
            "index": 0
          },
          {
            "node": "Agent 3 - Twitter Check",
            "type": "main",
            "index": 0
          },
          {
            "node": "1. Build Smart Search Query",
            "type": "main",
            "index": 0
          },
          {
            "node": "merge Tweet with web Search",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Agent 1 - Fact Check": {
      "main": [
        [
          {
            "node": "Check Agent 1 Confidence",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Agent 2 - Credibility": {
      "main": [
        [
          {
            "node": "Check Agent 2 Confidence",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Agent 3 - Twitter Check": {
      "main": [
        [
          {
            "node": "Merge with Agent 3",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Check Agent 1 Confidence": {
      "main": [
        [
          {
            "node": "Agent 1B - Fact Check Backup",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Merge Agents 1 & 2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Check Agent 2 Confidence": {
      "main": [
        [
          {
            "node": "Agent 2B - Credibility Backup",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Merge Agents 1 & 2",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Agent 1B - Fact Check Backup": {
      "main": [
        [
          {
            "node": "Code in JavaScript",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Agent 2B - Credibility Backup": {
      "main": [
        [
          {
            "node": "Merge Agent 2 Results",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge Agent 2 Results": {
      "main": [
        [
          {
            "node": "Merge Agents 1 & 2",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Merge Agents 1 & 2": {
      "main": [
        [
          {
            "node": "Merge with Agent 3",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge with Agent 3": {
      "main": [
        [
          {
            "node": "Combine for Agent 4",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Agent 4 - Decision": {
      "main": [
        [
          {
            "node": "Format for Google Sheets",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Format for Google Sheets": {
      "main": [
        [
          {
            "node": "Append row in sheet",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Google Gemini Chat Model2": {
      "ai_languageModel": [
        [
          {
            "node": "Agent 2 - Credibility",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Groq Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "Agent 1B - Fact Check Backup",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Google Gemini Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "Agent 4 - Decision",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Google Gemini Chat Model3": {
      "ai_languageModel": [
        [
          {
            "node": "AI Agent - Supabase Formatter",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Get row from Dataset (Supabase)": {
      "ai_tool": [
        [
          {
            "node": "AI Agent - Supabase Formatter",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "WhatsApp Trigger": {
      "main": [
        [
          {
            "node": "WhatsApp Input Parser",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "WhatsApp Input Parser": {
      "main": [
        [
          {
            "node": "AI Agent - Supabase Formatter",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "AI Agent - Supabase Formatter": {
      "main": [
        [
          {
            "node": "Merge Dataset & Twitter Inputs",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge Dataset & Twitter Inputs": {
      "main": [
        [
          {
            "node": "Format Input Data",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Format Input Data": {
      "main": [
        [
          {
            "node": "Parse Input Data",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Combine for Agent 4": {
      "main": [
        [
          {
            "node": "Agent 4 - Decision",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Every 4 Hours": {
      "main": [
        [
          {
            "node": "Search Viral News Tweets",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Manual Trigger": {
      "main": [
        [
          {
            "node": "Search Viral News Tweets",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Search Viral News Tweets": {
      "main": [
        [
          {
            "node": "Get Top N Most Viral",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Get Top N Most Viral": {
      "main": [
        [
          {
            "node": "Enrich Twitter Account Data",
            "type": "main",
            "index": 0
          },
          {
            "node": "Merge2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Enrich Twitter Account Data": {
      "main": [
        [
          {
            "node": "Merge Enriched Data",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge Enriched Data": {
      "main": [
        [
          {
            "node": "Merge2",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Merge2": {
      "main": [
        [
          {
            "node": "Build Final Enriched Data",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Build Final Enriched Data": {
      "main": [
        [
          {
            "node": "Format Input Data",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Google Gemini Chat Model4": {
      "ai_languageModel": [
        [
          {
            "node": "Agent 1 - Fact Check",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Groq Chat Model1": {
      "ai_languageModel": [
        [
          {
            "node": "Agent 2B - Credibility Backup",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Google Gemini Chat Model5": {
      "ai_languageModel": [
        [
          {
            "node": "Agent 3 - Twitter Check",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Code in JavaScript": {
      "main": [
        [
          {
            "node": "Merge Agents 1 & 2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "merge Tweet with web Search": {
      "main": [
        [
          {
            "node": "Merge input & web search",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "1. Build Smart Search Query": {
      "main": [
        [
          {
            "node": "2. Search Google1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "2. Search Google1": {
      "main": [
        [
          {
            "node": "3. Verify & Score Sources",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "3. Verify & Score Sources": {
      "main": [
        [
          {
            "node": "merge Tweet with web Search",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge input & web search": {
      "main": [
        [
          {
            "node": "Agent 1 - Fact Check",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": false,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "7b310ac6-7845-4776-bd3e-c2e13d44dedd",
  "meta": {
    "templateCredsSetupCompleted": true,
    "instanceId": "121d8e9b68760b992e165904fd6888a7f1a58413d4a67cf93ef67eae09ef6b3b"
  },
  "id": "kmJ12WwvvTAS7wFS",
  "tags": []
}