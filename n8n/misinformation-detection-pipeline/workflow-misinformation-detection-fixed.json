{
  "name": "Misinformation_Detection-Updated-latest-not-in-github-14.12-latest",
  "nodes": [
    {
      "parameters": {
        "options": {}
      },
      "id": "7c122f5a-6924-4e6b-a455-79d21eed97a8",
      "name": "Parse Input Data",
      "type": "n8n-nodes-base.set",
      "typeVersion": 3,
      "position": [
        912,
        -400
      ]
    },
    {
      "parameters": {
        "promptType": "=define",
        "text": "=â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nAGENT 1A: PRIMARY FACT-CHECKING AGENT v3.0\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nYou are Agent 1A in a misinformation detection system. Your job is to verify factual claims by checking credible news sources.\n\n**Core Principles:** \n1. When in doubt â†’ UNVERIFIABLE (not LEGITIMATE)\n2. UNVERIFIED â‰  LEGITIMATE\n3. Safety always overrides other considerations\n4. Accurate facts â‰  Neutral presentation\n\nCURRENT DATE: {{ $now.format('MMMM D, YYYY') }}\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nğŸ“Š INPUT DATA\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nTWEET CONTENT\nText: {{ $json.tweetText }}\nPosted: {{ $json.tweetMetadata.created_at }}\nAuthor: {{ $json.tweetMetadata.author }}\n\nACCOUNT INFO\nUsername: {{ $json.accountData.username }}\nDescription: {{ $json.accountData.description }}\nVerified: {{ $json.accountData.verified }}\nFollowers: {{ $json.accountData.followers }}\n\nPRE-FETCHED SEARCH RESULTS\nSearch Status: {{ $json.search_status }}\nCredible Sources Found: {{ $json.credible_sources_found }}\nResults: {{ JSON.stringify($json.search_results, null, 2) }}\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nâš ï¸ STEP 0: SAFETY & PARODY CHECK (DO FIRST)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nCheck content for safety concerns BEFORE fact-checking:\n\nA. HATE CONTENT / TARGETING\nâ–¡ Targets religious/ethnic/protected groups\nâ–¡ Describes offensive acts against groups\nâ–¡ Uses dehumanizing language\nâ–¡ Describes desecration of religious symbols\n\nB. INCITEMENT / COORDINATION\nâ–¡ Provides specific location of target (address)\nâ–¡ Provides specific time for action\nâ–¡ Calls for action against individuals/groups\nâ–¡ Uses violence-suggesting language\n\nC. PARODY DISCLOSURE\nâ–¡ Account bio contains \"parody\" or \"satire\"\nâ–¡ Bio states \"not affiliated\" or similar disclaimer\n\nDECISION:\n- 2+ boxes in A or B â†’ HATE_CONTENT (continue to document claims)\n- Boxes in C + false claims â†’ SATIRE (continue to verify)\n- No flags â†’ Continue to normal fact-checking\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nğŸ“‹ STEP 1: EXTRACT CLAIMS\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nIdentify specific factual claims:\n- WHO: _______________\n- WHAT: _______________\n- WHEN: _______________\n- HOW MUCH: _______________\n\nTopic: Sports | Politics | Health | Business | Other\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nğŸ§  STEP 2: SEMANTIC ANALYSIS\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nCRITICAL: Distinguish COMPLETED ACTIONS from INTEREST/SPECULATION\n\nCONFIRMS completion:\n- \"signs\", \"announces\", \"agrees to\", \"completes\", \"finalizes\"\n- Past tense or definitive present tense\n\nShows interest only (NOT confirmation):\n- \"interested in\", \"pursuing\", \"targets\", \"in talks with\"\n- \"eyeing\", \"wants\", \"linked with\"\n\nShows speculation (NOT confirmation):\n- \"predictions\", \"possible\", \"could\", \"likely\", \"rumors\"\n- \"expected to\", \"may\", \"might\"\n\nFor each search result:\n- Does title confirm COMPLETED action? YES/NO\n- Or just shows interest/speculation? YES/NO\n\nCount results that CONFIRM: _____\n\nIF count = 0 â†’ Claims are UNVERIFIED â†’ Classification = UNVERIFIABLE\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nğŸ“‹ STEP 3: VERIFICATION DECISION\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nIF pre-fetched results CONFIRM claims:\nâ†’ Proceed to classification\nâ†’ Cite REAL URLs from search_results\n\nIF results show only interest/speculation:\nâ†’ Try additional web_search\nâ†’ Look for sources confirming COMPLETED action\nâ†’ If still unconfirmed â†’ UNVERIFIABLE\n\nIF search returns 0 results:\nâ†’ Classification = UNVERIFIABLE\nâ†’ Sources = []\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nğŸš¨ CRITICAL RULES\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nRULE 1: Only cite URLs from search_results\n- NEVER fabricate URLs\n- Leave sources [] empty if nothing confirms\n\nRULE 2: Interest â‰  Confirmation\n- \"Interested\" â‰  \"Signed\"\n- \"Pursuing\" â‰  \"Completed\"\n\nRULE 3: UNVERIFIED â‰  LEGITIMATE\n- Can't verify â†’ UNVERIFIABLE (score 50)\n- NOT â†’ LEGITIMATE (score 100)\n\nRULE 4: Verified account â‰  Automatic truth\n- Still must verify with news sources\n\nRULE 5: When uncertain â†’ UNVERIFIABLE\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nğŸ“‹ STEP 4: CLASSIFY CONTENT\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nPRIORITY 1: Safety Classification (from Step 0)\nIF hate content detected â†’ HATE_CONTENT (skip to Step 6)\nIF parody disclosed + false claims â†’ SATIRE (continue for scoring)\n\nPRIORITY 2: Fact Verification\n1. Sources confirm COMPLETED action? NO â†’ UNVERIFIABLE\n2. Sources credible for topic? NO â†’ UNVERIFIABLE  \n3. Sources confirm SPECIFIC details? NO â†’ UNVERIFIABLE\n4. Evidence of deception? YES â†’ MISINFORMATION/DISINFORMATION\n5. Continue to Step 5\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nğŸ“‹ STEP 5: CHECK FOR BIASED PRESENTATION\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nIF facts are verified as TRUE, check presentation style:\n\nBIAS INDICATORS - Count how many apply:\n\nPARTISAN CHEERLEADING\nâ–¡ Encourages/celebrates one political side\nâ–¡ Uses \"we/us/our\" partisan framing\nâ–¡ Advocacy for political figures/positions\n\nEMOTIONAL MANIPULATION\nâ–¡ Emotional appeals unrelated to facts\nâ–¡ Inflammatory language beyond reporting\nâ–¡ Strategic use of emojis/symbols for political messaging\n\nINFORMAL/UNPROFESSIONAL TONE\nâ–¡ Casual descriptions of officials or events\nâ–¡ Profanity or crude language\nâ–¡ Personal commentary mixed with facts\n\nADVOCACY JOURNALISM\nâ–¡ Explicitly advocates for action\nâ–¡ Frames sides as heroes/villains\nâ–¡ Omits context contradicting preferred narrative\n\nPARTISAN FRAMING\nâ–¡ Uses loaded language (\"conquer\", \"invade\", \"tyrant\")\nâ–¡ Selective emphasis supporting one side\nâ–¡ Presents opinion as fact\n\nSCORING:\n0-1 indicators â†’ Neutral presentation â†’ LEGITIMATE\n2-3 indicators â†’ Moderate bias â†’ BIASED_BUT_FACTUAL\n4+ indicators â†’ Heavy bias â†’ PROPAGANDA\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nğŸ“‹ STEP 5A: HANDLE PARTIAL VERIFICATION (CRITICAL)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n**IMPORTANT: When some claims are TRUE and others are UNVERIFIED/FALSE**\n\nThis commonly happens with breaking news where:\n- Core event is TRUE (verified by credible sources)\n- But specific details are UNVERIFIED (numbers, descriptions, etc.)\n\nDECISION TREE FOR MIXED VERIFICATION:\n\n1. Identify the PRIMARY/CORE claim (the main point)\n2. Identify SECONDARY claims (specific details, numbers, descriptions)\n\nPRIMARY CLAIM:\n- What is the main event/action being reported?\n- Is this verified? YES/NO\n\nSECONDARY CLAIMS:\n- What specific details are added?\n- Are these verified? YES/NO\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nCLASSIFICATION LOGIC FOR PARTIAL VERIFICATION\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nSCENARIO 1: Core TRUE + Details UNVERIFIED\nExample: \"Active shooter at Brown, 6 casualties, masked gunman\"\n- Core: \"Active shooter at Brown\" = TRUE âœ“\n- Detail: \"6 casualties\" = UNVERIFIED âœ—\n- Detail: \"masked gunman\" = UNVERIFIED âœ—\n\nâ†’ Classification: BIASED_BUT_FACTUAL\nâ†’ Reasoning: Core event is TRUE, but sensationalized with unverified details\nâ†’ fact_score: 60-75 (weighted: core event carries most weight)\n\nSCENARIO 2: Core TRUE + Details FALSE\nExample: \"Car accident on I-95, driver drunk and fled scene\"\n- Core: \"Car accident on I-95\" = TRUE âœ“\n- Detail: \"driver drunk\" = FALSE (toxicology negative) âœ—\n- Detail: \"fled scene\" = FALSE (stayed at scene) âœ—\n\nâ†’ Classification: BIASED_BUT_FACTUAL or MISINFORMATION\nâ†’ If false details are minor: BIASED_BUT_FACTUAL\nâ†’ If false details substantially change story: MISINFORMATION\nâ†’ fact_score: 40-70 depending on severity\n\nSCENARIO 3: Core FALSE\nExample: \"Active shooter at Harvard\"\n- Core: \"Active shooter at Harvard\" = FALSE âœ—\n- No shooting happened at all\n\nâ†’ Classification: MISINFORMATION\nâ†’ fact_score: 0-30\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSCORING FOR PARTIAL VERIFICATION\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nUse WEIGHTED SCORING:\n\nStep 1: Assign weights to claims by importance\n- Primary/core claim: 60-70% weight\n- Secondary details: 30-40% weight (divided among them)\n\nStep 2: Score each claim\n- TRUE = 100 points\n- PARTIALLY_TRUE = 50 points\n- UNVERIFIED = 0 points (neutral, not negative)\n- FALSE = 0 points\n\nStep 3: Calculate weighted average\n\nEXAMPLE - Brown University Tweet:\nClaims:\n1. \"Active shooter at Brown\" (PRIMARY, 70% weight)\n   Status: TRUE\n   Points: 100 Ã— 0.70 = 70\n\n2. \"6 casualties\" (SECONDARY, 20% weight)\n   Status: UNVERIFIED\n   Points: 0 Ã— 0.20 = 0\n\n3. \"Masked gunman at large\" (SECONDARY, 10% weight)\n   Status: UNVERIFIED\n   Points: 0 Ã— 0.10 = 0\n\nTOTAL: 70 points âœ…\n\nClassification: BIASED_BUT_FACTUAL\n(Core is true, details sensationalized)\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nCRITICAL DISTINCTION\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n**MISINFORMATION requires:**\n- Primary/core claim is FALSE\n- The main event didn't happen\n- Fundamentally untrue\n\n**MISINFORMATION does NOT mean:**\n- \"Some details are unverified\"\n- \"Numbers are exaggerated\"\n- \"Description is unconfirmed\"\n\n**If core is TRUE but details are wrong:**\nâ†’ BIASED_BUT_FACTUAL (not MISINFORMATION)\nâ†’ Score based on what's verified vs unverified\nâ†’ Higher deceptiveness score for sensationalizing\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nPRE-CLASSIFICATION CHECK\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nBefore classifying as MISINFORMATION, ask:\n\nâ–¡ Is the PRIMARY/CORE claim FALSE?\nâ–¡ Did the main event NOT happen?\nâ–¡ Are sources saying it's completely untrue?\n\nIF you checked all boxes â†’ MISINFORMATION âœ“\n\nIF you only checked:\nâ–¡ Some details are unverified\nâ–¡ Numbers don't match\nâ–¡ Descriptions aren't confirmed\n\nâ†’ NOT MISINFORMATION\nâ†’ Likely BIASED_BUT_FACTUAL\nâ†’ Score 60-75 range\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nNow continue to Step 6 (Final Classification) with this analysis.\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nğŸ“‹ STEP 6: FINAL CLASSIFICATION\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nLEGITIMATE\n- Facts verified by credible sources\n- Neutral, professional presentation\n- Score: 90-100, deceptiveness: 0-20\n\nBIASED_BUT_FACTUAL\n- Core facts are TRUE\n- Presentation is partisan/biased (2-3 indicators)\n- Score: 75-85, deceptiveness: 40-60\n\nPROPAGANDA\n- Facts may be true\n- Heavy manipulation/bias (4+ indicators)\n- Score: 60-80, deceptiveness: 60-80\n\nUNVERIFIABLE\n- Cannot confirm claims from credible sources\n- Score: 50 (neutral), deceptiveness: varies\n\nMISINFORMATION\n- Claims are false, likely unintentional\n- Score: 0-40\n\nDISINFORMATION\n- Claims are false, intentionally deceptive\n- Score: 0-40\n\nSATIRE\n- Disclosed parody account\n- Claims intentionally false for comedy/commentary\n- Score: 0, deceptiveness: 40-60\n\nHATE_CONTENT\n- Targets protected groups\n- Describes offensive acts, could incite harm\n- Score: N/A, deceptiveness: 85-95\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nğŸ›‘ PRE-OUTPUT VERIFICATION\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nSTOP! Answer these before generating JSON:\n\nâ–¡ Did I check for safety issues in Step 0?\nâ–¡ Did I check for bias indicators in Step 5?\nâ–¡ If sources don't confirm â†’ Did I mark UNVERIFIABLE (not LEGITIMATE)?\nâ–¡ If I couldn't verify â†’ Is score = 50 (not 100)?\nâ–¡ Am I citing ONLY real URLs from search_results?\nâ–¡ If facts are true but biased â†’ Did I use BIASED_BUT_FACTUAL?\n\nIF ANY UNCHECKED â†’ GO BACK AND FIX\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nâš ï¸ OUTPUT FORMAT\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nReturn ONLY valid JSON (no markdown):\n\n{\n  \"classification\": \"LEGITIMATE|BIASED_BUT_FACTUAL|PROPAGANDA|MISINFORMATION|DISINFORMATION|SATIRE|UNVERIFIABLE|HATE_CONTENT\",\n  \"fact_accuracy_score\": 0-100,\n  \"deceptiveness_score\": 0-100,\n  \"appears_intentional\": true/false,\n  \"verified_claims\": [\n    {\n      \"claim\": \"exact claim text\",\n      \"status\": \"TRUE|FALSE|PARTIALLY_TRUE|UNVERIFIED\",\n      \"evidence\": \"specific findings\",\n      \"sources\": [\"real URLs only or []\"],\n      \"context_issue\": \"OMISSION|FALSE_CAUSATION|MISLEADING_FRAMING|TARGETING|PARTISAN_BIAS|NONE\"\n    }\n  ],\n  \"false_news_patterns_detected\": [],\n  \"key_omissions\": [],\n  \"manipulation_techniques\": [\"EMOTIONAL_APPEAL\", \"PARTISAN_CHEERLEADING\", \"INFORMAL_FRAMING\", \"ADVOCACY_JOURNALISM\", \"LOADED_LANGUAGE\"],\n  \"confidence\": \"high|medium|low\",\n  \"overall_assessment\": \"Explain: (1) Safety flags if any, (2) What sources showed, (3) Bias indicators found, (4) Why this classification\",\n  \"recommendation\": \"FLAG_FOR_SAFETY_REVIEW|FLAG_AS_FALSE_NEWS|LABEL_AS_SATIRE|LABEL_AS_BIASED|REQUIRES_MORE_INVESTIGATION|NO_ACTION_NEEDED\"\n}\n\nSCORE GUIDELINES:\nFact Accuracy: 90-100 (verified) | 50 (unverifiable) | 0-40 (false)\nDeceptiveness: 0-20 (neutral) | 40-60 (bias/satire) | 60-80 (propaganda) | 85-95 (hate)\nConfidence: high (verified/clear violation) | medium (some uncertainty) | low (unverifiable)\n\nBEGIN ANALYSIS. Return ONLY JSON.",
        "options": {
          "systemMessage": "You are a fact-checker with web_search. USE web_search for every claim. Return ONLY valid JSON, no markdown.",
          "maxIterations": 5
        }
      },
      "id": "1e5c35b0-8fb7-4929-a93a-bd1e5c6fd2ab",
      "name": "Agent 1 - Fact Check",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.6,
      "position": [
        2512,
        -848
      ],
      "executeOnce": false
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=ROLE: Source Credibility Analyst\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nğŸš¨ CRITICAL: MANDATORY EXTERNAL VERIFICATION\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nYOU MUST USE WEB_SEARCH TO VERIFY SOURCE REPUTATION.\n\nsources_checked CANNOT be empty for Twitter accounts.\nIf you submit output with empty sources_checked for Twitter, it will be REJECTED.\n\nThis is NOT optional - it is REQUIRED.\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nINPUT DATA\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nCONTENT: {{ $json.tweetText }}\n\nSOURCE INFORMATION:\n- Source Type: {{ $json.sourceType }}\n- Tweet Source: {{ $json.tweetSource }}\n- Author: {{ $json.author }}\n- Account Data: {{ JSON.stringify($json.accountData) }}\n- Title: {{ $json.title }}\n- Subject: {{ $json.subject }}\n\nMISSION: Assess source reliability through BOTH internal metrics AND external verification.\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 1: IDENTIFY SCENARIO\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nCheck \"Source Type\" field:\n\nIF sourceType = \"twitter\":\n  â†’ Scenario: TWITTER\n  â†’ Use accountData for analysis\n  â†’ MANDATORY: Search external reputation\n  â†’ Analyze bot behavior\n  â†’ Check verification status\n\nIF sourceType = \"dataset\":\n  â†’ Scenario: DATASET\n  â†’ Extract publisher from text\n  â†’ MANDATORY: Search publisher credibility\n  â†’ Skip bot detection\n\nIF sourceType = \"news\":\n  â†’ Scenario: NEWS\n  â†’ Evaluate domain credibility\n  â†’ MANDATORY: Search domain reputation\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 2A: TWITTER ANALYSIS\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nUse accountData:\n- username: {{ $json.accountData.username }}\n- verified: {{ $json.accountData.verified }}\n- followers: {{ $json.accountData.followers }}\n- following: {{ $json.accountData.following }}\n- account_age_days: {{ $json.accountData.account_age_days }}\n- tweets_per_day: {{ $json.accountData.tweets_per_day }}\n- profile_completeness_score: {{ $json.accountData.profile_completeness_score }}\n- description: {{ $json.accountData.description }}\n\n\n1. CHECK IF VERIFIED GOVERNMENT OFFICIAL OR ORGANIZATION:\n\n   TIER 0: GOVERNMENT OFFICIALS & AGENCIES (HIGHEST CREDIBILITY)\n   \n   Government officials and agencies are PRIMARY SOURCES for government \n   information and official positions. Political bias is EXPECTED and \n   does NOT reduce credibility - they are authoritative sources.\n   \n   A. Check if ELECTED OFFICIAL:\n   \n   Bio keywords that indicate elected government official:\n   - \"President\", \"Prime Minister\", \"Premier\"\n   - \"Vice President\", \"Deputy Prime Minister\"\n   - \"Minister\", \"Secretary\" (Cabinet level)\n   - \"Senator\", \"Member of Parliament\", \"MP\", \"Congressman\", \"Representative\"\n   - \"Governor\", \"Mayor\" (of major city/state)\n   - \"Chancellor\" (Germany, Austria)\n   - \"Premier\" (Canadian provinces, Australian states)\n   \n   Additional signals:\n   - verified = TRUE\n   - followers > 50,000 (typical for major officials)\n   - bio mentions government title\n   - account_age > 365 days (established)\n   \n   IF bio contains ANY government title keywords + verified:\n     â†’ rating = \"OFFICIAL_GOV\"\n     â†’ score = 95-98\n     â†’ source_type = \"official_government\"\n     â†’ red_flags = [] (DO NOT flag political bias!)\n     â†’ Still search to confirm identity, but DO NOT penalize for partisanship\n     â†’ SKIP partisan penalty adjustments\n     â†’ Proceed to bot analysis\n   \n   B. Check if GOVERNMENT AGENCY:\n   \n   Agency indicators:\n   - Bio mentions: \"Official account\", \"Ministry of\", \"Department of\"\n   - Username patterns: @[CountryCode]_[Agency], @[Agency]Gov\n   - Examples: @CDCgov, @WHO, @ECDC_EU, @MoHFW_INDIA\n   - UN bodies: UNESCO, UNICEF, UNHCR, etc.\n   - Space agencies: NASA, ESA, JAXA, ISRO, etc.\n   \n   IF verified + official agency + followers > 10,000:\n     â†’ rating = \"OFFICIAL_GOV\"\n     â†’ score = 95\n     â†’ source_type = \"official_government\"\n     â†’ Skip partisan penalties\n     â†’ Proceed to bot analysis\n\n1. CHECK IF VERIFIED GOVERNMENT OFFICIAL OR ORGANIZATION:\n\n   TIER 0: GOVERNMENT OFFICIALS & AGENCIES (HIGHEST CREDIBILITY)\n   \n   Government officials and agencies are PRIMARY SOURCES for government \n   information and official positions. Political bias is EXPECTED and \n   does NOT reduce credibility - they are authoritative sources.\n   \n   A. Check if ELECTED OFFICIAL:\n   \n   Bio keywords that indicate elected government official:\n   - \"President\", \"Prime Minister\", \"Premier\"\n   - \"Vice President\", \"Deputy Prime Minister\"\n   - \"Minister\", \"Secretary\" (Cabinet level)\n   - \"Senator\", \"Member of Parliament\", \"MP\", \"Congressman\", \"Representative\"\n   - \"Governor\", \"Mayor\" (of major city/state)\n   - \"Chancellor\" (Germany, Austria)\n   - \"Premier\" (Canadian provinces, Australian states)\n   \n   Additional signals:\n   - verified = TRUE\n   - followers > 50,000 (typical for major officials)\n   - bio mentions government title\n   - account_age > 365 days (established)\n   \n   IF bio contains ANY government title keywords + verified:\n     â†’ rating = \"OFFICIAL_GOV\"\n     â†’ score = 95-98\n     â†’ source_type = \"official_government\"\n     â†’ red_flags = [] (DO NOT flag political bias!)\n     â†’ Still search to confirm identity, but DO NOT penalize for partisanship\n     â†’ SKIP partisan penalty adjustments\n     â†’ Proceed to bot analysis\n   \n   B. Check if GOVERNMENT AGENCY:\n   \n   Agency indicators:\n   - Bio mentions: \"Official account\", \"Ministry of\", \"Department of\"\n   - Username patterns: @[CountryCode]_[Agency], @[Agency]Gov\n   - Examples: @CDCgov, @WHO, @ECDC_EU, @MoHFW_INDIA\n   - UN bodies: UNESCO, UNICEF, UNHCR, etc.\n   - Space agencies: NASA, ESA, JAXA, ISRO, etc.\n   \n   IF verified + official agency + followers > 10,000:\n     â†’ rating = \"OFFICIAL_GOV\"\n     â†’ score = 95\n     â†’ source_type = \"official_government\"\n     â†’ Skip partisan penalties\n     â†’ Proceed to bot analysis\n\n2. CHECK IF VERIFIED OFFICIAL ORGANIZATION (NON-GOVERNMENT):\n\n   Organizations with official authority in their domain:\n   - Major news agencies: Reuters, AP, BBC, AFP (official accounts)\n   - Universities: Verified educational institutions\n   - Major NGOs: Red Cross, Amnesty International, etc.\n   - Professional bodies: Medical associations, bar associations\n   \n   IF verified = TRUE + official non-gov org + followers > 100K:\n     â†’ rating = \"HIGH\"\n     â†’ score = 90-95\n     â†’ source_type = \"official_org\"\n     â†’ Still MUST search to confirm reputation\n     â†’ THEN skip to bot analysis\n\n3. MANDATORY EXTERNAL VERIFICATION (For Non-Government Sources):\n\n   IF source is NOT identified as OFFICIAL_GOV above:\n   \n   You MUST perform these searches:\n   \n   Search 1: web_search(\"[username] Twitter credibility\")\n   Search 2: web_search(\"[username] bias fact check\")\n   Search 3 (if needed): web_search(\"[username] misinformation\")\n   \n   Record ALL searches in sources_checked, even if no results.\n   \n   Evaluate findings:\n   - Known for misinformation? â†’ VERY_LOW rating\n   - Partisan commentator (NOT elected official)? â†’ LOW-MEDIUM rating\n   - Generally reliable journalist? â†’ MEDIUM-HIGH rating\n   - Established credible outlet? â†’ HIGH rating\n   \n   CRITICAL DISTINCTION:\n   \n   ELECTED OFFICIALS (VP, PM, Ministers):\n   - Political bias is EXPECTED (that's their job!)\n   - DO NOT apply partisan penalties\n   - They are PRIMARY SOURCES for government positions\n   - Score remains 95-98\n   \n   PARTISAN COMMENTATORS (pundits, activists):\n   - Political bias reduces credibility\n   - Apply partisan penalties\n   - They are SECONDARY SOURCES with agenda\n   - Score 40-70 depending on reliability\n\n4. CALCULATE SOURCE SCORE:\n\n   Base score from metrics:\n   - Official government (elected/agency) = 95-98 (NO partisan penalty)\n   - Official non-gov org = 90-95\n   - Verified + 1M+ followers = 80-90\n   - Verified + 100K+ followers = 70-80\n   - Verified + 10K+ followers = 60-70\n   - Unverified but established (5+ years, 10K+ followers) = 50-65\n   - Unverified, new or low followers = 30-50\n   \n   ADJUST based on external verification (NON-GOVERNMENT sources only):\n   - Known misinformation source: -30 points\n   - Partisan commentator (not elected official): -10 to -20 points\n   - Generally reliable journalist: +10 points\n   - Established credible outlet: +15 points\n   \n   DO NOT ADJUST for political bias if source = OFFICIAL_GOV\n\nCHECK FOR RED FLAGS:\n\nIF source_type = \"government_official\" OR \"government_agency\":\n   Only flag:\n   - tweets_per_day > 50 (unusual for official account)\n   - Profile incomplete (<4/7)\n   - Account age < 90 days (suspicious for official)\n   - Bot-like spam patterns\n   \n   DO NOT flag:\n   - Political bias (expected and appropriate)\n   - Partisan language (part of their role)\n\nIF source_type = other:\n   Flag all concerns:\n   - tweets_per_day > 50\n   - Political bias indicators in bio\n   - Known misinformation\n   - New account + high activity\n   - Spam patterns\n   - Profile incomplete\n\n6. DETERMINE RATING:\n\n   After adjustments:\n   - 85-100 = HIGH\n   - 65-84 = MEDIUM\n   - 45-64 = LOW\n   - 0-44 = VERY_LOW\n\n7. BOT ANALYSIS:\n\n   Bot indicators:\n   - Account age < 30 days + tweets_per_day > 50\n   - Following > followers Ã— 10\n   - Profile incomplete (< 3/7)\n   - Very high frequency (> 100/day)\n   - tweets_per_day > 50 (moderate concern)\n   \n   Calculate bot_likelihood:\n   - 0-1 indicators = \"HUMAN_LIKELY\"\n   - 2 indicators = \"MODERATE_RISK\"\n   - 3+ indicators = \"HIGH_RISK\"\n   \n   Set bot_likelihood.data_available = true\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 2B: DATASET ANALYSIS\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n1. EXTRACT PUBLISHER from text:\n\n   Look in title, subject, content for:\n   - Domain names (breitbart.com, cnn.com, etc.)\n   - \"Published by [name]\"\n   - \"Source: [publication]\"\n   - Author byline with publication\n   \n   IGNORE:\n   - Photo credits\n   - Social media mentions\n   - Sources cited in article\n\n2. MANDATORY EXTERNAL VERIFICATION:\n\n   IF publisher identified:\n   \n   You MUST search:\n   web_search(\"[publisher] Media Bias Fact Check\")\n   web_search(\"[publisher] credibility rating\")\n   \n   Record searches in sources_checked.\n   \n   Set rating based on findings:\n   - Least Biased / High Factual = HIGH (85-95)\n   - Left/Right / High Factual = MEDIUM (60-80)\n   - Mixed Factual = LOW (35-60)\n   - Questionable Source = VERY_LOW (10-35)\n   \n   IF no publisher identified:\n   \n   Assess content quality:\n   \n   Red flags (note each):\n   - No publication name\n   - No author byline\n   - Vulgar/unprofessional language\n   - Sensational headlines\n   - Multiple grammar/spelling errors\n   - Poor formatting\n   \n   Score based on red flags:\n   - 0-1 flags = 50-60 (LOW/UNKNOWN)\n   - 2-3 flags = 35-50 (LOW)\n   - 4+ flags = 15-35 (VERY_LOW)\n\n3. BOT ANALYSIS:\n\n   bot_likelihood.assessment = \"NOT_APPLICABLE\"\n   bot_likelihood.data_available = false\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 3: CALCULATE OVERALL TRUSTWORTHINESS\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nIF scenario = \"twitter\":\n  IF bot_likelihood = \"HIGH_RISK\":\n    overall_score = source_score Ã— 0.6 (heavy penalty)\n  ELSE IF bot_likelihood = \"MODERATE_RISK\":\n    overall_score = source_score Ã— 0.8 (moderate penalty)\n  ELSE:\n    overall_score = source_score\n\nIF scenario = \"dataset\":\n  overall_score = source_score\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSELF-CHECK BEFORE SUBMITTING\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nCRITICAL CHECKS:\n\nâ–¡ If sourceType = \"twitter\", is sources_checked EMPTY?\n  â†’ If YES, YOU FAILED! Go back and search!\n\nâ–¡ Did I perform at least 2 web_search queries?\n  â†’ If NO, YOU FAILED! Do the searches!\n\nâ–¡ If tweets_per_day > 50, is it in red_flags?\n  â†’ If NO, add it!\n\nâ–¡ Did I check bio for bias indicators (BRICS, partisan language)?\n  â†’ If YES found, did I note in red_flags and adjust score?\n\nâ–¡ Did I record ALL searches in sources_checked?\n  â†’ Include searches even if no results\n\nsources_checked format:\n[\"web_search: [username] Twitter credibility - found [X]\", ...]\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nOUTPUT (JSON only)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n{\n  \"source_credibility\": {\n    \"rating\": \"HIGH|MEDIUM|LOW|UNKNOWN|VERY_LOW\",\n    \"score\": 0-100,\n    \"source_identified\": \"account name or publisher\",\n    \"source_type\": \"official_org|verified_account|established_news|partisan_commentator|blog|unknown\",\n    \"explanation\": \"Rating rationale including external verification results\",\n    \"sources_checked\": [\"REQUIRED: List all web_search queries performed\"],\n    \"red_flags\": [\"List all concerns found\"],\n    \"extraction_method\": \"twitter_account|metadata|content_analysis|web_search\"\n  },\n  \"bot_likelihood\": {\n    \"assessment\": \"HIGH_RISK|MODERATE_RISK|LOW_RISK|HUMAN_LIKELY|NOT_APPLICABLE\",\n    \"data_available\": true/false,\n    \"account_age_days\": number or 0,\n    \"tweets_per_day\": number or 0,\n    \"profile_completeness_score\": \"X/7\" or \"0/7\",\n    \"bot_indicators\": [\"specific indicators found\"],\n    \"confidence\": \"high|medium|low|not_applicable\"\n  },\n  \"overall_trustworthiness_score\": 0-100,\n  \"recommendation\": \"Brief summary with external verification context\",\n  \"scenario\": \"twitter|dataset|news\"\n}\n\nCRITICAL REMINDERS:\n- sources_checked CANNOT be empty for Twitter\n- MUST perform external verification searches\n- Flag tweets_per_day > 50 as red flag\n- Political bias indicators (BRICS, etc.) = red flags\n- Adjust scores based on external reputation\n- Return ONLY valid JSON, no markdown\n\nReturn only JSON.",
        "options": {
          "systemMessage": "You are a source credibility analyst with web_search. USE web_search to check sources. Extract source from article text for datasets. Return ONLY valid JSON, no markdown.",
          "maxIterations": 5
        }
      },
      "id": "6e5adcb9-6750-4b0e-bebc-dd75cb529fd9",
      "name": "Agent 2 - Credibility",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.6,
      "position": [
        2192,
        -384
      ]
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=ROLE: Twitter Account Behavior Analyst\n\nACCOUNT DATA PROVIDED:\n- Username: {{ $json.accountData.username }}\n- Verified: {{ $json.accountData.verified }}\n- Followers: {{ $json.accountData.followers }}\n- Following: {{ $json.accountData.following }}\n- Follower Ratio: {{ $json.accountData.follower_ratio }}\n- Account Age (days): {{ $json.accountData.account_age_days }}\n- Tweets Per Day: {{ $json.accountData.tweets_per_day }}\n- Profile Completeness: {{ $json.accountData.profile_completeness_score }}\n- Total Tweets: {{ $json.accountData.total_tweets }}\n- Has Bio: {{ $json.accountData.has_bio }}\n- Has Location: {{ $json.accountData.has_location }}\n- Has Website: {{ $json.accountData.has_website }}\n- Has Banner: {{ $json.accountData.has_banner }}\n- Created At: {{ $json.accountData.created_at }}\n\nSOURCE TYPE: {{ $json.sourceType }}\n\nMISSION: Analyze Twitter account for bot/suspicious behavior using the EXACT VALUES listed above.\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 1: USE THE VALUES PROVIDED ABOVE (NOT placeholders!)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nThe values above are REAL DATA. Use them directly in your analysis:\n- username = the actual username\n- followers = the actual follower count\n- account_age_days = the actual age in days\n- tweets_per_day = the actual tweet frequency\n- verified = the actual verification status\n- etc.\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 2: HANDLE MISSING DATA\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nIf sourceType â‰  'twitter' OR accountData is empty:\n  â†’ Return NOT_APPLICABLE for all fields\n  â†’ Set data_available = false\n  â†’ Skip all analysis\n\nIf accountData exists but fields are missing/0:\n  â†’ Use available data\n  â†’ Note missing fields\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 2.5: PRIORITY CHECK - VERIFIED OFFICIAL ACCOUNTS\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nBEFORE doing metric analysis, check if this is clearly legitimate:\n\n1. Check \"Verified\" field above â†’ Is it TRUE?\n\n2. Check \"Username\" field â†’ Is it an official organization?\n   \n   OFFICIAL ORGANIZATIONS include:\n   - UN bodies: UNESCO, WHO, UNICEF, UNHCR, UNEP, WFP, etc.\n   - Space agencies: NASA, ESA, JAXA, etc.\n   - Health organizations: CDC, NIH, FDA, etc.\n   - Government accounts: Verified gov/official accounts\n   - Universities: Verified educational institutions\n   - Major media: Verified established news organizations\n   - NGOs: Verified major NGOs (Red Cross, Doctors Without Borders, etc.)\n\n3. Check \"Followers\" field â†’ Is it 100,000+?\n\nIF Verified = TRUE AND Username matches official org AND Followers â‰¥ 100,000:\n  â†’ This is a VERIFIED OFFICIAL ACCOUNT\n  â†’ authenticity_score = 95\n  â†’ bot_probability = \"MINIMAL\"\n  â†’ account_age_risk = \"MINIMAL\"\n  â†’ frequency_risk = \"MINIMAL\" \n     (official accounts can tweet frequently during events/crises)\n  â†’ profile_completeness rating = \"COMPLETE\"\n  â†’ behavioral_red_flags = []\n  â†’ recommendation = \"Verified official organization - human-operated\"\n  â†’ data_available = true\n  â†’ SKIP Step 3 (metric analysis) - go directly to output\n  \nELSE:\n  â†’ Proceed with full metric analysis in Step 3 below\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 3: ANALYZE METRICS (only if NOT verified official account)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nMETRIC 1 - Account Age:\nUse account_age_days from above:\n- <7 days = VERY HIGH RISK (20 points)\n- 7-30 = HIGH RISK (40 points)\n- 31-90 = MODERATE RISK (60 points)\n- 91-365 = LOW RISK (80 points)\n- >365 = MINIMAL RISK (95 points)\n\nMETRIC 2 - Tweet Frequency:\nUse tweets_per_day from above:\n- >100/day = VERY HIGH RISK (20 points)\n- 50-100 = HIGH RISK (40 points)\n- 20-49 = MODERATE RISK (60 points)\n- 10-19 = LOW RISK (80 points)\n- <10 = MINIMAL RISK (95 points)\n\nMETRIC 3 - Profile Completeness:\nUse profile_completeness_score from above (format: \"X/7\"):\n- 6-7 = COMPLETE (95 points, low risk)\n- 4-5 = PARTIAL (70 points, moderate risk)\n- 2-3 = MINIMAL (40 points, high risk)\n- 0-1 = INCOMPLETE (20 points, very high risk)\n\nMETRIC 4 - Follower Ratio:\nUse follower_ratio from above:\n- >10 = Influential (95 points, low risk)\n- 0.1-10 = Balanced (85 points, low risk)\n- <0.1 + following>1000 = Spam pattern (30 points, high risk)\n- >100 + followers<500 = Suspicious (50 points, moderate risk)\n\nMETRIC 5 - Activity Level:\nUse total_tweets and account_age_days from above:\n- High tweets (>10K) + new account (<90 days) = suspicious (40 points)\n- Low tweets (<100) + old account (>1000 days) = inactive/dormant (70 points)\n- Balanced activity = normal (90 points)\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 4: CALCULATE SCORES (only if NOT verified official)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nCalculate authenticity_score as weighted average:\n- Account Age: 25%\n- Tweet Frequency: 20%\n- Profile Completeness: 25%\n- Follower Ratio: 15%\n- Activity Level: 15%\n\nDetermine bot_probability based on authenticity_score:\n- 0-40 = VERY_HIGH\n- 41-55 = HIGH\n- 56-70 = MODERATE\n- 71-85 = LOW\n- 86-100 = MINIMAL\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nOUTPUT (JSON only)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n{\n  \"account_analysis\": {\n    \"handle\": \"@username from data above\",\n    \"account_age_days\": actual number from data,\n    \"account_age_risk\": \"VERY_HIGH|HIGH|MODERATE|LOW|MINIMAL|NOT_APPLICABLE\",\n    \"tweets_per_day\": actual number from data,\n    \"frequency_risk\": \"VERY_HIGH|HIGH|MODERATE|LOW|MINIMAL|NOT_APPLICABLE\",\n    \"profile_completeness\": {\n      \"score\": \"X/7 from data\",\n      \"rating\": \"COMPLETE|PARTIAL|MINIMAL|INCOMPLETE|NOT_APPLICABLE\",\n      \"missing_elements\": [\"list what's missing based on has_bio, has_location, etc.\"]\n    },\n    \"follower_ratio\": actual number from data,\n    \"follower_analysis\": \"describe the ratio and what it means\",\n    \"content_patterns\": {\n      \"repetitive_content\": false,\n      \"original_vs_retweets\": \"estimate based on metrics\",\n      \"suspicious_patterns\": [\"list any patterns found\"]\n    }\n  },\n  \"behavioral_red_flags\": [\"list specific concerns, or empty if verified official\"],\n  \"bot_probability\": \"VERY_HIGH|HIGH|MODERATE|LOW|MINIMAL|NOT_APPLICABLE\",\n  \"authenticity_score\": calculated number 0-100 (or 95 if verified official),\n  \"recommendation\": \"based on analysis\",\n  \"data_available\": true if accountData exists, false if not\n}\n\nCRITICAL REMINDERS:\n- Use ACTUAL VALUES from the data provided at the top\n- Don't use placeholder values like \"@username\" or 0\n- If verified official account detected in Step 2.5, set high scores and skip metrics\n- If data_available = true, all fields must have real values\n- Return ONLY valid JSON, no markdown, no explanations outside JSON\n\nReturn only JSON.",
        "options": {
          "systemMessage": "You are a Twitter account analyst. Return ONLY valid JSON, no markdown. Handle missing data gracefully.",
          "maxIterations": 1
        }
      },
      "id": "3eb4d0a7-bc60-4b4f-8f91-7692b38cd09f",
      "name": "Agent 3 - Twitter Check",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.6,
      "position": [
        2240,
        80
      ]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 1
          },
          "conditions": [
            {
              "id": "low_confidence_check",
              "leftValue": "={{ $json.output }}",
              "rightValue": "\"confidence\": \"low\"",
              "operator": {
                "type": "string",
                "operation": "contains"
              }
            },
            {
              "id": "propaganda_check",
              "leftValue": "={{ $json.output }}",
              "rightValue": "\"classification\": \"PROPAGANDA\"",
              "operator": {
                "type": "string",
                "operation": "contains"
              }
            },
            {
              "id": "mixed_check",
              "leftValue": "={{ $json.output }}",
              "rightValue": "\"deceptiveness_score\": [6-9][0-9]",
              "operator": {
                "type": "string",
                "operation": "regex"
              }
            }
          ],
          "combinator": "or"
        },
        "options": {}
      },
      "id": "62f9d755-a17d-4e23-ae99-e367e8f20852",
      "name": "Check Agent 1 Confidence",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        2864,
        -848
      ]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 1
          },
          "conditions": [
            {
              "id": "low_confidence_check",
              "leftValue": "={{ $json.output }}",
              "rightValue": "\"confidence\": \"low\"",
              "operator": {
                "type": "string",
                "operation": "contains"
              }
            },
            {
              "id": "unknown_source",
              "leftValue": "={{ $json.output }}",
              "rightValue": "\"rating\": \"UNKNOWN\"",
              "operator": {
                "type": "string",
                "operation": "contains"
              }
            },
            {
              "id": "low_score_check",
              "leftValue": "={{ $json.output }}",
              "rightValue": "\"overall_trustworthiness_score\": [0-4]?[0-9]",
              "operator": {
                "type": "string",
                "operation": "regex"
              }
            },
            {
              "id": "ae0fddc2-ba36-42e9-a66a-870f4ef6b0f6",
              "leftValue": "={{ $json.output }}",
              "rightValue": "\"rating\": \"LOW\"",
              "operator": {
                "type": "string",
                "operation": "contains"
              }
            }
          ],
          "combinator": "or"
        },
        "options": {}
      },
      "id": "508e148e-2fa4-4bcb-a8a5-79f156ff0a35",
      "name": "Check Agent 2 Confidence",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        2560,
        -176
      ],
      "notesInFlow": false
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nAGENT 1B: BACKUP FACT-CHECKER & VALIDATOR v3.0\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nYou are Agent 1B, the backup validator. Your role is to:\n1. Independently verify claims\n2. Catch Agent 1A's errors\n3. Validate classifications\n4. Check for missed safety/bias issues\n\n**Core Principles:**\n1. Safety checks first\n2. UNVERIFIED â‰  LEGITIMATE\n3. Accurate facts â‰  Neutral presentation\n4. Don't rubber-stamp - challenge Agent 1A\n\nCURRENT DATE: {{ $now.format('MMMM D, YYYY') }}\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nğŸ“Š INPUT DATA\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nINPUT 1: Original Tweet & Search Results (same as Agent 1A)\n\nTWEET CONTENT\nText: {{ $('Merge input & web search').item.json.tweetText }}\nAuthor: {{ $('Merge input & web search').item.json.tweetMetadata.author }}\n\nACCOUNT INFO\nUsername: {{ $('Merge input & web search').item.json.accountData.username }}\nDescription: {{ $('Merge input & web search').item.json.accountData.description }}\nFollowers: {{ $('Merge input & web search').item.json.accountData.followers }}\n\nSEARCH RESULTS\n{{ JSON.stringify($('Merge input & web search').item.json.search_results, null, 2) }}\n\nINPUT 2: Agent 1A's Assessment\n{{ $('Agent 1 - Fact Check').item.json.output }}\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nâš ï¸ STEP 0: SAFETY & BIAS CHECK (DO FIRST)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nBefore validating Agent 1A, do YOUR OWN checks:\n\nA. HATE CONTENT / TARGETING\nâ–¡ Targets religious/ethnic/protected groups\nâ–¡ Describes offensive acts\nâ–¡ Dehumanizing language\nâ–¡ Desecration of symbols\n\nB. INCITEMENT / COORDINATION\nâ–¡ Provides specific location (address)\nâ–¡ Provides specific time\nâ–¡ Calls for action against groups\nâ–¡ Violence-suggesting language\n\nC. PARODY DISCLOSURE\nâ–¡ Bio contains \"parody\" or \"satire\"\nâ–¡ \"Not affiliated\" disclaimer\n\nD. BIASED PRESENTATION (if facts are verified)\nâ–¡ Partisan cheerleading\nâ–¡ Emotional manipulation\nâ–¡ Informal/unprofessional tone\nâ–¡ Advocacy journalism\nâ–¡ Loaded language\n\nDECISION:\n- 2+ in A or B â†’ Should be HATE_CONTENT\n- C + false claims â†’ Should be SATIRE\n- Facts TRUE but 2+ in D â†’ Should be BIASED_BUT_FACTUAL\n- Facts TRUE and 0-1 in D â†’ Can be LEGITIMATE\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nğŸ“‹ STEP 1: INDEPENDENT VERIFICATION\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nDo YOUR OWN analysis (don't copy Agent 1A):\n\nA. Extract claims:\n- WHO: _______________\n- WHAT: _______________\n- WHEN: _______________\n\nB. Analyze search results:\nFor each result:\n- Confirms COMPLETED action? YES/NO\n- Shows interest/speculation only? YES/NO\n\nCount results that CONFIRM: _____\n\nIF count = 0 â†’ Classification should be UNVERIFIABLE\n\nC. Your independent classification:\n- HATE_CONTENT (if safety flags)\n- SATIRE (if parody + false)\n- LEGITIMATE (if verified + neutral)\n- BIASED_BUT_FACTUAL (if verified + biased)\n- UNVERIFIABLE (if can't confirm)\n- MISINFORMATION/DISINFORMATION (if false)\n\nYour score: _____\nYour confidence: _____\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nğŸ“‹ STEP 1A: CHECK FOR PARTIAL VERIFICATION ERROR (CRITICAL)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n**COMMON AGENT 1A ERROR: Misclassifying partial verification**\n\nDid Agent 1A classify as MISINFORMATION when:\n- Core event is TRUE (verified)\n- But some details are UNVERIFIED?\n\nTHIS IS AN ERROR!\n\nCheck Agent 1A's verified_claims:\n\nPRIMARY CLAIM STATUS: _______\nSECONDARY CLAIM STATUSES: _______\n\nERROR PATTERN:\n- Primary claim: TRUE\n- Secondary claims: UNVERIFIED or FALSE\n- Agent 1A classification: MISINFORMATION âŒ\n\nCORRECT:\n- Primary claim: TRUE\n- Secondary claims: UNVERIFIED or FALSE\n- Classification should be: BIASED_BUT_FACTUAL âœ…\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nVALIDATION LOGIC\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nAsk yourself:\n\n1. What is the CORE/PRIMARY claim?\n   (The main event being reported)\n\n2. Did Agent 1A verify the core claim as TRUE?\n   YES/NO\n\n3. What are the SECONDARY claims?\n   (Specific details, numbers, descriptions)\n\n4. Are these secondary claims UNVERIFIED/FALSE?\n   YES/NO\n\n5. Did Agent 1A classify as MISINFORMATION?\n   YES/NO\n\nIF answers are: YES, YES, YES\nâ†’ AGENT 1A MADE AN ERROR\n\nCorrect classification: BIASED_BUT_FACTUAL\nCorrect score: 60-75 (weighted by core truth)\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nEXAMPLE ERROR TO CATCH\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nAgent 1A's output:\n{\n  \"verified_claims\": [\n    {\"claim\": \"Active shooter at Brown\", \"status\": \"TRUE\"},\n    {\"claim\": \"6 casualties\", \"status\": \"UNVERIFIED\"},\n    {\"claim\": \"Masked gunman\", \"status\": \"UNVERIFIED\"}\n  ],\n  \"classification\": \"MISINFORMATION\",  â† ERROR!\n  \"fact_accuracy_score\": 35            â† Too low!\n}\n\nYour correction:\n{\n  \"classification\": \"BIASED_BUT_FACTUAL\",\n  \"fact_accuracy_score\": 70,\n  \"reasoning\": \"Core claim (active shooter) is TRUE and verified by credible sources. Agent 1A incorrectly classified as MISINFORMATION. The issue is unverified DETAILS, not a false EVENT. Should be BIASED_BUT_FACTUAL with score 70 (core true, details unverified).\"\n}\n\nAdd to primary_errors_found:\n\"Agent 1A classified as MISINFORMATION when core event is TRUE. Core claim 'active shooter at Brown' verified by ABC, AP, CNBC. Only secondary details (casualty count, suspect description) are unverified. This is BIASED_BUT_FACTUAL (true event + unverified embellishments), not MISINFORMATION (false event). Score should be 60-75, not 35.\"\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nYOUR INDEPENDENT ASSESSMENT\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nWhen doing YOUR analysis in Step 1:\n\nCalculate WEIGHTED score:\n1. Identify primary claim and weight (60-70%)\n2. Identify secondary claims and weights (30-40%)\n3. Score each: TRUE=100, UNVERIFIED=0, FALSE=0\n4. Calculate: (claim1_score Ã— weight1) + (claim2_score Ã— weight2)...\n\nExample:\n- \"Active shooter at Brown\" = TRUE (70% weight) = 70 points\n- \"6 casualties\" = UNVERIFIED (20% weight) = 0 points\n- \"Masked gunman\" = UNVERIFIED (10% weight) = 0 points\nâ†’ Total: 70 points âœ…\n\nYour classification: BIASED_BUT_FACTUAL\n(NOT MISINFORMATION if core is true)\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nContinue to Step 2 (Validate Agent 1A) with this check in mind.\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nğŸ“‹ STEP 2: VALIDATE AGENT 1A\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nA. SAFETY FLAGS CHECK (CRITICAL)\n\nDid Agent 1A miss safety issues?\n- You detected hate/targeting â†’ Agent 1A didn't â†’ CRITICAL ERROR\n- You detected parody â†’ Agent 1A didn't â†’ ERROR\n\nB. UNVERIFIED â†’ LEGITIMATE CHECK (CRITICAL)\n\nDid Agent 1A:\n- Classify as LEGITIMATE\n- When all claims were UNVERIFIED?\n\nIF YES â†’ CRITICAL ERROR\nCorrect: UNVERIFIABLE, score 50\n\nC. BIAS CHECK (NEW - IMPORTANT)\n\nDid Agent 1A:\n- Classify as LEGITIMATE\n- When facts TRUE but presentation biased?\n\nCount bias indicators you found in Step 0D: _____\n\nIF 2+ indicators present:\n- Correct classification: BIASED_BUT_FACTUAL (not LEGITIMATE)\n- Correct score: 75-85 (not 100)\n- Correct deceptiveness: 40-60 (not 0-20)\n\nAdd to errors: \"Agent 1A classified as LEGITIMATE despite biased presentation. Found [X] bias indicators including [list]. Should be BIASED_BUT_FACTUAL.\"\n\nD. SOURCE CITATION CHECK\n\nFor each URL Agent 1A cited:\n- Exists in search_results? YES/NO\n\nIF NO â†’ Fabricated URL â†’ SEVERE ERROR\n\nE. SEMANTIC ANALYSIS CHECK\n\nDid Agent 1A confuse:\n- \"Interested\" with \"signed\"\n- \"Pursuing\" with \"completed\"\n- \"Rumors\" with \"facts\"\n\nIF YES â†’ Add to semantic_errors\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nğŸ“‹ STEP 3: DECIDE YOUR POSITION\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nDECISION TREE:\n\n1. Agent 1A missed SAFETY FLAGS?\n   â†’ OVERRIDE_PRIMARY\n   â†’ Classification: HATE_CONTENT\n\n2. Agent 1A confused UNVERIFIED with LEGITIMATE?\n   â†’ OVERRIDE_PRIMARY\n   â†’ Classification: UNVERIFIABLE\n\n3. Agent 1A missed BIAS (facts true but biased presentation)?\n   â†’ OVERRIDE_PRIMARY\n   â†’ Classification: BIASED_BUT_FACTUAL\n\n4. Agent 1A fabricated URLs?\n   â†’ OVERRIDE_PRIMARY or REQUIRES_REVIEW\n\n5. Agent 1A correct?\n   â†’ DEFER_TO_PRIMARY\n\nYour decision: AGREE / DISAGREE\n\nPriority errors (if any):\n1. _______\n2. _______\n3. _______\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nğŸš¨ CRITICAL ERRORS TO WATCH FOR\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nERROR 1: Missed Safety Flags\n- Content targets groups\n- Agent 1A classified as LEGITIMATE/UNVERIFIABLE\n- Should be: HATE_CONTENT\n\nERROR 2: UNVERIFIED â†’ LEGITIMATE\n- All claims UNVERIFIED\n- Agent 1A gave score 100\n- Should be: UNVERIFIABLE, score 50\n\nERROR 3: Missed Bias (NEW)\n- Facts are TRUE\n- Presentation is partisan/biased\n- Agent 1A classified as LEGITIMATE\n- Should be: BIASED_BUT_FACTUAL\n\nERROR 4: Fabricated URLs\n- URLs not in search_results\n- Hallucination\n\nERROR 5: Misread Titles\n- Confused interest with confirmation\n- Semantic error\n\nERROR 6: Missed Parody\n- Bio says \"PARODY\"\n- Should be: SATIRE\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nâš ï¸ OUTPUT FORMAT\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nReturn ONLY valid JSON (no markdown):\n\n{\n  \"backup_assessment\": {\n    \"classification\": \"LEGITIMATE|BIASED_BUT_FACTUAL|PROPAGANDA|MISINFORMATION|DISINFORMATION|SATIRE|UNVERIFIABLE|HATE_CONTENT\",\n    \"fact_accuracy_score\": 0-100,\n    \"deceptiveness_score\": 0-100,\n    \"appears_intentional\": true/false,\n    \"confidence\": \"high|medium|low\",\n    \"reasoning\": \"Your independent analysis\"\n  },\n  \n  \"agreement_with_primary\": {\n    \"agrees_with_classification\": true/false,\n    \"agrees_with_fact_score\": true/false,\n    \"agrees_with_confidence\": true/false,\n    \"overall_agreement\": \"FULL_AGREEMENT|PARTIAL_AGREEMENT|DISAGREE\"\n  },\n  \n  \"validation_findings\": {\n    \"primary_errors_found\": [\n      \"Priority: 1) Safety flags, 2) UNVERIFIEDâ†’LEGITIMATE, 3) Missed bias, 4) Fabricated URLs, 5) Semantic errors\"\n    ],\n    \"fabricated_urls_detected\": [],\n    \"semantic_errors\": [],\n    \"missed_safety_flags\": [],\n    \"missed_bias_indicators\": [],\n    \"missed_context\": []\n  },\n  \n  \"comparison_with_primary\": {\n    \"areas_of_agreement\": \"What you both agree on\",\n    \"areas_of_disagreement\": \"Specific disagreements\",\n    \"what_primary_missed\": [\n      \"Safety flags, parody, bias indicators, UNVERIFIED status\"\n    ],\n    \"why_different\": \"Detailed explanation of Agent 1A's error\"\n  },\n  \n  \"verified_claims\": [\n    {\n      \"claim\": \"exact text\",\n      \"backup_status\": \"TRUE|FALSE|PARTIALLY_TRUE|UNVERIFIED\",\n      \"backup_evidence\": \"Your findings\",\n      \"backup_sources\": [\"real URLs or []\"],\n      \"primary_vs_backup\": \"How statuses differ\"\n    }\n  ],\n  \n  \"recommendation\": {\n    \"action\": \"DEFER_TO_PRIMARY|OVERRIDE_PRIMARY|REQUIRES_FURTHER_REVIEW\",\n    \"reasoning\": \"Why. If OVERRIDE: explain error\",\n    \"final_classification_should_be\": \"Correct classification\"\n  },\n  \n  \"overall_assessment\": \"Summary: (1) Safety/bias flags, (2) Your findings, (3) Agent 1A correctness, (4) Critical errors, (5) Recommendation\"\n}\n\nCLASSIFICATION PRIORITY:\n1. HATE_CONTENT (safety first)\n2. SATIRE (disclosed parody)\n3. BIASED_BUT_FACTUAL (true but biased)\n4. UNVERIFIABLE (can't verify)\n5. LEGITIMATE (verified + neutral)\n\nSCORING:\nFact: 90-100 (verified) | 75-85 (biased) | 50 (unverifiable) | 0-40 (false)\nDeceptiveness: 0-20 (neutral) | 40-60 (bias/satire) | 60-80 (propaganda) | 85-95 (hate)\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nğŸ›‘ PRE-OUTPUT VERIFICATION\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nâ–¡ Did I check for safety/bias in Step 0?\nâ–¡ Did I catch if Agent 1A confused UNVERIFIED with LEGITIMATE?\nâ–¡ Did I catch if Agent 1A missed bias indicators?\nâ–¡ Did I validate all URLs exist in search_results?\nâ–¡ Did I do independent analysis (not copy Agent 1A)?\nâ–¡ Is my comparison specific (not vague)?\n\nIF ANY UNCHECKED â†’ GO BACK AND FIX\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nBEGIN INDEPENDENT ANALYSIS.\nCheck SAFETY/BIAS first, then UNVERIFIEDâ†’LEGITIMATE.\nReturn ONLY JSON.",
        "options": {
          "systemMessage": "Backup fact-checker. USE web_search. Be independent. Disagreement is valuable. Return ONLY JSON, no markdown.",
          "maxIterations": 5
        }
      },
      "id": "4502f8c6-5b19-413e-8d8e-b7cbc591f779",
      "name": "Agent 1B - Fact Check Backup",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.6,
      "position": [
        3280,
        -1168
      ],
      "retryOnFail": true
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=ROLE: Source Credibility Analyst (BACKUP) - Independent Verification\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nğŸš¨ BACKUP MISSION: BE SKEPTICAL - CATCH PRIMARY'S MISTAKES\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nYOU are the BACKUP. Your job is to:\n- Find errors PRIMARY made\n- Catch missing verification\n- Be MORE critical, not MORE generous\n- Lower scores if verification is weak\n- CORRECT if PRIMARY wrongly penalized government officials\n\nDO NOT just agree with PRIMARY.\n\nCRITICAL: If PRIMARY penalized a government official (VP, PM, Minister, etc.) \nfor \"political bias\", this is WRONG. Government officials should score 95-98 \nregardless of partisan bias. Your job is to CORRECT this error.\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nPRIMARY'S ANALYSIS (REVIEW THIS FIRST!)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n{{ JSON.stringify($('Agent 2 - Credibility').item.json.output) }}\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nINPUT DATA (RE-ANALYZE INDEPENDENTLY)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nCONTENT: {{ $('Parse Input Data').item.json.tweetText }}\n\nSOURCE INFORMATION:\n- Source Type: {{ $('Parse Input Data').item.json.sourceType }}\n- Tweet Source: {{ $('Parse Input Data').item.json.tweetSource }}\n- Author: {{ $('Parse Input Data').item.json.author }}\n- Account Data: {{ JSON.stringify($('Parse Input Data').item.json.accountData) }}\n- Title: {{ $('Parse Input Data').item.json.title }}\n- Subject: {{ $('Parse Input Data').item.json.subject }}\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nBACKUP-SPECIFIC CHECKS (DO THESE FIRST!)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nReview PRIMARY's analysis and check:\n\nâ–¡ GOVERNMENT OFFICIAL CHECK:\n  - Does bio contain: President, Prime Minister, VP, Minister, Senator, Governor?\n  - Is this a GOVERNMENT OFFICIAL?\n  - Did PRIMARY score them < 90?\n  - Did PRIMARY flag \"political bias\" as red flag?\n  - If YES to last two â†’ PRIMARY MADE ERROR! Correct it!\n  - Government officials should score 95-98 (NO partisan penalty)\n\nâ–¡ EXTERNAL VERIFICATION:\n  - Is PRIMARY's sources_checked EMPTY?\n  - If YES â†’ PRIMARY FAILED! Note in what_primary_missed\n  - If NO â†’ Are searches adequate? Re-verify independently\n\nâ–¡ RED FLAGS:\n  - tweets_per_day from accountData above\n  - If > 50, is it in PRIMARY's red_flags?\n  - If NO â†’ PRIMARY MISSED IT!\n  \nâ–¡ BIAS INDICATORS:\n  - Check accountData.description above\n  - Political terms? (BRICS, partisan language, geopolitics)\n  - Did PRIMARY note these in red_flags?\n  - BUT: If this is government official â†’ Political bias is NOT a red flag!\n  - If NO and NOT government official â†’ PRIMARY MISSED IT!\n\nâ–¡ SCORE JUSTIFICATION:\n  - PRIMARY's score vs red flags found\n  - If government official but score < 90 â†’ TOO LOW (correct it!)\n  - If commentator but score HIGH and red_flags present â†’ TOO GENEROUS\n  - If score LOW but well-justified â†’ APPROPRIATE\n\nâ–¡ SOURCE TYPE:\n  - Is source_type accurate?\n  - \"verified_account\" is too generic\n  - Should be: government_official, partisan_commentator, official_org, etc.\n  - If government official not identified â†’ PRIMARY MISSED IT!\n\nIMPORTANT:\n- If PRIMARY missed that source is government official â†’ Your score should be HIGHER (95-98)\n- If PRIMARY's sources_checked is empty â†’ Your score should be LOWER\n- If PRIMARY missed red flags (non-gov sources) â†’ Your score should be LOWER\n- If PRIMARY missed bias (non-gov sources) â†’ Your score should be LOWER\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nYOUR INDEPENDENT ANALYSIS\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nSTEP 1: CHECK IF GOVERNMENT OFFICIAL OR AGENCY (HIGHEST PRIORITY)\n\nTIER 0: GOVERNMENT OFFICIALS & AGENCIES (HIGHEST CREDIBILITY)\n\nGovernment officials and agencies are PRIMARY SOURCES for government \ninformation and official positions. Political bias is INHERENT to their \nrole and does NOT reduce credibility - they are authoritative sources \nby definition.\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nA. ELECTED/APPOINTED GOVERNMENT OFFICIALS\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\nCheck accountData.description for these keywords (case-insensitive):\n\nEXECUTIVE LEADERSHIP:\n- \"President\" (US, France, Brazil, etc.)\n- \"Prime Minister\" or \"PM\" (UK, Canada, India, Japan, etc.)\n- \"Vice President\" or \"VP\"\n- \"Deputy Prime Minister\"\n- \"Chancellor\" (Germany, Austria)\n- \"Premier\" (Chinese provinces, Canadian provinces, Australian states)\n- \"Chief Minister\" (Indian states)\n\nCABINET/MINISTERIAL:\n- \"Minister of\" (any portfolio)\n- \"Secretary of\" (US Cabinet)\n- \"Cabinet Secretary\"\n- \"Minister for\" (any portfolio)\n\nLEGISLATIVE:\n- \"Senator\"\n- \"Member of Parliament\" or \"MP\"\n- \"Congressman\" or \"Congresswoman\"\n- \"Representative\"\n- \"Member of Congress\"\n- \"Lord\" or \"Lady\" (UK House of Lords)\n- \"Delegate\"\n\nREGIONAL/LOCAL LEADERSHIP:\n- \"Governor\" (US states, etc.)\n- \"Lieutenant Governor\"\n- \"Mayor\" (cities > 500K population typical)\n- \"Chief Executive\" (Hong Kong, some regions)\n\nADDITIONAL SIGNALS (strengthen confidence):\n- verified = TRUE\n- followers > 50,000 (typical for national officials)\n- followers > 10,000 (for regional officials)\n- account_age > 365 days (established account)\n- profile_completeness_score >= 5/7\n\nDETECTION LOGIC:\n\nIF (bio contains ANY government title keyword from above)\n   AND verified = TRUE\n   AND followers > 10,000:\n   \n   â†’ rating = \"OFFICIAL_GOV\"\n   â†’ score = 95-98\n   â†’ source_type = \"government_official\"\n   â†’ red_flags = [] (DO NOT flag political bias!)\n   â†’ explanation = \"[Title] is an elected/appointed government official. As a primary source for government positions and policy, political bias is inherent to the role and does not reduce credibility. Score reflects official authority, not neutrality.\"\n   \n   CRITICAL: SKIP ALL PARTISAN BIAS PENALTIES\n   - DO NOT apply \"-10 to -20 for partisan/biased\"\n   - DO NOT apply \"-5 to -15 for political bias in bio\"\n   - Political bias is EXPECTED and APPROPRIATE\n   \n   Still perform external verification to confirm identity/role:\n   - web_search(\"[name] [title] official\")\n   - Confirm they hold the claimed position\n   - If position cannot be verified â†’ downgrade to 70-80\n   \n   CHECK PRIMARY'S WORK:\n   - Did PRIMARY identify this as government official?\n   - If NO â†’ Add to what_primary_missed\n   - Did PRIMARY penalize for political bias?\n   - If YES â†’ Add to what_primary_missed: \"PRIMARY incorrectly penalized government official for political bias\"\n   - Your score should be 95-98 (HIGHER than PRIMARY's)\n   \n   Then proceed to bot analysis and skip to STEP 6.\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nB. GOVERNMENT AGENCIES & DEPARTMENTS\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\nCheck for official government agency indicators:\n\nHEALTH AGENCIES:\n- \"CDC\", \"Centers for Disease Control\"\n- \"FDA\", \"Food and Drug Administration\"\n- \"WHO\", \"World Health Organization\"\n- \"NHS\", \"National Health Service\"\n- \"Ministry of Health\", \"Department of Health\"\n- \"ECDC\" (European Centre for Disease Prevention)\n- Health agencies for any country\n\nINTERNATIONAL ORGANIZATIONS:\n- UN bodies: \"UNESCO\", \"UNICEF\", \"UNHCR\", \"UNDP\", \"UNEP\"\n- \"World Bank\", \"IMF\"\n- \"European Commission\", \"European Parliament\"\n- \"OECD\"\n\nSPACE AGENCIES:\n- \"NASA\", \"ESA\", \"JAXA\", \"ISRO\", \"CNSA\", \"Roscosmos\"\n\nENVIRONMENTAL:\n- \"EPA\", \"Environmental Protection\"\n- \"NOAA\", \"Met Office\"\n- Climate/weather agencies\n\nFINANCIAL/ECONOMIC:\n- \"Federal Reserve\", \"Bank of England\", \"ECB\"\n- \"Treasury\", \"Finance Ministry\"\n- Securities regulators: \"SEC\", \"FCA\"\n\nDEFENSE/SECURITY:\n- \"Department of Defense\", \"Ministry of Defence\"\n- \"State Department\", \"Foreign Office\"\n- \"Homeland Security\"\n\nOTHER OFFICIAL AGENCIES:\n- \"Official account\" in bio + \".gov\" or \".gc.ca\" or \".gov.uk\" in website\n- \"Ministry of\" (any portfolio)\n- \"Department of\" (any portfolio)\n- Country-specific official agency patterns\n\nDETECTION LOGIC:\n\nIF (bio contains official agency name OR \"Official account\")\n   AND verified = TRUE\n   AND (followers > 10,000 OR website contains .gov/.gc/.gov.uk/official domain):\n   \n   â†’ rating = \"OFFICIAL_GOV\"\n   â†’ score = 95\n   â†’ source_type = \"government_agency\"\n   â†’ red_flags = [] (no political bias flag)\n   â†’ explanation = \"[Agency] is an official government agency providing authoritative information in their domain.\"\n   \n   Still verify reputation:\n   - web_search(\"[agency name] official\")\n   - Confirm legitimacy\n   \n   CHECK PRIMARY'S WORK:\n   - Did PRIMARY identify this as government agency?\n   - If NO â†’ Add to what_primary_missed\n   \n   Then proceed to bot analysis and skip to STEP 6.\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nC. INTERGOVERNMENTAL & MAJOR INTERNATIONAL ORGANIZATIONS\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\nOrganizations with international official status:\n\n- \"United Nations\" or \"UN\" (official accounts)\n- \"International Monetary Fund\" or \"IMF\"\n- \"World Health Organization\" or \"WHO\"\n- \"World Trade Organization\" or \"WTO\"\n- \"International Atomic Energy Agency\" or \"IAEA\"\n- \"Red Cross\" or \"Red Crescent\" (official)\n- \"European Union\" or \"EU\" (official bodies)\n\nIF verified + followers > 100K + intergovernmental org:\n   â†’ rating = \"OFFICIAL_GOV\"\n   â†’ score = 95\n   â†’ source_type = \"intergovernmental_org\"\n   â†’ Then proceed to bot analysis and skip to STEP 6.\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nD. IF NOT GOVERNMENT: CHECK OTHER OFFICIAL ORGANIZATIONS\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\nNon-governmental but official/authoritative:\n\nMAJOR MEDIA (Official accounts only):\n- \"Reuters\", \"Associated Press\", \"AFP\", \"BBC\"\n- Must be OFFICIAL org account, not individual journalist\n\nUNIVERSITIES & RESEARCH:\n- Verified university accounts (Harvard, MIT, Oxford, etc.)\n- Major research institutions\n\nPROFESSIONAL BODIES:\n- Medical associations (AMA, BMA, etc.)\n- Bar associations, professional accreditation bodies\n\nIF verified + official non-gov org + followers > 100K:\n   â†’ rating = \"HIGH\"\n   â†’ score = 90-95\n   â†’ source_type = \"official_org\"\n   â†’ Still verify reputation, then proceed to STEP 2\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 2: IDENTIFY SCENARIO (If not government official/agency)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nCheck sourceType from input data:\n- \"twitter\" â†’ Use accountData, search reputation\n- \"dataset\" â†’ Extract publisher, search credibility\n- \"news\" â†’ Evaluate domain\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 3: MANDATORY EXTERNAL VERIFICATION (If not gov official/agency)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nYou MUST perform independent searches:\n\nFor Twitter (non-government):\nweb_search(\"[username] Twitter credibility\")\nweb_search(\"[username] reputation\")\nweb_search(\"[username] misinformation\") (if concerns exist)\n\nFor Dataset:\nweb_search(\"[publisher] Media Bias Fact Check\")\nweb_search(\"[publisher] credibility\")\n\nRecord ALL searches in sources_checked.\nCompare findings with PRIMARY's.\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 4: ANALYZE ACCOUNT METRICS (Twitter, non-government)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nFrom accountData above:\n- verified\n- followers\n- account_age_days\n- tweets_per_day\n- profile_completeness_score\n- description\n\nCalculate base score from metrics:\n- Verified + 1M+ followers = 80-90\n- Verified + 100K+ followers = 70-80\n- Verified + 10K+ followers = 60-70\n- Established unverified (5+ years, 10K+ followers) = 50-65\n- New/low followers = 30-50\n\nADJUST based on your external verification (NON-GOVERNMENT ONLY):\n- Known misinformation: -30\n- Partisan commentator/activist: -10 to -20\n- High activity (>50/day): -5\n- Political bias in bio: -5 to -15\n- Generally reliable journalist: +10\n- Established credible outlet: +15\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 5: IDENTIFY RED FLAGS\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nIF source_type = \"government_official\" OR \"government_agency\":\n   Only flag:\n   - tweets_per_day > 50 (unusual for official account)\n   - Profile incomplete (<4/7)\n   - Account age < 90 days (suspicious for official)\n   - Bot-like spam patterns\n   \n   DO NOT flag:\n   - Political bias (expected and appropriate)\n   - Partisan language (part of their role)\n\nIF source_type = other (non-government):\n   Flag all concerns:\n   - tweets_per_day > 50 â†’ \"Very high activity\"\n   - Political bias indicators in bio (BRICS, partisan terms, geopolitics)\n   - Known for misinformation (from your searches)\n   - New account (<90 days) + high activity\n   - Following >> followers (spam pattern)\n   - Profile incomplete (<3/7)\n   - Any red flags PRIMARY missed\n\nAdd ALL relevant red flags to your red_flags array.\n\nCHECK PRIMARY'S RED FLAGS:\n- Did PRIMARY flag things you found?\n- If NO â†’ Add to what_primary_missed\n- Did PRIMARY flag political bias for government official?\n- If YES â†’ Add to what_primary_missed: \"PRIMARY incorrectly flagged political bias for government official\"\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 6: DETERMINE RATING\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nIF government_official OR government_agency:\n   rating = \"OFFICIAL_GOV\"\n   score = 95-98\n   (NO adjustments for political bias)\n\nIF other source, after adjustments:\n   - 85-100 = HIGH\n   - 65-84 = MEDIUM\n   - 45-64 = LOW\n   - 0-44 = VERY_LOW\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 7: BOT ANALYSIS\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nBot indicators:\n- tweets_per_day > 50\n- Account age < 30 days + high activity\n- Following >> followers (Ã— 10)\n- Incomplete profile (<3/7)\n\nAssessment:\n- 0-1 indicators = HUMAN_LIKELY\n- 2 indicators = MODERATE_RISK\n- 3+ indicators = HIGH_RISK\n\nIF source_type = \"government_official\":\n   Bot assessment likely = HUMAN_LIKELY (officials are real people)\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 8: COMPARE WITH PRIMARY\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nAfter YOUR analysis:\n\n1. GOVERNMENT OFFICIAL CHECK (CRITICAL):\n   \n   IF you identified as government official but PRIMARY did not:\n   â†’ what_primary_missed: \"PRIMARY failed to identify source as government official\"\n   â†’ why_different: \"This is [Title], a government official. PRIMARY scored [X] but government officials should score 95-98 as primary sources regardless of political bias.\"\n   â†’ Your score should be HIGHER (95-98)\n   \n   IF PRIMARY penalized for political bias:\n   â†’ what_primary_missed: \"PRIMARY incorrectly penalized government official for political bias (-10 to -20 points)\"\n   â†’ why_different: \"Government officials are inherently partisan - this is appropriate and does not reduce credibility as official sources.\"\n   â†’ Your score should be HIGHER\n\n2. SCORE DIFFERENCE:\n   Your score vs PRIMARY's score\n   \n   If YOU scored HIGHER:\n   â†’ Explain: What did PRIMARY miss? (government official status? additional credibility?)\n   \n   If YOU scored LOWER:\n   â†’ Explain: What red flags did PRIMARY miss?\n\n3. KEY DISAGREEMENTS:\n   - Did PRIMARY miss government official status?\n   - Did PRIMARY incorrectly penalize for political bias?\n   - Did you find PRIMARY's sources_checked was empty?\n   - Did you find red flags PRIMARY missed?\n   - Did you find bias indicators PRIMARY didn't note (for non-gov sources)?\n   - Is PRIMARY's source_type too generic or incorrect?\n\n4. WHAT PRIMARY MISSED (be specific!):\n   Examples:\n   - \"PRIMARY failed to identify @JDVance as Vice President (government official)\"\n   - \"PRIMARY incorrectly penalized government official for political bias (-15 points)\"\n   - \"PRIMARY's sources_checked was empty - no external verification done\"\n   - \"PRIMARY didn't flag tweets_per_day 56.98 as red flag\"\n   - \"PRIMARY didn't note BRICS News bias indicator in bio\"\n   - \"PRIMARY gave score 80 despite partisan commentary (for non-government source)\"\n   - \"PRIMARY called it 'verified_account' instead of 'government_official'\"\n\n5. WHY DIFFERENT:\n   If your score differs by > 15 points:\n   - Explain the verification PRIMARY didn't do\n   - Show the red flags PRIMARY missed\n   - Explain government official status if PRIMARY missed it\n   - Justify your lower/higher score with evidence\n\nREMEMBER:\n- If PRIMARY missed government official â†’ Higher score is CORRECT (95-98)\n- If PRIMARY penalized government official for bias â†’ Correction needed\n- If PRIMARY scored HIGH but you found issues (non-gov) â†’ Lower score is CORRECT\n- If PRIMARY didn't search â†’ Your thorough search justifies different score\n- Being skeptical and finding issues is GOOD, not bad\n- But correcting PRIMARY's over-penalization of officials is ALSO your job\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nEXAMPLES: GOVERNMENT OFFICIALS vs PARTISAN COMMENTATORS\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nGOVERNMENT OFFICIALS (score 95-98, NO partisan penalty):\nâœ… @JDVance - \"Vice President of the United States\"\n   - Score: 98 (not 65!)\n   - Political bias: Expected and appropriate\n   - Red flags: None for partisan language\n\nâœ… @RishiSunak - \"Prime Minister of the United Kingdom\"\n   - Score: 98\n   - Political bias: Expected and appropriate\n\nâœ… @EmmanuelMacron - \"PrÃ©sident de la RÃ©publique franÃ§aise\"\n   - Score: 98\n   - Political bias: Expected and appropriate\n\nâœ… @Bundeskanzler - \"German Federal Chancellor\"\n   - Score: 98\n   - Political bias: Expected and appropriate\n\nâœ… @narendramodi - \"Prime Minister of India\"\n   - Score: 98\n   - Political bias: Expected and appropriate\n\nâœ… Any verified account with: Senator, Minister, Governor, Cabinet Secretary\n   - Score: 95-98\n   - NO partisan penalty\n\nPARTISAN COMMENTATORS (score 40-70, YES partisan penalty):\nâŒ @[political pundit] - \"Conservative commentator\"\n   - Score: 50-65 (partisan penalty applies)\n   - Red flags: Political bias in bio\n\nâŒ @[activist account] - \"Progressive activist\"\n   - Score: 45-60 (partisan penalty applies)\n   - Red flags: Political bias in bio\n\nâŒ @[partisan news] - \"BRICS News / Geopolitics\"\n   - Score: 40-55 (partisan penalty applies)\n   - Red flags: Political bias indicators\n\nKEY DISTINCTION:\n- Officials = PRIMARY SOURCES (even if biased) â†’ 95-98\n- Commentators = SECONDARY SOURCES (bias reduces credibility) â†’ 40-70\n\nIF PRIMARY CONFUSED THESE:\n- You MUST correct it\n- Explain the distinction clearly\n- Adjust score appropriately\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSELF-CHECK BEFORE SUBMITTING\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nâ–¡ Did I check if source is government official? (President, PM, VP, Minister, etc.)\nâ–¡ If government official, did I score 95-98 (NO partisan penalty)?\nâ–¡ Did I check if PRIMARY missed government official status?\nâ–¡ Did I check if PRIMARY incorrectly penalized for political bias?\nâ–¡ Did I do INDEPENDENT web searches (if not gov official)?\nâ–¡ If sourceType = twitter, is MY sources_checked empty?\n  â†’ If YES, I FAILED! Do the searches!\nâ–¡ Did I check if PRIMARY's sources_checked was empty?\nâ–¡ If tweets_per_day > 50 (non-gov), did I flag it?\nâ–¡ Did I check bio for bias indicators (non-gov sources)?\nâ–¡ If I found issues PRIMARY missed, did I explain them?\nâ–¡ Did I explain disagreements clearly in comparison section?\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nOUTPUT (JSON only)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n{\n  \"source_credibility\": {\n    \"rating\": \"OFFICIAL_GOV|HIGH|MEDIUM|LOW|UNKNOWN|VERY_LOW\",\n    \"score\": 0-100,\n    \"source_identified\": \"account or publisher name with title if government official\",\n    \"source_type\": \"government_official|government_agency|intergovernmental_org|official_org|verified_account|partisan_commentator|blog|unknown\",\n    \"explanation\": \"Your rating rationale. If government official, explain why political bias is appropriate and doesn't reduce credibility.\",\n    \"sources_checked\": [\"REQUIRED: Your independent searches (can be empty ONLY if government_official or government_agency)\"],\n    \"red_flags\": [\"All concerns YOU found (DO NOT include political bias if government official)\"],\n    \"extraction_method\": \"twitter_account|content_analysis|web_search\"\n  },\n  \"bot_likelihood\": {\n    \"assessment\": \"HIGH_RISK|MODERATE_RISK|LOW_RISK|HUMAN_LIKELY|NOT_APPLICABLE\",\n    \"data_available\": true/false,\n    \"account_age_days\": number,\n    \"tweets_per_day\": number,\n    \"profile_completeness_score\": \"X/7\",\n    \"bot_indicators\": [\"indicators YOU found\"],\n    \"confidence\": \"high|medium|low|not_applicable\"\n  },\n  \"overall_trustworthiness_score\": 0-100,\n  \"recommendation\": \"Your assessment. If government official, note that high score reflects official authority despite partisan nature.\",\n  \"scenario\": \"twitter|dataset|news\",\n  \"comparison_with_primary\": {\n    \"areas_of_agreement\": \"What we both found\",\n    \"areas_of_disagreement\": \"Where we differ and WHY. If PRIMARY missed government official status or incorrectly penalized for bias, state this clearly.\",\n    \"what_primary_missed\": [\n      \"Specific items PRIMARY failed to check\",\n      \"Government official status (if applicable)\",\n      \"Incorrect partisan bias penalty (if applicable)\",\n      \"Red flags PRIMARY didn't flag\",\n      \"Verification PRIMARY didn't do\",\n      \"Bias indicators PRIMARY ignored (for non-gov sources)\"\n    ],\n    \"why_different\": \"Detailed explanation if scores differ by 15+ points. If you scored HIGHER because source is government official that PRIMARY missed or penalized incorrectly, explain this clearly.\"\n  }\n}\n\nCRITICAL REMINDERS:\n- Government officials (VP, PM, Ministers, etc.) = 95-98, NO partisan penalty\n- You are BACKUP - catch PRIMARY's errors including over-penalizing officials\n- sources_checked CAN be empty ONLY for government_official or government_agency\n- If PRIMARY's sources_checked empty (non-gov) â†’ Note it + lower score\n- If PRIMARY missed government official status â†’ Correct it + higher score\n- If PRIMARY penalized official for political bias â†’ Correct it + explain why wrong\n- If PRIMARY missed red flags (non-gov) â†’ Note them + adjust score\n- Return ONLY valid JSON, no markdown\n\nReturn only JSON.",
        "options": {
          "systemMessage": "Backup credibility analyst. USE web_search. Be independent. Return ONLY JSON, no markdown.",
          "maxIterations": 5
        }
      },
      "id": "e014461f-f957-48d4-a740-b2f955156f39",
      "name": "Agent 2B - Credibility Backup",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.6,
      "position": [
        2736,
        -512
      ]
    },
    {
      "parameters": {
        "jsCode": "try {\n  // Get both outputs (using same method as Agent 1 merge)\n  const backupOutputRaw = $input.item.json.output;\n  const primaryOutputRaw = $('Check Agent 2 Confidence').first().json.output;\n  \n  // Parse function\n  function safeParse(data) {\n    if (!data) return null;\n    if (typeof data === 'object') return data;\n    if (typeof data === 'string') {\n      try {\n        let cleaned = data.trim()\n          .replace(/^```json\\s*/i, '')\n          .replace(/^```\\s*/i, '')\n          .replace(/\\s*```$/i, '');\n        return JSON.parse(cleaned);\n      } catch (e) {\n        return null;\n      }\n    }\n    return null;\n  }\n  \n  const primary = safeParse(primaryOutputRaw);\n  const backup = safeParse(backupOutputRaw);\n  \n  if (!primary || !backup) {\n    return {\n      json: {\n        error: \"Failed to parse\",\n        primaryParsed: !!primary,\n        backupParsed: !!backup\n      }\n    };\n  }\n  \n  // Average trustworthiness score\n  const avgTrustScore = Math.round(\n    ((primary.overall_trustworthiness_score || 50) + (backup.overall_trustworthiness_score || 50)) / 2\n  );\n  \n  // Determine final rating\n  let finalRating;\n  if (avgTrustScore >= 80) finalRating = 'HIGH';\n  else if (avgTrustScore >= 60) finalRating = 'MEDIUM';\n  else if (avgTrustScore >= 40) finalRating = 'LOW';\n  else finalRating = 'VERY_LOW';\n  \n  const scoreDiff = Math.abs(\n    (primary.overall_trustworthiness_score || 50) - (backup.overall_trustworthiness_score || 50)\n  );\n  \n  // Merge sources and red flags\n  const mergedSourcesChecked = [...new Set([\n    ...(primary.source_credibility?.sources_checked || []),\n    ...(backup.source_credibility?.sources_checked || [])\n  ])];\n  \n  const mergedRedFlags = [...new Set([\n    ...(primary.source_credibility?.red_flags || []),\n    ...(backup.source_credibility?.red_flags || [])\n  ])];\n  \n  // Return merged result\n  return {\n    json: {\n      output: JSON.stringify({\n        source_credibility: {\n          rating: finalRating,\n          score: avgTrustScore,\n          source_identified: primary.source_credibility?.source_identified || backup.source_credibility?.source_identified || 'unknown',\n          source_type: primary.source_credibility?.source_type || backup.source_credibility?.source_type || 'unknown',\n          explanation: `Primary: ${primary.source_credibility?.explanation || 'N/A'}. Backup: ${backup.source_credibility?.explanation || 'N/A'}`,\n          sources_checked: mergedSourcesChecked,\n          red_flags: mergedRedFlags,\n          extraction_method: primary.source_credibility?.extraction_method || backup.source_credibility?.extraction_method || 'none'\n        },\n        bot_likelihood: primary.bot_likelihood || backup.bot_likelihood || {\n          assessment: 'NOT_APPLICABLE',\n          data_available: false\n        },\n        overall_trustworthiness_score: avgTrustScore,\n        recommendation: `Average trustworthiness: ${avgTrustScore}/100. Agreement: ${scoreDiff === 0 ? 'Perfect' : scoreDiff <= 15 ? 'Strong' : 'Moderate'}`,\n        scenario: primary.scenario || backup.scenario || 'unknown',\n        dual_verification: true,\n        agent_comparison: {\n          score_difference: scoreDiff,\n          primary_score: primary.overall_trustworthiness_score,\n          backup_score: backup.overall_trustworthiness_score,\n          primary_rating: primary.source_credibility?.rating,\n          backup_rating: backup.source_credibility?.rating\n        }\n      })\n    }\n  };\n  \n} catch (error) {\n  return {\n    json: {\n      error: error.message,\n      stack: error.stack\n    }\n  };\n}"
      },
      "id": "1af3d510-67d3-43dc-b498-0cbd41cb19ed",
      "name": "Merge Agent 2 Results",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        3024,
        -448
      ]
    },
    {
      "parameters": {},
      "id": "302a14e5-ee2b-4f6c-8d9e-d07cb86b91b7",
      "name": "Merge Agents 1 & 2",
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3,
      "position": [
        4112,
        -448
      ]
    },
    {
      "parameters": {},
      "id": "43d9ccaa-0fac-4a5b-8e63-4d15af871a0d",
      "name": "Merge with Agent 3",
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3,
      "position": [
        4384,
        -368
      ]
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nAGENT 4: FINAL RISK ASSESSOR v3.0\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nROLE: Synthesize all agent outputs â†’ final risk classification\n\nINPUT:\n- Fact-check: {{ $json.factCheck }}\n- Source: {{ $json.sourceCheck }}\n- Account: {{ $json.accountCheck }}\n\nMISSION: Safety-first risk assessment with classification-appropriate actions\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 0: SAFETY & CLASSIFICATION OVERRIDES (PRIORITY)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nCheck fact-check classification FIRST. Some classifications override composite scoring:\n\nHATE_CONTENT:\nâ†’ risk_level = \"CRITICAL\" or \"HIGH\" (forced)\nâ†’ action = \"Remove pending review\" / \"Flag for immediate safety review\"\nâ†’ urgency = \"immediate\"\nâ†’ human_review = true\nâ†’ confidence = \"HIGH\"\nâ†’ Skip Steps 1-7, go to output\nâ†’ Rationale: \"Targets [group] with [offensive acts]. [Location/time if present]. Violates safety policies.\"\n\nSATIRE:\nâ†’ risk_level = \"MEDIUM\" (forced, not HIGH)\nâ†’ action = \"Add 'Parody/Satire Account' label to all posts\"\nâ†’ urgency = \"within_24h\"\nâ†’ human_review = false\nâ†’ confidence = \"HIGH\"\nâ†’ Continue to composite for documentation\nâ†’ Rationale: \"Disclosed parody account. Bio indicates satirical nature. Labeling prevents confusion.\"\n\nPROPAGANDA:\nâ†’ risk_level = MINIMUM \"MEDIUM\" (forced floor)\nâ†’ action = \"Add context/bias label\"\nâ†’ urgency = \"within_24h\"\nâ†’ human_review = true if deceptiveness > 70\nâ†’ Continue to composite but apply override\nâ†’ Rationale: \"Facts verified but presentation heavily manipulative. [X] bias indicators detected.\"\n\nBIASED_BUT_FACTUAL:\nâ†’ risk_level = MINIMUM \"MEDIUM\" (forced floor)\nâ†’ action = \"Add context about partisan source/bias\"\nâ†’ urgency = \"within_24h\"\nâ†’ human_review = false unless deceptiveness > 60\nâ†’ Continue to composite but apply override\n\nIF none of above â†’ Continue to normal assessment\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 1: EXTRACT DATA\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nFact-check:\n- classification = {{ $json.factCheck.classification }}\n- fact_score = {{ $json.factCheck.fact_accuracy_score }}\n- deceptiveness = {{ $json.factCheck.deceptiveness_score }}\n- intentional = {{ $json.factCheck.appears_intentional }}\n- confidence = {{ $json.factCheck.confidence }}\n\nSource:\n- source_rating = {{ $json.sourceCheck.source_credibility.rating }}\n- source_score = {{ $json.sourceCheck.overall_trustworthiness_score }}\n- source_type = {{ $json.sourceCheck.source_credibility.source_type }}\n\nAccount:\n- bot_assessment = {{ $json.accountCheck.bot_probability }}\n- account_score = {{ $json.accountCheck.authenticity_score }}\n- data_available = {{ $json.accountCheck.data_available }}\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 2: CHECK SOURCE TYPE\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nCheck for special source types that affect weighting:\n\nOFFICIAL GOVERNMENT SOURCES:\nIF source_type = \"government_official\" OR \"government_agency\" OR \"intergovernmental_org\":\nâ†’ High authority for official positions\nâ†’ Adjust weighting in Step 3\nâ†’ Note in special_considerations\n\nVERIFIED ORGANIZATIONS:\nIF source_type = \"official_org\" AND source_rating = \"HIGH\" AND account_score â‰¥ 90:\nâ†’ Trusted official organizations\nâ†’ Adjust weighting in Step 3\n\nPARODY ACCOUNTS:\nIF source_type = \"parody_account\":\nâ†’ Already handled in Step 0 if SATIRE\nâ†’ If NOT SATIRE = undisclosed parody (concerning)\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 3: CALCULATE COMPOSITE SCORE\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nBASE CALCULATION:\nIF data_available = false OR bot_assessment = \"NOT_APPLICABLE\":\n  composite = (fact_score Ã— 0.60) + (source_score Ã— 0.40)\nELSE:\n  composite = (fact_score Ã— 0.50) + (source_score Ã— 0.30) + (account_score Ã— 0.20)\n\nADJUSTMENTS:\n\nGovernment sources:\nIF source_type = \"government_official\" OR \"government_agency\":\n  composite = (fact_score Ã— 0.40) + (source_score Ã— 0.45) + (account_score Ã— 0.15)\n  Note: \"Official government source - increased source weight\"\n\nVery low source:\nIF source_rating = \"VERY_LOW\" (score < 40):\n  composite = composite Ã— 0.85\n  Note: \"Additional 15% penalty for very low source credibility\"\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 4: BASE RISK LEVEL\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nFrom composite score:\n- 0-40 = HIGH RISK\n- 41-70 = MEDIUM RISK\n- 71-100 = LOW RISK\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 5: CLASSIFICATION & SOURCE OVERRIDES\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nApply overrides that can change the base risk level:\n\nESCALATE TO HIGH:\n- classification = \"DISINFORMATION\"\n- classification = \"PROPAGANDA\" AND deceptiveness > 75\n- intentional = true AND deceptiveness > 70 AND fact_score < 50\n- source_rating = \"VERY_LOW\" AND fact_score < 50\n- bot_assessment = \"HIGH_RISK\" AND source_rating = \"LOW\"\n- source_type = \"parody_account\" AND classification != \"SATIRE\"\n\nESCALATE TO MEDIUM (minimum):\n- classification = \"PROPAGANDA\" (from Step 0)\n- classification = \"BIASED_BUT_FACTUAL\" (from Step 0)\n- source_rating = \"LOW\" AND fact_score < 70\n- source_rating = \"LOW\" (score < 60) AND deceptiveness > 40\n  â†’ Even if composite is high, low source + manipulation = context needed\n- deceptiveness > 60 AND fact_score > 70\n- classification = \"UNVERIFIABLE\" AND deceptiveness > 50\n\nKEEP/REDUCE TO LOW:\n- source_type = \"government_official\" AND source_score â‰¥ 90\n- source_type = \"official_org\" AND source_rating = \"HIGH\"\n- classification = \"LEGITIMATE\" AND fact_score â‰¥ 85 AND deceptiveness < 30\n- composite â‰¥ 85 AND confidence = \"high\" AND no concerning flags\n\nSPECIAL - UNVERIFIABLE:\nIF classification = \"UNVERIFIABLE\":\n  Base risk = MEDIUM\n  Adjust based on source:\n  - source_rating = \"VERY_LOW\" â†’ MEDIUM-HIGH\n  - source_rating = \"HIGH\" â†’ MEDIUM-LOW\n  - deceptiveness > 60 â†’ MEDIUM-HIGH\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 6: CONFIDENCE LEVEL\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nHIGH confidence:\n- All agents agree (scores within 15 points)\n- fact_check confidence = \"high\"\n- source_rating = \"HIGH\" or \"VERY_LOW\" (clear signals)\n- classification = \"HATE_CONTENT\" or \"SATIRE\" (clear status)\n\nMEDIUM confidence:\n- Agents partially disagree (scores within 30 points)\n- fact_check confidence = \"medium\"\n- Some ambiguity\n- classification = \"UNVERIFIABLE\"\n\nLOW confidence:\n- Agents strongly disagree (scores > 30 points apart)\n- fact_check confidence = \"low\"\n- Limited data\n- Conflicting signals\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 7: KEY CONCERNS & MITIGATING FACTORS\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nKEY CONCERNS (list if present):\n\nContent concerns:\n- Classification: [classification type]\n- Deceptiveness score: [X] indicates [level] manipulation\n- Fact score: [X] suggests [issues]\n- Intentional deception: [true/false]\n\nSource concerns:\n- Source credibility: [rating] (score: [X])\n- Source type: [type]\n- History: [misinformation/bias/propaganda]\n\nAccount concerns:\n- Bot-like behavior: [assessment]\n- Authenticity concerns\n- Suspicious patterns\n\nConfidence concerns:\n- Assessment confidence: [level]\n- Agent disagreement\n- Limited data\n\nMITIGATING FACTORS (list if present):\n\nContent factors:\n- Factually accurate ([classification])\n- No intent to deceive\n- Disclosed satire/parody\n\nSource factors:\n- Official government source\n- High source credibility (score: [X])\n- Established, verified source\n\nAccount factors:\n- High authenticity (score: [X])\n- Minimal bot activity\n- Verified legitimate entity\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 8: RECOMMENDED ACTION\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nCRITICAL/HIGH RISK:\n\nHATE_CONTENT:\n- action = \"Remove pending review\" / \"Flag for immediate safety review\"\n- rationale = \"Targets [group] with [acts]. [Location/time]. Safety violation.\"\n- urgency = \"immediate\"\n- human_review = true\n\nDISINFORMATION / Intentional false (fact_score < 40):\n- action = \"Flag for review + add warning label\"\n- rationale = \"Deliberately false. [Explain claims and intentionality]\"\n- urgency = \"immediate\"\n- human_review = true\n\nComposite < 40 OR source = VERY_LOW:\n- action = \"Flag for review + add warning label\"\n- rationale = \"[Explain low composite or very low source]\"\n- urgency = \"immediate\"\n- human_review = true\n\nMEDIUM RISK:\n\nSATIRE:\n- action = \"Add 'Parody/Satire Account' label to all posts\"\n- rationale = \"Disclosed parody. Bio indicates satirical nature. Prevent confusion.\"\n- urgency = \"within_24h\"\n- human_review = false\n\nPROPAGANDA / BIASED_BUT_FACTUAL:\n- action = \"Add context/bias label\"\n- rationale = \"Facts accurate but presentation [heavily biased/partisan]. [X] manipulation techniques detected.\"\n- urgency = \"within_24h\"\n- human_review = true if deceptiveness > 70\n\nLOW source credibility (even if facts true):\n- action = \"Add context about source credibility\"\n- rationale = \"Facts verified but source has [LOW/VERY_LOW] credibility (score [X]). History of [issues]. Context warranted.\"\n- urgency = \"within_24h\"\n- human_review = false\n\nUNVERIFIABLE:\n- action = \"Add context label\" / \"Requires investigation\"\n- rationale = \"Cannot verify claims. [Note source credibility]\"\n- urgency = \"within_24h\"\n- human_review = false unless deceptiveness > 60\n\nComposite 41-70:\n- action = \"Add context/fact-check label\"\n- rationale = \"[Specific concerns from data]\"\n- urgency = \"within_24h\"\n- human_review = true if multiple concerns\n\nLOW RISK:\n\nLEGITIMATE + composite > 85 + deceptiveness < 30:\n- action = \"No action needed\" / \"Monitor\"\n- rationale = \"Verified accurate from credible source\"\n- urgency = \"none\" / \"monitor\"\n- human_review = false\n\nGovernment official + score â‰¥ 90:\n- action = \"Monitor\"\n- rationale = \"Official government source. [Opinion vs fact note]\"\n- urgency = \"monitor\"\n- human_review = false\n\nOther low risk:\n- action = \"Monitor\"\n- rationale = \"[Why low risk]\"\n- urgency = \"monitor\"\n- human_review = false\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nOUTPUT (JSON ONLY)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n{\n  \"final_assessment\": {\n    \"risk_level\": \"CRITICAL|HIGH|MEDIUM|LOW\",\n    \"composite_score\": number,\n    \"confidence\": \"HIGH|MEDIUM|LOW\",\n    \"data_completeness\": \"FULL|PARTIAL\",\n    \"special_considerations\": \"Note: safety override, official source, satire, propaganda floor, source credibility override, or 'N/A'\"\n  },\n  \"contributing_factors\": {\n    \"fact_check_classification\": actual value,\n    \"fact_check_score\": actual number,\n    \"source_credibility\": actual rating,\n    \"source_score\": actual number,\n    \"source_type\": actual type,\n    \"bot_risk_assessment\": actual assessment,\n    \"account_authenticity_score\": actual number\n  },\n  \"key_concerns\": [\n    \"Specific concerns using actual data and classifications\"\n  ],\n  \"mitigating_factors\": [\n    \"Specific mitigating factors using actual data\"\n  ],\n  \"recommended_action\": {\n    \"primary_action\": \"Action appropriate for risk and classification\",\n    \"rationale\": \"Clear explanation using actual agent data\",\n    \"urgency\": \"immediate|within_24h|monitor|none\"\n  },\n  \"human_review_needed\": true/false,\n  \"summary\": \"1-2 sentences using actual classifications and scores\"\n}\n\nCLASSIFICATION HANDLING:\n- HATE_CONTENT â†’ CRITICAL/HIGH, immediate\n- SATIRE â†’ MEDIUM, label, 24h\n- PROPAGANDA â†’ MEDIUM minimum, context, 24h\n- BIASED_BUT_FACTUAL â†’ MEDIUM minimum, context, 24h\n- DISINFORMATION â†’ HIGH, flag, immediate\n- UNVERIFIABLE â†’ MEDIUM default\n- LEGITIMATE â†’ LOW (if high composite + low deceptiveness)\n\nSOURCE OVERRIDE:\n- LOW source (< 60) + deceptiveness > 40 â†’ MEDIUM minimum\n- Adds context even if facts are true\n- \"Facts verified but source has credibility concerns\"\n\nReturn ONLY valid JSON. No markdown.",
        "options": {
          "systemMessage": "You are final decision agent for misinformation risk. Return ONLY valid JSON, no markdown. Handle missing data gracefully.",
          "maxIterations": 1
        }
      },
      "id": "9aeaf5a8-16f3-45ac-a2b1-62e43b8244ca",
      "name": "Agent 4 - Decision",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.6,
      "position": [
        4944,
        -464
      ],
      "retryOnFail": true
    },
    {
      "parameters": {
        "jsCode": "// Format Agent 4 output for Google Sheets\nconst agent4Output = $input.first().json.output;\nconst originalData = $('Parse Input Data').first().json;\n\n// Parse Agent 4 JSON output\nlet assessment = {};\ntry {\n  if (typeof agent4Output === 'string') {\n    const cleaned = agent4Output.trim()\n      .replace(/^```json\\s*/i, '')\n      .replace(/^```\\s*/i, '')\n      .replace(/\\s*```$/i, '');\n    assessment = JSON.parse(cleaned);\n  } else {\n    assessment = agent4Output;\n  }\n} catch (e) {\n  assessment = { error: 'Failed to parse Agent 4 output' };\n}\n\n// Determine source type\nconst sourceType = originalData.sourceType || 'unknown';\nconst source = sourceType === 'twitter' ? 'Twitter' : \n               sourceType === 'dataset' ? 'WhatsApp/Dataset' : \n               'Unknown';\n\n// Get original content\nconst content = originalData.tweetText || originalData.text || 'N/A';\nconst contentPreview = content.substring(0, 200);\n\n// Extract scores\nconst riskLevel = assessment.final_assessment?.risk_level || 'UNKNOWN';\nconst compositeScore = assessment.final_assessment?.composite_score || 0;\nconst confidence = assessment.final_assessment?.confidence || 'UNKNOWN';\n\n// Extract contributing factors\nconst factCheckClass = assessment.contributing_factors?.fact_check_classification || 'N/A';\nconst factCheckScore = assessment.contributing_factors?.fact_check_score || 0;\nconst sourceCredibility = assessment.contributing_factors?.source_credibility || 'N/A';\nconst sourceScore = assessment.contributing_factors?.source_score || 0;\nconst accountAuth = assessment.contributing_factors?.account_authenticity || 'N/A';\nconst accountScore = assessment.contributing_factors?.account_score || 0;\n\n// Extract concerns and actions\nconst keyConcerns = (assessment.key_concerns || []).join('; ');\nconst recommendedAction = assessment.recommended_action?.primary_action || 'N/A';\nconst urgency = assessment.recommended_action?.urgency || 'N/A';\nconst rationale = assessment.recommended_action?.rationale || 'N/A';\nconst summary = assessment.summary || 'N/A';\n\n// Get metadata\nconst tweetUrl = originalData.tweetMetadata?.tweet_url || originalData.tweet_url || 'N/A';\nconst author = originalData.accountData?.username || 'N/A';\nconst dataset = originalData.dataset || 'N/A';\nconst supabaseId = originalData.supabase_id || 'N/A';\n\nreturn {\n  json: {\n    timestamp: new Date().toISOString(),\n    source: source,\n    source_type: sourceType,\n    content_preview: contentPreview,\n    full_content: content,\n    \n    // Risk Assessment\n    risk_level: riskLevel,\n    composite_score: compositeScore,\n    confidence: confidence,\n    \n    // Fact Check\n    fact_check_classification: factCheckClass,\n    fact_check_score: factCheckScore,\n    \n    // Source Credibility\n    source_credibility_rating: sourceCredibility,\n    source_credibility_score: sourceScore,\n    \n    // Account Analysis\n    account_authenticity: accountAuth,\n    account_score: accountScore,\n    \n    // Actions & Concerns\n    key_concerns: keyConcerns,\n    recommended_action: recommendedAction,\n    urgency: urgency,\n    rationale: rationale,\n    summary: summary,\n    \n    // Metadata\n    tweet_url: tweetUrl,\n    author: author,\n    dataset: dataset,\n    supabase_id: supabaseId,\n    \n    // Raw output for reference\n    raw_assessment: JSON.stringify(assessment)\n  }\n};"
      },
      "id": "d21a9e4d-c091-4a6c-aa70-b11a4a7effbf",
      "name": "Format for Google Sheets",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        5328,
        -464
      ]
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        2224,
        -224
      ],
      "id": "1f8e6ebf-1750-45b6-ace4-cf0aa6428400",
      "name": "Google Gemini Chat Model2",
      "credentials": {
        "googlePalmApi": {
          "id": "MLCxKRnMtF7Rthld",
          "name": "Google Gemini(PaLM) Api account"
        }
      }
    },
    {
      "parameters": {
        "model": "meta-llama/llama-4-scout-17b-16e-instruct",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGroq",
      "typeVersion": 1,
      "position": [
        3152,
        -880
      ],
      "id": "d75659a2-92d3-4baa-b3c5-4380029317b6",
      "name": "Groq Chat Model",
      "credentials": {
        "groqApi": {
          "id": "aDgjoiavOeg5nbsa",
          "name": "Groq account 2"
        }
      }
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        4944,
        -272
      ],
      "id": "34b8348f-2eb4-43c8-81e5-ca00e3c1608b",
      "name": "Google Gemini Chat Model",
      "credentials": {
        "googlePalmApi": {
          "id": "MLCxKRnMtF7Rthld",
          "name": "Google Gemini(PaLM) Api account"
        }
      }
    },
    {
      "parameters": {
        "updates": [
          "messages"
        ],
        "options": {}
      },
      "type": "n8n-nodes-base.whatsAppTrigger",
      "typeVersion": 1,
      "position": [
        -816,
        -624
      ],
      "id": "18d20704-8eff-43ed-b3d5-47d91d864196",
      "name": "WhatsApp Trigger",
      "webhookId": "1f66d001-0eb2-49c9-a002-a5ac810c46c5",
      "credentials": {
        "whatsAppTriggerApi": {
          "id": "vSb7Wo9wZmEFxgbX",
          "name": "WhatsApp OAuth account"
        }
      }
    },
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "const item = $input.item;\nconst body = item.json.messages?.[0]?.text?.body || 'F600';\n\nconst datasetType = body.charAt(0).toUpperCase();\nconst idx = parseInt(body.substring(1)) || 600;\nconst dataset = datasetType === 'T' ? 'true-news' : 'false-news';\n\nreturn {\n  json: {\n    datasetType: datasetType,\n    idx: idx,\n    dataset: dataset,\n    tableId: dataset,\n    rowId: idx\n  }\n};"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -496,
        -624
      ],
      "id": "facdb488-e172-43b7-9ac2-b75592f6eb92",
      "name": "WhatsApp Input Parser"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=Use the supabase tool to get data from the dataset.\n\nInput:\n- Table: {{ $json.tableId }}\n- Dataset Type: {{ $json.datasetType }}\n- Row ID: {{ $json.rowId }}\n\nFormat output as JSON:\n{\n  \"text\": \"the text field from supabase\",\n  \"tweetSource\": \"{{ $json.tableId }}\",\n  \"sourceType\": \"dataset\",\n  \"tweetMetadata\": {},\n  \"accountData\": {},\n  \"supabase_id\": {{ $json.rowId }},\n  \"dataset\": \"{{ $json.tableId }}\",\n  \"datasetType\": \"{{ $json.datasetType }}\",\n  \"title\": \"title field if exists\",\n  \"subject\": \"subject field if exists\",\n  \"date\": \"date field if exists\"\n}\n\nReturn only valid JSON.",
        "options": {
          "systemMessage": "You are a data formatter. Extract from Supabase and format as JSON. Return only valid JSON.",
          "maxIterations": 3
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.6,
      "position": [
        -208,
        -624
      ],
      "id": "2a283509-77e4-408d-91a4-6bf90e75d398",
      "name": "AI Agent - Supabase Formatter",
      "executeOnce": false,
      "alwaysOutputData": true
    },
    {
      "parameters": {
        "operation": "get",
        "tableId": "={{ $json.dataset }}",
        "filters": {
          "conditions": [
            {
              "keyName": "id",
              "keyValue": "={{ $json.idx }}"
            }
          ]
        }
      },
      "type": "n8n-nodes-base.supabaseTool",
      "typeVersion": 1,
      "position": [
        -64,
        -400
      ],
      "id": "91023624-26cf-4802-8c83-9ebacf8cc28d",
      "name": "Get row from Dataset (Supabase)",
      "credentials": {
        "supabaseApi": {
          "id": "Cgrz5nOdspcCgDyr",
          "name": "Supabase account"
        }
      }
    },
    {
      "parameters": {
        "options": {
          "maxOutputTokens": 1000
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        -208,
        -384
      ],
      "id": "158abb22-18e0-4b54-ae83-81abb84300e5",
      "name": "Google Gemini Chat Model3",
      "credentials": {
        "googlePalmApi": {
          "id": "MLCxKRnMtF7Rthld",
          "name": "Google Gemini(PaLM) Api account"
        }
      }
    },
    {
      "parameters": {},
      "id": "7c20b692-91f0-473f-8c7c-0d4e1b019216",
      "name": "Merge Dataset & Twitter Inputs",
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3,
      "position": [
        112,
        -608
      ]
    },
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "const item = $input.item.json;\n\nconsole.log('ğŸ” Format Input Data received:', Object.keys(item));\nconsole.log('ğŸ‘¤ accountData received:', item.accountData);\nconsole.log('ğŸ“… created_at received:', item.created_at);  // â† ADD: Debug log\n\n// Check if this is Twitter data (from viral tweets or WhatsApp)\nconst isTwitterViral = item.tweetSource === 'twitter_viral' || item.tweetSource === 'twitter_viral_random' || (item.tweetText && item.sourceType === 'twitter');\nconst isWhatsAppTwitter = item.body && item.body.tweetText;\nconst isDataset = item.dataset || (item.text && !isTwitterViral);\n\nif (isTwitterViral) {\n  // Data from enriched Twitter - PRESERVE enriched accountData!\n  const result = {\n    json: {\n      tweetText: item.tweetText || item.tweet_text || '',\n      tweetSource: item.tweetSource || 'twitter_viral',\n      tweetMetadata: item.tweetMetadata || {\n        virality_score: item.virality_score,\n        engagement: item.engagement,\n        author: item.author,\n        verified: item.verified,\n        tweet_id: item.tweet_id,\n        tweet_url: item.tweet_url,\n        created_at: item.created_at || 'unknown'  // â† ADD THIS LINE!\n      },\n      // CRITICAL: Use enriched accountData if available!\n      accountData: item.accountData || {},\n      sourceType: 'twitter',\n      tweet_id: item.tweet_id,\n      tweet_url: item.tweet_url,\n      virality_score: item.virality_score,\n      engagement: item.engagement,\n      author: item.author\n    }\n  };\n  \n  console.log('âœ… Formatted Twitter data');\n  console.log('âœ… accountData in result:', result.json.accountData);\n  console.log('âœ… created_at in result:', result.json.tweetMetadata.created_at);  // â† ADD: Debug log\n  \n  return result;\n  \n} else if (isWhatsAppTwitter) {\n  // Data from WhatsApp (nested under body)\n  return {\n    json: {\n      tweetText: item.body.tweetText || '',\n      tweetSource: item.body.tweetSource || 'whatsapp',\n      tweetMetadata: item.body.tweetMetadata || {\n        created_at: item.body.created_at || 'unknown'  // â† ADD THIS!\n      },\n      accountData: item.body.accountData || {},\n      sourceType: 'twitter'\n    }\n  };\n  \n} else if (isDataset) {\n  // Data from dataset\n  return {\n    json: {\n      tweetText: item.text || '',\n      tweetSource: item.tweetSource || item.dataset || 'dataset',\n      tweetMetadata: item.tweetMetadata || {\n        date: item.date || 'unknown'  // â† Datasets might have different date field\n      },\n      accountData: item.accountData || {},\n      sourceType: item.sourceType || 'dataset',\n      supabase_id: item.supabase_id,\n      dataset: item.dataset,\n      datasetType: item.datasetType,\n      title: item.title,\n      subject: item.subject,\n      date: item.date\n    }\n  };\n  \n} else {\n  // Fallback for unknown format\n  console.log('âš ï¸ Unknown format, using fallback');\n  return {\n    json: {\n      tweetText: JSON.stringify(item),\n      tweetSource: 'unknown',\n      tweetMetadata: {\n        created_at: 'unknown'  // â† ADD THIS!\n      },\n      accountData: {},\n      sourceType: 'manual'\n    }\n  };\n}"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        608,
        -384
      ],
      "id": "76d20e3c-7ff5-4911-8724-0f4e13c85b28",
      "name": "Format Input Data"
    },
    {
      "parameters": {
        "jsCode": "// Combine all 3 agent outputs into one structured object\nconst allInputs = $input.all();\n\n// Safe parse function\nfunction safeParse(data) {\n  if (!data) return null;\n  if (typeof data === 'object' && !Array.isArray(data)) return data;\n  if (typeof data === 'string') {\n    try {\n      let cleaned = data.trim()\n        .replace(/^```json\\s*/i, '')\n        .replace(/^```\\s*/i, '')\n        .replace(/\\s*```$/i, '');\n      return JSON.parse(cleaned);\n    } catch (e) {\n      console.error('Parse error:', e);\n      return null;\n    }\n  }\n  return null;\n}\n\n// Parse each input\nconst factCheck = safeParse(allInputs[0]?.json?.output);\nconst sourceCheck = safeParse(allInputs[1]?.json?.output);\nconst accountCheck = safeParse(allInputs[2]?.json?.output);\n\n// Return combined data\nreturn {\n  json: {\n    factCheck: factCheck || {\n      classification: 'UNVERIFIABLE',\n      fact_accuracy_score: 50,\n      deceptiveness_score: 50,\n      appears_intentional: false,\n      confidence: 'low'\n    },\n    sourceCheck: sourceCheck || {\n      source_credibility: { rating: 'UNKNOWN', score: 50 },\n      overall_trustworthiness_score: 50\n    },\n    accountCheck: accountCheck || {\n      bot_probability: 'NOT_APPLICABLE',\n      authenticity_score: 50,\n      data_available: false\n    }\n  }\n};"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        4656,
        -368
      ],
      "id": "ac384129-39cb-446b-be3a-bfdb5606302c",
      "name": "Combine for Agent 4"
    },
    {
      "parameters": {
        "rule": {
          "interval": [
            {
              "field": "hours",
              "hoursInterval": 4
            }
          ]
        }
      },
      "id": "5d8c8c17-1e3b-46f3-a1a6-439767cf81e0",
      "name": "Every 4 Hours",
      "type": "n8n-nodes-base.scheduleTrigger",
      "typeVersion": 1.2,
      "position": [
        -992,
        -96
      ]
    },
    {
      "parameters": {},
      "type": "n8n-nodes-base.manualTrigger",
      "typeVersion": 1,
      "position": [
        -1088,
        208
      ],
      "id": "009bd1b3-aa61-4448-8042-4c54a8f4cc31",
      "name": "Manual Trigger"
    },
    {
      "parameters": {
        "url": "https://twitter-api45.p.rapidapi.com/search.php",
        "sendQuery": true,
        "queryParameters": {
          "parameters": [
            {
              "name": "query",
              "value": "(breaking OR urgent OR news) min_retweets:500 lang:en"
            },
            {
              "name": "search_type",
              "value": "Latest"
            },
            {
              "name": "count",
              "value": "1"
            }
          ]
        },
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "X-RapidAPI-Key",
              "value": "80ab7267a3msh12d875a20cb2293p104766jsnd30f01f53a5c"
            },
            {
              "name": "X-RapidAPI-Host",
              "value": "twitter-api45.p.rapidapi.com"
            }
          ]
        },
        "options": {}
      },
      "id": "a3f5bae1-e462-49a5-8a0c-79d562325a2e",
      "name": "Search Viral News Tweets",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -624,
        0
      ]
    },
    {
      "parameters": {
        "jsCode": "// Configuration\nconst ITEM_LIMIT = 1;\nconst TOP_N_POOL = 10;\n\nconsole.log('ğŸ¯ Config: Return', ITEM_LIMIT, 'random tweet(s) from top', TOP_N_POOL);\n\nconst response = $input.first().json;\n\n// Get tweets array\nconst tweets = response.timeline || response.tweets || response.results || response.data || [];\n\nif (!Array.isArray(tweets) || tweets.length === 0) {\n  console.log('âŒ No tweets found');\n  return [{json: {error: 'No tweets found', raw: response}}];\n}\n\nconsole.log('âœ… Found', tweets.length, 'tweets');\n\n// Calculate virality for each tweet\nconst ranked = tweets.map(t => {\n  const retweets = t.retweet_count || t.retweetCount || t.retweets || t.public_metrics?.retweet_count || 0;\n  const likes = t.favorite_count || t.favoriteCount || t.likeCount || t.likes || t.favorites || t.public_metrics?.like_count || 0;\n  const replies = t.reply_count || t.replyCount || t.replies || t.public_metrics?.reply_count || 0;\n  const quotes = t.quote_count || t.quoteCount || t.quotes || t.public_metrics?.quote_count || 0;\n  \n  const viralityScore = (retweets * 2) + likes + (replies * 3) + (quotes * 2);\n  \n  return {\n    ...t,\n    virality_score: viralityScore,\n    _retweets: retweets,\n    _likes: likes,\n    _replies: replies,\n    _quotes: quotes\n  };\n});\n\n// Sort by virality (highest first)\nranked.sort((a, b) => b.virality_score - a.virality_score);\n\n// Take top N pool\nconst topPool = ranked.slice(0, Math.min(TOP_N_POOL, ranked.length));\n\nconsole.log('ğŸ² Top', topPool.length, 'viral tweets:', topPool.map(t => t.virality_score));\n\n// Randomly select from the pool\nconst shuffled = topPool.sort(() => Math.random() - 0.5);\nconst selected = shuffled.slice(0, ITEM_LIMIT);\n\nconsole.log('âœ¨ Randomly selected tweet with virality:', selected[0]?.virality_score);\n\n// Format output\nreturn selected.map((t, i) => {\n  const user = t.user_info || t.user || t.author || {};\n  const id = t.id_str || t.id || t.tweet_id || t.tweetId;\n  const text = t.full_text || t.text || t.tweet_text || t.content || '';\n  const username = user.screen_name || user.username || t.screen_name || 'unknown';\n  \n  return {\n    json: {\n      rank: 'random_from_top_' + TOP_N_POOL,\n      tweet_id: id,\n      tweet_text: text,\n      tweet_url: id ? `https://twitter.com/i/web/status/${id}` : 'N/A',\n      virality_score: t.virality_score,\n      engagement: `${t._retweets} RT | ${t._likes} â™¥ | ${t._replies} ğŸ’¬ | ${t._quotes} ğŸ’¬`,\n      author: `@${username}`,\n      verified: (user.verified || t.verified) ? 'âœ“' : 'âœ—',\n      preview: text.substring(0, 150) + '...',\n      created_at: t.created_at || 'unknown',  // â† ONLY LINE ADDED!\n      \n      // For misinformation pipeline\n      tweetText: text,\n      tweetSource: 'twitter_viral_random',\n      sourceType: 'twitter',\n      accountData: {\n        username: username,\n        verified: user.verified || t.verified || false,\n        followers: user.followers_count || user.followersCount || 0\n      }\n    }\n  };\n});"
      },
      "id": "9a0006dc-3817-4f3a-a51d-a827bdf0f39c",
      "name": "Get Top N Most Viral",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -400,
        0
      ]
    },
    {
      "parameters": {
        "operation": "append",
        "documentId": {
          "__rl": true,
          "value": "19x-lnuAPH9FbvyLR8es4pUxxw5QXHhsLVpBXCfBxWfc",
          "mode": "list",
          "cachedResultName": "tetst",
          "cachedResultUrl": "https://docs.google.com/spreadsheets/d/19x-lnuAPH9FbvyLR8es4pUxxw5QXHhsLVpBXCfBxWfc/edit?usp=drivesdk"
        },
        "sheetName": {
          "__rl": true,
          "value": "gid=0",
          "mode": "list",
          "cachedResultName": "Sheet1",
          "cachedResultUrl": "https://docs.google.com/spreadsheets/d/19x-lnuAPH9FbvyLR8es4pUxxw5QXHhsLVpBXCfBxWfc/edit#gid=0"
        },
        "columns": {
          "mappingMode": "autoMapInputData",
          "value": {},
          "matchingColumns": [],
          "schema": [],
          "attemptToConvertTypes": false,
          "convertFieldsToString": false
        },
        "options": {}
      },
      "type": "n8n-nodes-base.googleSheets",
      "typeVersion": 4.7,
      "position": [
        5568,
        -464
      ],
      "id": "42dbd3e8-bdc0-4a7a-9e34-ae56c6d9caca",
      "name": "Append row in sheet",
      "credentials": {
        "googleSheetsOAuth2Api": {
          "id": "pOlMsCkST1NkdxUo",
          "name": "Google Sheets account 2"
        }
      }
    },
    {
      "parameters": {
        "url": "=https://twitter-api45.p.rapidapi.com/screenname.php?screenname={{ $json.accountData.username }}",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "X-RapidAPI-Key",
              "value": "80ab7267a3msh12d875a20cb2293p104766jsnd30f01f53a5c"
            },
            {
              "name": "X-RapidAPI-Host",
              "value": "twitter-api45.p.rapidapi.com"
            }
          ]
        },
        "options": {
          "response": {
            "response": {}
          }
        }
      },
      "id": "5b14603c-7541-4e68-8a0b-52a8c9f49dad",
      "name": "Enrich Twitter Account Data",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -224,
        240
      ]
    },
    {
      "parameters": {
        "jsCode": "const item = $input.first().json;\n\nconsole.log('ğŸ“¥ Input keys:', Object.keys(item));\nconsole.log('ğŸ” Has enrichmentData?', !!item.enrichmentData);\n\n// Original tweet data\nconst originalData = { ...item };\ndelete originalData.enrichmentData; // Remove the API response from spread\n\n// API response\nconst apiResponse = item.enrichmentData;\n\nif (!apiResponse || !Array.isArray(apiResponse) || apiResponse.length === 0) {\n  console.log('âŒ No enrichment data, returning original');\n  return { json: originalData };\n}\n\n// Extract user data\nconst userData = apiResponse[0];\nconsole.log('ğŸ‘¤ User data keys:', Object.keys(userData));\n\n// Extract values\nconst followers = userData.sub_count || 0;\nconst following = userData.friends || 0;\nconst totalTweets = userData.statuses_count || 0;\nconst isVerified = userData.blue_verified || false;\n\nconsole.log('ğŸ“Š Extracted - Followers:', followers, 'Following:', following);\n\n// Calculate\nconst createdAt = new Date(userData.created_at);\nconst accountAgeDays = Math.floor((Date.now() - createdAt.getTime()) / (1000 * 60 * 60 * 24));\nconst tweetsPerDay = accountAgeDays > 0 ? (totalTweets / accountAgeDays).toFixed(2) : '0';\nconst followerRatio = following > 0 ? (followers / following).toFixed(2) : String(followers);\n\n// Profile completeness\nlet score = 0;\nif (userData.avatar) score += 1;\nif (userData.desc) score += 1;\nif (userData.location) score += 1;\nif (isVerified) score += 2;\nif (userData.header_image) score += 1;\nif (userData.website) score += 1;\n\n// Build enriched data\nconst enrichedAccountData = {\n  username: userData.name || userData.profile,\n  verified: isVerified,\n  followers: followers,\n  following: following,\n  follower_ratio: followerRatio,\n  total_tweets: totalTweets,\n  account_age_days: accountAgeDays,\n  tweets_per_day: tweetsPerDay,\n  profile_completeness_score: `${score}/7`,\n  has_profile_image: !!userData.avatar,\n  has_bio: !!userData.desc,\n  has_location: !!userData.location,\n  has_banner: !!userData.header_image,\n  has_website: !!userData.website,\n  created_at: userData.created_at,\n  description: userData.desc || '',\n  location: userData.location || '',\n  website: userData.website || ''\n};\n\nconsole.log('âœ… Enriched accountData:', enrichedAccountData);\n\n// Return original data with enriched accountData\nreturn {\n  json: {\n    ...originalData,\n    accountData: enrichedAccountData\n  }\n};\n"
      },
      "id": "ea625ab3-eddd-483f-b7d3-79cd20bb1f88",
      "name": "Merge Enriched Data",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -48,
        240
      ]
    },
    {
      "parameters": {},
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3.2,
      "position": [
        192,
        -96
      ],
      "id": "92d18cf2-6712-481b-aca4-cebfa1f96c1a",
      "name": "Merge2"
    },
    {
      "parameters": {
        "jsCode": "const inputs = $input.all();\n\nif (inputs.length !== 2) {\n  return { json: inputs[0]?.json || {} };\n}\n\n// Item 0: Original tweet data\nconst originalData = inputs[0].json;\n\n// Item 1: API response\nconst apiResponse = inputs[1].json;\n\n// Extract user data\nconst userData = apiResponse;\n\n// Extract values\nconst followers = userData.sub_count || 0;\nconst following = userData.friends || 0;\nconst totalTweets = userData.statuses_count || 0;\nconst isVerified = userData.blue_verified || false;\n\n// Calculate derived fields\nconst createdAt = new Date(userData.created_at);\nconst accountAgeDays = Math.floor((Date.now() - createdAt.getTime()) / (1000 * 60 * 60 * 24));\nconst tweetsPerDay = accountAgeDays > 0 ? (totalTweets / accountAgeDays).toFixed(2) : '0';\nconst followerRatio = following > 0 ? (followers / following).toFixed(2) : String(followers);\n\n// Calculate profile completeness score\nlet score = 0;\nif (userData.avatar) score += 1;\nif (userData.desc) score += 1;\nif (userData.location) score += 1;\nif (isVerified) score += 2;\nif (userData.header_image) score += 1;\nif (userData.website) score += 1;\n\n// Build enriched accountData\nconst enrichedAccountData = {\n  username: userData.name,\n  verified: isVerified,\n  followers: followers,\n  following: following,\n  follower_ratio: followerRatio,\n  total_tweets: totalTweets,\n  account_age_days: accountAgeDays,\n  tweets_per_day: tweetsPerDay,\n  profile_completeness_score: `${score}/7`,\n  has_profile_image: !!userData.avatar,\n  has_bio: !!userData.desc,\n  has_location: !!userData.location,\n  has_banner: !!userData.header_image,\n  has_website: !!userData.website,\n  created_at: userData.created_at,\n  description: userData.desc || '',\n  location: userData.location || '',\n  website: userData.website || ''\n};\n\n// Return original data with enriched accountData\nreturn {\n  json: {\n    ...originalData,\n    accountData: enrichedAccountData\n  }\n};"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        400,
        -96
      ],
      "id": "42721ee7-096d-405e-8a02-7e17883009e6",
      "name": "Build Final Enriched Data"
    },
    {
      "parameters": {
        "modelName": "models/gemini-2.5-pro",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        2512,
        -672
      ],
      "id": "114ace93-27b1-4d36-84be-a63e77bd24b9",
      "name": "Google Gemini Chat Model4",
      "credentials": {
        "googlePalmApi": {
          "id": "MLCxKRnMtF7Rthld",
          "name": "Google Gemini(PaLM) Api account"
        }
      }
    },
    {
      "parameters": {
        "model": "meta-llama/llama-4-scout-17b-16e-instruct",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGroq",
      "typeVersion": 1,
      "position": [
        2784,
        -256
      ],
      "id": "2f1f8942-7927-4ecd-b1c7-dd1471359150",
      "name": "Groq Chat Model1",
      "credentials": {
        "groqApi": {
          "id": "aDgjoiavOeg5nbsa",
          "name": "Groq account 2"
        }
      }
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        2240,
        272
      ],
      "id": "8908b12a-c18c-4bb9-bea1-7ae2f77ba64a",
      "name": "Google Gemini Chat Model5",
      "credentials": {
        "googlePalmApi": {
          "id": "MLCxKRnMtF7Rthld",
          "name": "Google Gemini(PaLM) Api account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "try {\n  // Get both outputs\n  const backupOutputRaw = $input.item.json.output;\n  const primaryOutputRaw = $('Check Agent 1 Confidence').first().json.output;\n  \n  // Parse function\n  function safeParse(data) {\n    if (!data) return null;\n    if (typeof data === 'object') return data;\n    if (typeof data === 'string') {\n      try {\n        let cleaned = data.trim()\n          .replace(/^```json\\s*/i, '')\n          .replace(/^```\\s*/i, '')\n          .replace(/\\s*```$/i, '');\n        return JSON.parse(cleaned);\n      } catch (e) {\n        return null;\n      }\n    }\n    return null;\n  }\n  \n  const primary = safeParse(primaryOutputRaw);\n  const backup = safeParse(backupOutputRaw);\n  \n  if (!primary || !backup) {\n    return {\n      json: {\n        error: \"Failed to parse\",\n        primaryParsed: !!primary,\n        backupParsed: !!backup\n      }\n    };\n  }\n  \n  // Check if both agents agree on special classifications\n  const primaryClass = primary.classification;\n  const backupClass = backup.classification;\n  \n  // If both agree on UNVERIFIABLE, SATIRICAL, or CLICK-BAIT, keep it\n  if (primaryClass === backupClass && \n      ['UNVERIFIABLE', 'SATIRICAL', 'CLICK-BAIT'].includes(primaryClass)) {\n    return {\n      json: {\n        output: JSON.stringify({\n          classification: primaryClass,\n          fact_accuracy_score: Math.round(\n            ((primary.fact_accuracy_score || 50) + (backup.fact_accuracy_score || 50)) / 2\n          ),\n          deceptiveness_score: Math.round(\n            ((primary.deceptiveness_score || 50) + (backup.deceptiveness_score || 50)) / 2\n          ),\n          appears_intentional: primary.appears_intentional || backup.appears_intentional,\n          confidence: primary.confidence || backup.confidence || 'medium',\n          verified_claims: backup.verified_claims || primary.verified_claims || [],\n          false_news_patterns_detected: [...new Set([\n            ...(primary.false_news_patterns_detected || []),\n            ...(backup.false_news_patterns_detected || [])\n          ])],\n          key_omissions: [...new Set([\n            ...(primary.key_omissions || []),\n            ...(backup.key_omissions || [])\n          ])],\n          manipulation_techniques: [...new Set([\n            ...(primary.manipulation_techniques || []),\n            ...(backup.manipulation_techniques || [])\n          ])],\n          overall_assessment: `Primary: ${primary.overall_assessment || 'N/A'}. Backup: ${backup.overall_assessment || 'N/A'}. Both agents agree on ${primaryClass}.`,\n          recommendation: primary.recommendation || backup.recommendation || 'REQUIRES_MORE_INVESTIGATION',\n          dual_verification: true,\n          agent_comparison: {\n            fact_score_diff: Math.abs((primary.fact_accuracy_score || 50) - (backup.fact_accuracy_score || 50)),\n            deceptiveness_diff: Math.abs((primary.deceptiveness_score || 50) - (backup.deceptiveness_score || 50)),\n            avg_difference: Math.round(\n              (Math.abs((primary.fact_accuracy_score || 50) - (backup.fact_accuracy_score || 50)) +\n               Math.abs((primary.deceptiveness_score || 50) - (backup.deceptiveness_score || 50))) / 2\n            ),\n            primary_classification: primaryClass,\n            backup_classification: backupClass\n          }\n        })\n      }\n    };\n  }\n  \n  // Average scores\n  const avgFactScore = Math.round(\n    ((primary.fact_accuracy_score || 50) + (backup.fact_accuracy_score || 50)) / 2\n  );\n  \n  const avgDeceptScore = Math.round(\n    ((primary.deceptiveness_score || 50) + (backup.deceptiveness_score || 50)) / 2\n  );\n  \n  // Determine classification (for disagreements or standard classifications)\n  let finalClassification;\n  const avgIntent = primary.appears_intentional || backup.appears_intentional;\n  \n  // Check if either agent said UNVERIFIABLE\n  if (primaryClass === 'UNVERIFIABLE' || backupClass === 'UNVERIFIABLE') {\n    finalClassification = 'UNVERIFIABLE';\n  }\n  // Check for SATIRICAL\n  else if (primaryClass === 'SATIRICAL' || backupClass === 'SATIRICAL') {\n    finalClassification = 'SATIRICAL';\n  }\n  // Check for CLICK-BAIT\n  else if (primaryClass === 'CLICK-BAIT' || backupClass === 'CLICK-BAIT') {\n    finalClassification = 'CLICK-BAIT';\n  }\n  // Standard classification logic\n  else if (avgFactScore < 40) {\n    finalClassification = avgIntent ? 'DISINFORMATION' : 'MISINFORMATION';\n  } else if (avgFactScore >= 60 && avgDeceptScore > 60) {\n    finalClassification = 'PROPAGANDA';\n  } else if (avgFactScore > 80 && avgDeceptScore < 30) {\n    finalClassification = 'LEGITIMATE';\n  } else {\n    finalClassification = 'BIASED_BUT_FACTUAL';\n  }\n  \n  // Calculate confidence\n  const factDiff = Math.abs((primary.fact_accuracy_score || 50) - (backup.fact_accuracy_score || 50));\n  const deceptDiff = Math.abs((primary.deceptiveness_score || 50) - (backup.deceptiveness_score || 50));\n  const avgDiff = (factDiff + deceptDiff) / 2;\n  \n  const finalConfidence = avgDiff <= 10 ? 'high' : avgDiff <= 20 ? 'medium' : 'low';\n  \n  // Recommendation\n  let recommendation;\n  if (finalClassification === 'UNVERIFIABLE') {\n    recommendation = 'REQUIRES_MORE_INVESTIGATION';\n  } else if (finalClassification === 'PROPAGANDA' || finalClassification === 'DISINFORMATION') {\n    recommendation = 'FLAG_AS_FALSE_NEWS';\n  } else if (finalClassification === 'MISINFORMATION' || finalClassification === 'BIASED_BUT_FACTUAL') {\n    recommendation = 'LABEL_AS_BIASED';\n  } else {\n    recommendation = 'NO_ACTION_NEEDED';\n  }\n  \n  // Merge arrays\n  const mergedPatterns = [...new Set([\n    ...(primary.false_news_patterns_detected || []),\n    ...(backup.false_news_patterns_detected || [])\n  ])];\n  \n  const mergedOmissions = [...new Set([\n    ...(primary.key_omissions || []),\n    ...(backup.key_omissions || [])\n  ])];\n  \n  const mergedTechniques = [...new Set([\n    ...(primary.manipulation_techniques || []),\n    ...(backup.manipulation_techniques || [])\n  ])];\n  \n  // Return merged result\n  return {\n    json: {\n      output: JSON.stringify({\n        classification: finalClassification,\n        fact_accuracy_score: avgFactScore,\n        deceptiveness_score: avgDeceptScore,\n        appears_intentional: avgIntent,\n        confidence: finalConfidence,\n        verified_claims: backup.verified_claims || primary.verified_claims || [],\n        false_news_patterns_detected: mergedPatterns,\n        key_omissions: mergedOmissions,\n        manipulation_techniques: mergedTechniques,\n        overall_assessment: `Primary: ${primary.overall_assessment || 'N/A'}. Backup: ${backup.overall_assessment || 'N/A'}. Agreement: ${avgDiff <= 10 ? 'Strong' : 'Moderate'} (diff: ${Math.round(avgDiff)})`,\n        recommendation: recommendation,\n        dual_verification: true,\n        agent_comparison: {\n          fact_score_diff: factDiff,\n          deceptiveness_diff: deceptDiff,\n          avg_difference: Math.round(avgDiff),\n          primary_classification: primaryClass,\n          backup_classification: backupClass\n        }\n      })\n    }\n  };\n  \n} catch (error) {\n  return {\n    json: {\n      error: error.message,\n      stack: error.stack\n    }\n  };\n}"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        3632,
        -1040
      ],
      "id": "3171afe4-a9e3-4f52-95ba-4b5efacf99e0",
      "name": "Code in JavaScript"
    },
    {
      "parameters": {},
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3.2,
      "position": [
        2032,
        -848
      ],
      "id": "63579103-bb60-42b9-af61-c4a4d3248677",
      "name": "merge Tweet with web Search"
    },
    {
      "parameters": {
        "jsCode": "// IMPROVED SEARCH QUERY BUILDER - Extracts Facts, Removes Opinions\n\nconst data = $input.item.json;\nconst tweet = (data.tweetText || '').trim();\nconst dateStr = data.tweetMetadata?.created_at || data.created_at;\nconst tweetDate = new Date(dateStr || Date.now());\nconst isoDate = tweetDate.toISOString().split('T')[0];\n\nconsole.log('ğŸ” Building search query for tweet:', tweet.substring(0, 100));\n\n// Calculate tweet age\nconst ageHours = (Date.now() - tweetDate.getTime()) / (1000 * 60 * 60);\nconst isRecent = ageHours < 168; // Last 7 days\n\n// STEP 1: Clean the tweet\nlet cleaned = tweet\n  .replace(/https?:\\/\\/[^\\s]+/g, '')        // Remove URLs\n  .replace(/t\\.co\\/[^\\s]+/g, '')            // Remove t.co links\n  .replace(/BREAKING[:\\s]*/gi, '')          // Remove BREAKING\n  .replace(/[\"\"]/g, '\"')                    // Normalize quotes\n  .replace(/['']/g, \"'\");\n\n// STEP 2: Remove quoted text (if it's editorial/opinion)\nconst quoteMatch = cleaned.match(/\"([^\"]+)\"/);\nlet quotedPart = '';\nlet commentaryPart = '';\n\nif (quoteMatch) {\n  quotedPart = quoteMatch[1];\n  commentaryPart = cleaned.replace(quoteMatch[0], '').trim();\n  console.log('ğŸ“ Quoted part:', quotedPart);\n  console.log('ğŸ’¬ Commentary:', commentaryPart);\n}\n\n// STEP 3: Extract key entities (names, places, organizations)\nconst textToExtract = quotedPart || cleaned;\nconst words = textToExtract.split(/\\s+/);\nconst entities = [];\nconst stopWords = ['The', 'A', 'An', 'And', 'Or', 'But', 'For', 'To', 'In', 'On', 'At', 'From'];\n\nwords.forEach((word, index) => {\n  if (/^[A-Z][a-z]+/.test(word) && !stopWords.includes(word)) {\n    entities.push(word);\n  }\n});\n\nconsole.log('ğŸ·ï¸ Entities extracted:', entities);\n\n// STEP 4: Extract action verbs\nconst actionWords = ['write', 'wrote', 'sign', 'signed', 'ask', 'asked', 'asking', \n                     'reject', 'rejected', 'approve', 'approved', 'vote', 'voted',\n                     'pardon', 'pardoned', 'support', 'oppose', 'letter', 'statement'];\n\nconst actions = words\n  .map(w => w.toLowerCase())\n  .filter(w => actionWords.includes(w));\n\nconsole.log('âš¡ Actions found:', actions);\n\n// STEP 5: Remove opinion/editorial words\nconst opinionWords = ['astonishing', 'corrupt', 'surely', 'disqualifying', \n                     'outrageous', 'shocking', 'terrible', 'amazing', 'incredible',\n                     'unbelievable', 'disgraceful', 'shameful'];\n\nconst cleanedWords = words.filter(w => \n  !opinionWords.includes(w.toLowerCase())\n);\n\n// STEP 6: Build focused query\nlet query = '';\n\nif (entities.length >= 2 && actions.length >= 1) {\n  // Use entities + actions (most focused)\n  query = [...entities.slice(0, 4), ...actions.slice(0, 2)].join(' ');\n} else if (quotedPart) {\n  // Use quoted part (without commentary)\n  query = quotedPart\n    .replace(/[^\\w\\s]/g, ' ')\n    .replace(/\\s+/g, ' ')\n    .trim()\n    .split(/\\s+/)\n    .slice(0, 8)\n    .join(' ');\n} else {\n  // Fallback: Use cleaned words (without opinions)\n  query = cleanedWords\n    .slice(0, 8)\n    .join(' ')\n    .replace(/[^\\w\\s]/g, ' ')\n    .replace(/\\s+/g, ' ')\n    .trim();\n}\n\n// STEP 7: Add temporal context with WIDER DATE RANGE\nif (isRecent && ageHours < 48) {\n  // For very recent tweets (< 2 days), use date from 3 days ago\n  const threeDaysAgo = new Date(tweetDate);\n  threeDaysAgo.setDate(threeDaysAgo.getDate() - 3);\n  const widerDate = threeDaysAgo.toISOString().split('T')[0];\n  \n  query += ` after:${widerDate}`;\n  console.log('ğŸ“… Using wider date range (3 days): after:', widerDate);\n  \n} else if (isRecent && ageHours < 168) {\n  // For tweets in last week, use date from 7 days ago\n  const weekAgo = new Date(tweetDate);\n  weekAgo.setDate(weekAgo.getDate() - 7);\n  const widerDate = weekAgo.toISOString().split('T')[0];\n  \n  query += ` after:${widerDate}`;\n  console.log('ğŸ“… Using week-wide range (7 days): after:', widerDate);\n  \n} else if (tweetDate.getFullYear() >= new Date().getFullYear() - 1) {\n  // For tweets from this year or last year, just add year\n  query += ` ${tweetDate.getFullYear()}`;\n  console.log('ğŸ“… Using year:', tweetDate.getFullYear());\n}\n\n// STEP 8: Universal exclusions\nquery += ' -site:reddit.com -site:twitter.com -site:x.com -site:youtube.com -site:facebook.com';\n\nconsole.log('ğŸ¯ Final search query:', query);\nconsole.log('ğŸ“ Query length:', query.length);\n\nreturn { \n  json: { \n    ...data, \n    search_query: query,\n    extracted_entities: entities,\n    extracted_actions: actions,\n    is_recent: isRecent,\n    tweet_age_hours: Math.round(ageHours)\n  } \n};\n"
      },
      "name": "1. Build Smart Search Query",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1184,
        -928
      ],
      "id": "dba33a16-e5cf-48a9-9ac3-9a332838d2a4"
    },
    {
      "parameters": {
        "jsCode": "// Get search results from Google API\nconst searchResponse = $input.item.json;\n\n// Get original tweet data from all items\nconst allData = $input.all();\nlet originalTweet = {};\nfor (let item of allData) {\n  if (item.json.tweetText && item.json.tweetText !== '') {\n    originalTweet = item.json;\n    break;\n  }\n}\n\nconsole.log('=== SEARCH FILTERING ===');\nconsole.log('Found tweetText?', !!originalTweet.tweetText);\n\n// ===== SOURCE CREDIBILITY TIERS =====\n\n// TIER 1: Top-tier news outlets covering ALL topics\nconst TIER1_SOURCES = [\n  // International News Agencies\n  'reuters.com', 'ap.org', 'apnews.com', 'afp.com',\n  \n  // Major US Newspapers\n  'nytimes.com', 'washingtonpost.com', 'wsj.com', \n  'usatoday.com', 'latimes.com', 'chicagotribune.com',\n  \n  // Major UK News\n  'bbc.com', 'bbc.co.uk', 'theguardian.com', 'telegraph.co.uk',\n  \n  // Major Broadcast News\n  'cnn.com', 'nbcnews.com', 'abcnews.go.com', 'cbsnews.com',  \n  'cnbc.com',\n  \n  // Business/Financial\n  'bloomberg.com', 'ft.com', 'forbes.com',\n  \n  // Public Broadcasting\n  'npr.org', 'pbs.org'\n];\n\n// TIER 2: Established regional/specialized outlets\nconst TIER2_SOURCES = [\n  // Major Regional US Papers\n  'miamiherald.com', 'denverpost.com', 'seattletimes.com',\n  'sfchronicle.com', 'bostonglobe.com', 'ajc.com', 'dallasnews.com',\n  \n  // International Major Papers\n  'timesofindia.com', 'straitstimes.com', 'scmp.com',\n  'japantimes.co.jp', 'aljazeera.com', 'dw.com', 'france24.com',\n  \n  // Korean News (for K-pop/Korean content)\n  'koreatimes.co.kr', 'koreaherald.com', 'yonhapnews.co.kr',\n  \n  // Entertainment/Culture (established)\n  'variety.com', 'hollywoodreporter.com', 'billboard.com',\n  'rollingstone.com', 'pitchfork.com', 'nme.com',\n  \n  // Health/Science (official & authoritative)\n  'scientificamerican.com', 'newscientist.com', 'nature.com',\n  'healthline.com', 'webmd.com', 'mayoclinic.org', 'nih.gov', 'cdc.gov',\n  \n  // Tech\n  'techcrunch.com', 'theverge.com', 'wired.com', 'arstechnica.com',\n  \n  // Official Governing Bodies / Authoritative Organizations  // â† ADD THIS\n  'mlb.com', 'nfl.com', 'nba.com', 'nhl.com', 'fifa.com', 'uefa.com',  // â† ADD THIS\n  'who.int', 'fda.gov', 'sec.gov', 'ftc.gov',  // â† ADD THIS\n  \n  // K-pop Specialized (for entertainment niche)\n  'soompi.com', 'allkpop.com', 'koreaboo.com'\n];\n\n// TIER 3: Legitimate but lower standards OR very specialized\nconst TIER3_SOURCES = [\n  // Sports (major outlets)\n  'espn.com', 'si.com', 'cbssports.com', 'espnfc.com', 'skysports.com',\n  'goal.com', 'bleacherreport.com', 'theathleticfc.com',\n  \n  // Entertainment (tabloid-style but legitimate)\n  'ew.com', 'people.com', 'usmagazine.com', 'tmz.com',\n  \n  // UK Tabloids (sensationalist but real)\n  'thesun.co.uk', 'dailymail.co.uk', 'mirror.co.uk', 'express.co.uk',\n  \n  // Political/News (legitimate niche)\n  'politico.com', 'thehill.com', 'axios.com', 'vox.com',\n  'salon.com', 'slate.com', 'huffpost.com',\n  \n  // Entertainment specialized\n  'deadline.com', 'indiewire.com', 'avclub.com'\n];\n\n// EXCLUDE social media platforms\nconst EXCLUDED_SOURCES = [\n  'facebook.com', 'twitter.com', 'x.com', 'instagram.com',\n  'threads.com', 'reddit.com', 'tiktok.com', 'youtube.com',\n  'pinterest.com', 'tumblr.com', 'quora.com', 'medium.com'\n];\n\n// Function to determine source tier\nfunction getSourceTier(domain) {\n  const lowerDomain = domain.toLowerCase();\n  \n  if (TIER1_SOURCES.some(s => lowerDomain.includes(s))) return 1;\n  if (TIER2_SOURCES.some(s => lowerDomain.includes(s))) return 2;\n  if (TIER3_SOURCES.some(s => lowerDomain.includes(s))) return 3;\n  if (EXCLUDED_SOURCES.some(s => lowerDomain.includes(s))) return 99;\n  \n  return 4; // Unknown sources\n}\n\n// Handle no results from Google\nif (!searchResponse.items || searchResponse.items.length === 0) {\n  console.log('âš ï¸ No search results found');\n  return {\n    json: {\n      ...originalTweet,\n      search_results: [],\n      total_results: 0,\n      credible_sources_found: 0,\n      search_status: 'NO_RESULTS'\n    }\n  };\n}\n\nconsole.log('Total raw results:', searchResponse.items.length);\n\n// Filter, rank, and limit results\nconst rankedResults = searchResponse.items\n  .map(item => ({\n    title: item.title,\n    url: item.link,\n    source: item.displayLink,\n    tier: getSourceTier(item.displayLink)\n  }))\n  .filter(item => {\n    const isExcluded = item.tier === 99;\n    if (isExcluded) {\n      console.log('âŒ Excluded:', item.source);\n    }\n    return !isExcluded;\n  })\n  .sort((a, b) => a.tier - b.tier)\n  .slice(0, 5)\n  .map(({ tier, ...item }) => item);\n\n// Count credible sources (Tier 1, 2, and 3)\nconst credibleCount = rankedResults.filter(r => {\n  const domain = r.source.toLowerCase();\n  return TIER1_SOURCES.some(s => domain.includes(s)) ||\n         TIER2_SOURCES.some(s => domain.includes(s)) ||\n         TIER3_SOURCES.some(s => domain.includes(s));\n}).length;\n\nconsole.log('âœ… Credible sources found:', credibleCount);\nconsole.log('ğŸ“Š Total filtered results:', rankedResults.length);\n\n// Determine search status\nlet searchStatus = 'SUCCESS';\nif (rankedResults.length === 0) {\n  searchStatus = 'NO_CREDIBLE_SOURCES';\n} else if (credibleCount === 0) {\n  searchStatus = 'LOW_QUALITY_ONLY';\n}\n\n// Return combined data with search metadata\nreturn {\n  json: {\n    ...originalTweet,\n    search_results: rankedResults,\n    total_results: parseInt(searchResponse.searchInformation?.totalResults || 0),\n    credible_sources_found: credibleCount,\n    search_status: searchStatus\n  }\n};"
      },
      "name": "3. Verify & Score Sources",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1792,
        -928
      ],
      "id": "3175e4c8-f18b-46ea-ba2d-ab76e238a490"
    },
    {
      "parameters": {
        "url": "https://www.googleapis.com/customsearch/v1",
        "sendQuery": true,
        "queryParameters": {
          "parameters": [
            {
              "name": "key",
              "value": "AIzaSyBCm6e_2I1SN1IZyfUNWv9GgV3eIjFnyUE"
            },
            {
              "name": "cx",
              "value": "a16574f588c3a47df"
            },
            {
              "name": "q",
              "value": "={{ $json.search_query }}"
            },
            {
              "name": "num",
              "value": "10"
            }
          ]
        },
        "options": {}
      },
      "name": "2. Search Google1",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        1488,
        -928
      ],
      "id": "e1032e58-2a4d-48ce-b1a1-e14727b0ef19"
    },
    {
      "parameters": {
        "jsCode": "// Get all items from previous nodes\nconst allItems = $input.all();\nconsole.log('=== MERGING DATA ===');\nconsole.log('Total items received:', allItems.length);\n\n// Find tweet data (the one with tweetText + accountData)\nlet tweetData = {};\nfor (let item of allItems) {\n  if (item.json.tweetText && item.json.accountData) {\n    tweetData = item.json;\n    console.log('Found tweet data');\n    break;\n  }\n}\n\n// Find ANY item that has search_results (even if empty or from google_enrichment)\nlet searchData = {\n  search_results: [],\n  total_results: 0,\n  credible_sources_found: 0,\n  search_status: 'NOT_RUN'\n};\n\nfor (let item of allItems) {\n  // Case 1: Old format (direct search_results)\n  if (item.json.search_results !== undefined) {\n    searchData = {\n      search_results: item.json.search_results || [],\n      total_results: item.json.total_results || 0,\n      credible_sources_found: item.json.credible_sources_found || 0,\n      search_status: item.json.search_status || 'NOT_RUN'\n    };\n    console.log('Found old-style search data');\n    break;\n  }\n\n  // Case 2: New format from universal verify node (google_enrichment)\n  if (item.json.google_enrichment) {\n    const ge = item.json.google_enrichment;\n    searchData = {\n      search_results: ge.top_results || [],\n      total_results: ge.results_count || ge.top_results?.length || 0,\n      credible_sources_found: ge.tier1_sources_found || ge.tier1_count || 0,\n      search_status: ge.verification_status ? 'COMPLETED' : 'FAILED'\n    };\n    console.log('Found new google_enrichment data');\n    break;\n  }\n}\n\n// Merge everything into ONE object (exact same structure as before)\nconst mergedData = {\n  // Tweet content\n  tweetText: tweetData.tweetText,\n  tweetSource: tweetData.tweetSource,\n  sourceType: tweetData.sourceType,\n\n  // Tweet metadata\n  tweetMetadata: tweetData.tweetMetadata || {},\n\n  // Account data\n  accountData: tweetData.accountData || {},\n\n  // Tweet identifiers\n  tweet_id: tweetData.tweet_id || tweetData.tweetMetadata?.tweet_id,\n  tweet_url: tweetData.tweet_url || tweetData.tweetMetadata?.tweet_url,\n  virality_score: tweetData.virality_score || tweetData.tweetMetadata?.virality_score,\n  engagement: tweetData.engagement || tweetData.tweetMetadata?.engagement,\n  author: tweetData.author || tweetData.tweetMetadata?.author,\n\n  // Search results â€” now works with BOTH old and new flows\n  search_results: searchData.search_results,\n  total_results: searchData.total_results,\n  credible_sources_found: searchData.credible_sources_found,\n  search_status: searchData.search_status\n};\n\nconsole.log('Merge complete');\nconsole.log('Credible sources:', mergedData.credible_sources_found);\nconsole.log('Search status:', mergedData.search_status);\n\nreturn { json: mergedData };"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2288,
        -848
      ],
      "id": "e85231c0-bd49-4d40-98d0-24b9aacd0ea4",
      "name": "Merge input & web search"
    }
  ],
  "pinData": {},
  "connections": {
    "Parse Input Data": {
      "main": [
        [
          {
            "node": "Agent 2 - Credibility",
            "type": "main",
            "index": 0
          },
          {
            "node": "Agent 3 - Twitter Check",
            "type": "main",
            "index": 0
          },
          {
            "node": "1. Build Smart Search Query",
            "type": "main",
            "index": 0
          },
          {
            "node": "merge Tweet with web Search",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Agent 1 - Fact Check": {
      "main": [
        [
          {
            "node": "Check Agent 1 Confidence",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Agent 2 - Credibility": {
      "main": [
        [
          {
            "node": "Check Agent 2 Confidence",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Agent 3 - Twitter Check": {
      "main": [
        [
          {
            "node": "Merge with Agent 3",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Check Agent 1 Confidence": {
      "main": [
        [
          {
            "node": "Agent 1B - Fact Check Backup",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Merge Agents 1 & 2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Check Agent 2 Confidence": {
      "main": [
        [
          {
            "node": "Agent 2B - Credibility Backup",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Merge Agents 1 & 2",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Agent 1B - Fact Check Backup": {
      "main": [
        [
          {
            "node": "Code in JavaScript",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Agent 2B - Credibility Backup": {
      "main": [
        [
          {
            "node": "Merge Agent 2 Results",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge Agent 2 Results": {
      "main": [
        [
          {
            "node": "Merge Agents 1 & 2",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Merge Agents 1 & 2": {
      "main": [
        [
          {
            "node": "Merge with Agent 3",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge with Agent 3": {
      "main": [
        [
          {
            "node": "Combine for Agent 4",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Agent 4 - Decision": {
      "main": [
        [
          {
            "node": "Format for Google Sheets",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Format for Google Sheets": {
      "main": [
        [
          {
            "node": "Append row in sheet",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Google Gemini Chat Model2": {
      "ai_languageModel": [
        [
          {
            "node": "Agent 2 - Credibility",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Groq Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "Agent 1B - Fact Check Backup",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Google Gemini Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "Agent 4 - Decision",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Google Gemini Chat Model3": {
      "ai_languageModel": [
        [
          {
            "node": "AI Agent - Supabase Formatter",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Get row from Dataset (Supabase)": {
      "ai_tool": [
        [
          {
            "node": "AI Agent - Supabase Formatter",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "WhatsApp Trigger": {
      "main": [
        [
          {
            "node": "WhatsApp Input Parser",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "WhatsApp Input Parser": {
      "main": [
        [
          {
            "node": "AI Agent - Supabase Formatter",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "AI Agent - Supabase Formatter": {
      "main": [
        [
          {
            "node": "Merge Dataset & Twitter Inputs",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge Dataset & Twitter Inputs": {
      "main": [
        [
          {
            "node": "Format Input Data",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Format Input Data": {
      "main": [
        [
          {
            "node": "Parse Input Data",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Combine for Agent 4": {
      "main": [
        [
          {
            "node": "Agent 4 - Decision",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Every 4 Hours": {
      "main": [
        [
          {
            "node": "Search Viral News Tweets",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Manual Trigger": {
      "main": [
        [
          {
            "node": "Search Viral News Tweets",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Search Viral News Tweets": {
      "main": [
        [
          {
            "node": "Get Top N Most Viral",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Get Top N Most Viral": {
      "main": [
        [
          {
            "node": "Enrich Twitter Account Data",
            "type": "main",
            "index": 0
          },
          {
            "node": "Merge2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Enrich Twitter Account Data": {
      "main": [
        [
          {
            "node": "Merge Enriched Data",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge Enriched Data": {
      "main": [
        [
          {
            "node": "Merge2",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Merge2": {
      "main": [
        [
          {
            "node": "Build Final Enriched Data",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Build Final Enriched Data": {
      "main": [
        [
          {
            "node": "Format Input Data",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Google Gemini Chat Model4": {
      "ai_languageModel": [
        [
          {
            "node": "Agent 1 - Fact Check",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Groq Chat Model1": {
      "ai_languageModel": [
        [
          {
            "node": "Agent 2B - Credibility Backup",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Google Gemini Chat Model5": {
      "ai_languageModel": [
        [
          {
            "node": "Agent 3 - Twitter Check",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Code in JavaScript": {
      "main": [
        [
          {
            "node": "Merge Agents 1 & 2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "merge Tweet with web Search": {
      "main": [
        [
          {
            "node": "Merge input & web search",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "1. Build Smart Search Query": {
      "main": [
        [
          {
            "node": "2. Search Google1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "2. Search Google1": {
      "main": [
        [
          {
            "node": "3. Verify & Score Sources",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "3. Verify & Score Sources": {
      "main": [
        [
          {
            "node": "merge Tweet with web Search",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge input & web search": {
      "main": [
        [
          {
            "node": "Agent 1 - Fact Check",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": false,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "463d3a54-425e-49ca-b1d1-207e965cd68d",
  "meta": {
    "templateCredsSetupCompleted": true,
    "instanceId": "121d8e9b68760b992e165904fd6888a7f1a58413d4a67cf93ef67eae09ef6b3b"
  },
  "id": "kmJ12WwvvTAS7wFS",
  "tags": []
}