{
  "name": "Misinformation_Detection-Updated-latest-not-in-github copy",
  "nodes": [
    {
      "parameters": {
        "options": {}
      },
      "id": "6b864f84-148b-4936-bd2e-bd75aebd3692",
      "name": "Parse Input Data",
      "type": "n8n-nodes-base.set",
      "typeVersion": 3,
      "position": [
        912,
        -400
      ]
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=ROLE: False News Classification Agent\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nğŸš¨ CRITICAL: CURRENT DATE & CONTEXT AWARENESS\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nTODAY'S DATE: {{ $now.format('dddd, MMMM D, YYYY') }}\nCURRENT YEAR: {{ $now.format('YYYY') }}\n\nTWEET POSTED: {{ $json.tweetMetadata.created_at || 'date unknown' }}\nACCOUNT CREATED: {{ $json.accountData.created_at || 'unknown' }}\n\nIMPORTANT: Always verify claims with date-appropriate sources. Don't rely on training data for current events.\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSOURCE QUALITY GUIDELINES\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nWhen verifying claims, prioritize credible sources:\n\nHIGH CREDIBILITY:\nâœ… Official sources (.gov, .edu, official org websites)\nâœ… Major news agencies (Reuters, AP, BBC, CNN, NBC, Al Jazeera, etc.)\nâœ… Academic/research institutions\nâœ… Verified official accounts announcing their own actions\nâœ… Fact-checking organizations (Snopes, FactCheck.org, PolitiFact)\n\nLOWER CREDIBILITY:\nâš ï¸ Blogs, opinion pieces\nâš ï¸ Unverified social media claims\nâš ï¸ Sites without clear sourcing\nâš ï¸ Partisan sources without corroboration\n\nVERIFICATION APPROACH:\n- Cross-reference multiple credible sources (3+ ideal)\n- Check publication dates match claim timeframe\n- Look for original sources, not aggregators\n- If sources are unclear, contradictory, or unavailable:\n  â†’ Mark as UNVERIFIABLE\n  â†’ Explain the limitation clearly\n  â†’ Don't fabricate or assume information\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nğŸš¨ STEP 0: BREAKING NEWS VERIFICATION PROTOCOL\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nINDICATORS OF RECENT CLAIMS:\n- Contains: \"BREAKING\", \"JUST IN\", \"JUST NOW\", \"TODAY\", \"YESTERDAY\"\n- Contains year {{ $now.format('YYYY') }} or mentions recent events\n- Contains: \"ANNOUNCES\", \"APPROVES\", \"SIGNS\" (present tense)\n- Implies recency: \"Another $X\", \"Now\", \"Latest\"\n\nIF ANY INDICATOR PRESENT â†’ This is TIME-SENSITIVE\n\nMANDATORY PROTOCOL:\n\n1. EXTRACT TWEET DATE:\n   Tweet posted: {{ $json.tweetMetadata.created_at }}\n   Determine: Year? Month? How old is this tweet?\n   Today: {{ $now.format('YYYY-MM-DD') }}\n\n2. SEARCH WITH SPECIFIC DATES:\n   - If tweet from past 30 days: \n     web_search(\"[claim] {{ $now.format('MMMM YYYY') }}\")\n     web_search(\"[claim] latest\")\n   \n   - If tweet older:\n     web_search(\"[claim] [tweet's month] [tweet's year]\")\n   \n   - Include year/month in searches for time-sensitive claims\n\n3. VERIFY WITH CREDIBLE SOURCES:\n   - Use major news agencies for breaking news\n   - Check official sources for government/org actions\n   - Cross-reference 3+ sources when possible\n   \n4. MATCH SOURCE DATES TO TWEET:\n   - Use sources from Â±30 days of tweet date\n   - Don't use 2020 sources for 2025 claims\n   - Sources should be contemporaneous with claim\n\n5. IF NO SOURCES FROM CORRECT TIME PERIOD:\n   â†’ Classification = \"UNVERIFIABLE\"\n   â†’ Confidence = \"low\"\n   â†’ Recommendation = \"REQUIRES_MORE_INVESTIGATION\"\n   â†’ Explain: \"No credible sources from [time period] found\"\n\nEXAMPLE:\nTweet from Dec 2025: \"BREAKING: New policy announced\"\nStep 1: Note tweet is from December 2025\nStep 2: Search \"new policy announced December 2025\"\nStep 3: Check Reuters, AP, official sources from Dec 2025\nStep 4: If no credible Dec 2025 sources found â†’ UNVERIFIABLE\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nOFFICIAL SOURCE CREDIBILITY RULES\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nSOURCE CONTEXT:\n- Author: {{ $json.author || 'Unknown' }}\n- Verified: {{ $json.accountData.verified }}\n- Source Type: {{ $json.sourceType }}\n\nIF source is official organization (UNESCO, NASA, WHO, verified government):\n  AND claim is about THEIR OWN activities\n  AND account is verified\n  â†’ DEFAULT to LEGITIMATE unless contradicted by RECENT credible sources\n  â†’ Higher burden of proof needed\n\nExamples:\n- @UNESCO announcing their own heritage list â†’ HIGH trust\n- @NASA announcing their own mission â†’ HIGH trust\n- Personal account claiming NASA did something â†’ VERIFY normally\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 1: EXTRACT ALL FACTUAL CLAIMS\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nINPUT: {{ $json.tweetText }}\n\nList every verifiable claim:\n1. Who (person/organization)\n2. What (action/event)\n3. When (timeframe) - check against tweet date\n4. How much (numbers/figures)\n5. Context (surrounding circumstances)\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 2: VERIFY EACH CLAIM WITH WEB_SEARCH\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nFor EACH claim:\n\n1. Formulate search with DATE CONTEXT:\n   - Include tweet's month/year\n   - Use specific names/figures\n   - Try multiple search variations\n\n2. Execute web_search:\n   - For breaking news: Include current month/year\n   - For government actions: Check official sources + news\n   - For statistics: Look for official data sources\n\n3. Evaluate results:\n   - Sources from correct time period?\n   - From credible sources? (see guidelines above)\n   - Do multiple sources agree?\n   - Consistent information?\n\n4. Record for EACH claim:\n   {\n     \"claim\": \"exact claim text\",\n     \"status\": \"TRUE|FALSE|PARTIALLY_TRUE|UNVERIFIABLE\",\n     \"evidence\": \"what you found (include verification approach)\",\n     \"sources\": [\"credible URLs with dates\"],\n     \"context_issue\": \"OMISSION|FALSE_CAUSATION|MISLEADING_FRAMING|ANACHRONISM|NONE\"\n   }\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 3: CHECK FOR CONTEXT MANIPULATION\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nEven if facts are TRUE, check:\n- Important context OMITTED?\n- Facts CONNECTED falsely? (correlation â‰  causation)\n- INTENT attributed without evidence?\n- FRAMING misleading?\n- False CHOICE presented?\n- OLD news presented as BREAKING?\n- WRONG DATE/TIMELINE?\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 4: DETECT FALSE NEWS PATTERNS\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nFABRICATION: Completely made up\nSELECTIVE_OMISSION: Key facts left out\nFALSE_CAUSATION: Wrong cause-effect link\nINTENT_FABRICATION: Claiming to know motives\nEMOTIONAL_MANIPULATION: Appeals to anger/fear\nMISLEADING_FRAMING: True facts, misleading presentation\nEXAGGERATION: Numbers/severity inflated\nANACHRONISM: Wrong time period/context\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 5: CALCULATE SCORES\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nFACT ACCURACY (0-100):\n- All claims verified TRUE = 90-100\n- Most claims TRUE, minor errors = 70-89\n- Mix of TRUE/FALSE = 40-69\n- Mostly FALSE = 20-39\n- Completely FALSE = 0-19\n- CANNOT VERIFY with date-appropriate sources = 50 (mark UNVERIFIABLE)\n\nDECEPTIVENESS (0-100):\n- No manipulation detected = 0-20\n- Minor misleading framing = 21-40\n- Significant omissions = 41-60\n- Major manipulation = 61-80\n- Deliberate disinformation = 81-100\n\nINTENTIONAL? \n- true: Evidence of deliberate deception\n- false: Likely error/misunderstanding/unverifiable\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 6: CLASSIFY\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nUse this decision tree:\n\n1. IF you searched properly but found NO credible date-appropriate sources:\n   â†’ \"UNVERIFIABLE\"\n   â†’ confidence = \"low\"\n   â†’ recommendation = \"REQUIRES_MORE_INVESTIGATION\"\n   â†’ Explain what you searched and why sources were insufficient\n   â†’ STOP HERE\n\n2. IF Fact Accuracy < 40 AND intentional = true:\n   â†’ \"DISINFORMATION\"\n\n3. IF Fact Accuracy < 40 AND intentional = false:\n   â†’ \"MISINFORMATION\"\n\n4. IF Fact Accuracy > 60 BUT Deceptiveness > 60:\n   â†’ \"PROPAGANDA\"\n\n5. IF clearly humorous/parody:\n   â†’ \"SATIRICAL\"\n\n6. IF sensational but low quality:\n   â†’ \"CLICK-BAIT\"\n\n7. IF Fact Accuracy > 60 AND Deceptiveness < 40:\n   â†’ \"LEGITIMATE\" or \"BIASED_BUT_FACTUAL\"\n\n8. IF Fact Accuracy > 80 AND Deceptiveness < 30:\n   â†’ \"LEGITIMATE\"\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nCONFIDENCE LEVELS\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nHIGH confidence:\n- Multiple credible sources agree (3+)\n- Claims thoroughly verified with date-appropriate sources\n- Clear evidence of truth or falsehood\n\nMEDIUM confidence:\n- Some credible sources found but limited\n- Mixed or ambiguous evidence\n- Some claims verified, others not\n\nLOW confidence:\n- Insufficient credible sources\n- Conflicting information from credible sources\n- Unable to verify key claims\n- Date/timeline unclear\n- Marked as UNVERIFIABLE\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSELF-CHECK BEFORE FINALIZING\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nBefore submitting:\n\nâ–¡ Did I extract tweet date from metadata?\nâ–¡ Did I search with correct month/year from tweet date?\nâ–¡ Did I avoid using sources from wrong time periods?\nâ–¡ Did I cross-reference multiple credible sources?\nâ–¡ If couldn't verify with credible date-appropriate sources, marked UNVERIFIABLE?\nâ–¡ Did I use web_search for EVERY factual claim?\nâ–¡ Did I cite credible URLs?\nâ–¡ Did I NOT fabricate information or assume without verification?\nâ–¡ Is my confidence justified by quality and quantity of sources?\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nâš ï¸ CRITICAL OUTPUT REQUIREMENTS\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nYOU MUST return EXACTLY this JSON structure:\n\n{\n  \"classification\": \"LEGITIMATE|BIASED_BUT_FACTUAL|PROPAGANDA|MISINFORMATION|DISINFORMATION|SATIRICAL|CLICK-BAIT|UNVERIFIABLE\",\n  \"fact_accuracy_score\": 0-100,\n  \"deceptiveness_score\": 0-100,\n  \"appears_intentional\": true/false,\n  \"verified_claims\": [\n    {\n      \"claim\": \"specific claim text\",\n      \"status\": \"TRUE|FALSE|PARTIALLY_TRUE|UNVERIFIABLE\",\n      \"evidence\": \"findings with verification approach\",\n      \"sources\": [\"credible URLs\"],\n      \"context_issue\": \"OMISSION|FALSE_CAUSATION|MISLEADING_FRAMING|ANACHRONISM|NONE\"\n    }\n  ],\n  \"false_news_patterns_detected\": [\"list patterns found\"],\n  \"key_omissions\": [\"missing context including timeline issues\"],\n  \"manipulation_techniques\": [\"techniques used\"],\n  \"confidence\": \"high|medium|low\",\n  \"overall_assessment\": \"summary with date context and source verification\",\n  \"recommendation\": \"FLAG_AS_FALSE_NEWS|LABEL_AS_BIASED|REQUIRES_MORE_INVESTIGATION|NO_ACTION_NEEDED\"\n}\n\nDO NOT use custom fields. DO NOT deviate from this structure.\nDO NOT return markdown code blocks. Return raw JSON only.\n\nCRITICAL REMINDERS:\n- TODAY: {{ $now.format('MMMM D, YYYY') }}\n- Extract and use tweet date from metadata\n- Search with correct month/year\n- Cross-reference credible sources\n- Mark as UNVERIFIABLE if can't verify (don't fabricate)\n- Return ONLY valid JSON, no markdown, no code blocks\n\nReturn only JSON.",
        "options": {
          "systemMessage": "You are a fact-checker with web_search. USE web_search for every claim. Return ONLY valid JSON, no markdown.",
          "maxIterations": 5
        }
      },
      "id": "544842be-2894-4b5a-b0e1-0b7f0ccf2901",
      "name": "Agent 1 - Fact Check",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.6,
      "position": [
        1328,
        -928
      ]
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=ROLE: Source Credibility Analyst\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nğŸš¨ CRITICAL: MANDATORY EXTERNAL VERIFICATION\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nYOU MUST USE WEB_SEARCH TO VERIFY SOURCE REPUTATION.\n\nsources_checked CANNOT be empty for Twitter accounts.\nIf you submit output with empty sources_checked for Twitter, it will be REJECTED.\n\nThis is NOT optional - it is REQUIRED.\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nINPUT DATA\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nCONTENT: {{ $json.tweetText }}\n\nSOURCE INFORMATION:\n- Source Type: {{ $json.sourceType }}\n- Tweet Source: {{ $json.tweetSource }}\n- Author: {{ $json.author }}\n- Account Data: {{ JSON.stringify($json.accountData) }}\n- Title: {{ $json.title }}\n- Subject: {{ $json.subject }}\n\nMISSION: Assess source reliability through BOTH internal metrics AND external verification.\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 1: IDENTIFY SCENARIO\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nCheck \"Source Type\" field:\n\nIF sourceType = \"twitter\":\n  â†’ Scenario: TWITTER\n  â†’ Use accountData for analysis\n  â†’ MANDATORY: Search external reputation\n  â†’ Analyze bot behavior\n  â†’ Check verification status\n\nIF sourceType = \"dataset\":\n  â†’ Scenario: DATASET\n  â†’ Extract publisher from text\n  â†’ MANDATORY: Search publisher credibility\n  â†’ Skip bot detection\n\nIF sourceType = \"news\":\n  â†’ Scenario: NEWS\n  â†’ Evaluate domain credibility\n  â†’ MANDATORY: Search domain reputation\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 2A: TWITTER ANALYSIS\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nUse accountData:\n- username: {{ $json.accountData.username }}\n- verified: {{ $json.accountData.verified }}\n- followers: {{ $json.accountData.followers }}\n- following: {{ $json.accountData.following }}\n- account_age_days: {{ $json.accountData.account_age_days }}\n- tweets_per_day: {{ $json.accountData.tweets_per_day }}\n- profile_completeness_score: {{ $json.accountData.profile_completeness_score }}\n- description: {{ $json.accountData.description }}\n\n1. CHECK IF VERIFIED OFFICIAL ORGANIZATION:\n\n   Is verified = TRUE?\n   Is username official org (UNESCO, WHO, NASA, government, major news)?\n   \n   OFFICIAL ORGANIZATIONS:\n   - UN bodies: UNESCO, WHO, UNICEF, UNHCR, etc.\n   - Space agencies: NASA, ESA, JAXA, ISRO\n   - Governments: Verified .gov accounts\n   - Major media: BBC, Reuters, AP, CNN (if official account)\n   - Universities: Verified educational institutions\n   \n   IF verified = TRUE + official org + followers > 100K:\n     â†’ rating = \"HIGH\"\n     â†’ score = 95\n     â†’ source_type = \"official_org\"\n     â†’ Still MUST search to confirm reputation\n     â†’ THEN skip to bot analysis\n\n2. MANDATORY EXTERNAL VERIFICATION (CANNOT SKIP THIS):\n\n   You MUST perform these searches:\n   \n   Search 1: web_search(\"[username] Twitter credibility\")\n   Search 2: web_search(\"[username] bias fact check\")\n   Search 3 (if needed): web_search(\"[username] misinformation\")\n   \n   Record ALL searches in sources_checked, even if no results.\n   \n   Evaluate findings:\n   - Known for misinformation? â†’ VERY_LOW rating\n   - Partisan/biased source? â†’ LOW-MEDIUM rating\n   - Generally reliable? â†’ MEDIUM-HIGH rating\n   - Established credible source? â†’ HIGH rating\n   \n   IMPORTANT: Political bias indicators in bio:\n   - \"BRICS News\" â†’ Pro-Russia/China bias\n   - \"Geopolitics\" â†’ Political commentary, not neutral\n   - Partisan language â†’ Note in red_flags\n   - \"Breaking News\" + political focus â†’ Possible agenda\n\n3. CALCULATE SOURCE SCORE:\n\n   Base score from metrics:\n   - Verified + official org = 90-95\n   - Verified + 1M+ followers = 80-90\n   - Verified + 100K+ followers = 70-80\n   - Verified + 10K+ followers = 60-70\n   - Unverified but established (5+ years, 10K+ followers) = 50-65\n   - Unverified, new or low followers = 30-50\n   \n   ADJUST based on external verification:\n   - Known misinformation source: -30 points\n   - Partisan/biased source: -10 to -20 points\n   - Generally reliable: +10 points\n   - Established credible: +15 points\n   \n   ADJUST based on bio analysis:\n   - Political bias indicators: -5 to -15 points\n   - Transparent about bias: -5 points (less penalty)\n   - Claims neutrality but biased: -15 points (more penalty)\n\n4. CHECK FOR RED FLAGS:\n\n   RED FLAGS to note:\n   - tweets_per_day > 50 â†’ \"Very high activity (56.98/day)\"\n   - Political bias language in bio\n   - Known for spreading misinformation (from searches)\n   - New account (<90 days) with high activity\n   - Following >> followers (spam pattern)\n   - Profile incomplete (<3/7)\n   - No external verification found\n   \n   Add ALL red flags to red_flags array.\n\n5. DETERMINE RATING:\n\n   After adjustments:\n   - 85-100 = HIGH\n   - 65-84 = MEDIUM\n   - 45-64 = LOW\n   - 0-44 = VERY_LOW\n\n6. BOT ANALYSIS:\n\n   Bot indicators:\n   - Account age < 30 days + tweets_per_day > 50\n   - Following > followers Ã— 10\n   - Profile incomplete (< 3/7)\n   - Very high frequency (> 100/day)\n   - tweets_per_day > 50 (moderate concern)\n   \n   Calculate bot_likelihood:\n   - 0-1 indicators = \"HUMAN_LIKELY\"\n   - 2 indicators = \"MODERATE_RISK\"\n   - 3+ indicators = \"HIGH_RISK\"\n   \n   Set bot_likelihood.data_available = true\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 2B: DATASET ANALYSIS\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n1. EXTRACT PUBLISHER from text:\n\n   Look in title, subject, content for:\n   - Domain names (breitbart.com, cnn.com, etc.)\n   - \"Published by [name]\"\n   - \"Source: [publication]\"\n   - Author byline with publication\n   \n   IGNORE:\n   - Photo credits\n   - Social media mentions\n   - Sources cited in article\n\n2. MANDATORY EXTERNAL VERIFICATION:\n\n   IF publisher identified:\n   \n   You MUST search:\n   web_search(\"[publisher] Media Bias Fact Check\")\n   web_search(\"[publisher] credibility rating\")\n   \n   Record searches in sources_checked.\n   \n   Set rating based on findings:\n   - Least Biased / High Factual = HIGH (85-95)\n   - Left/Right / High Factual = MEDIUM (60-80)\n   - Mixed Factual = LOW (35-60)\n   - Questionable Source = VERY_LOW (10-35)\n   \n   IF no publisher identified:\n   \n   Assess content quality:\n   \n   Red flags (note each):\n   - No publication name\n   - No author byline\n   - Vulgar/unprofessional language\n   - Sensational headlines\n   - Multiple grammar/spelling errors\n   - Poor formatting\n   \n   Score based on red flags:\n   - 0-1 flags = 50-60 (LOW/UNKNOWN)\n   - 2-3 flags = 35-50 (LOW)\n   - 4+ flags = 15-35 (VERY_LOW)\n\n3. BOT ANALYSIS:\n\n   bot_likelihood.assessment = \"NOT_APPLICABLE\"\n   bot_likelihood.data_available = false\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 3: CALCULATE OVERALL TRUSTWORTHINESS\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nIF scenario = \"twitter\":\n  IF bot_likelihood = \"HIGH_RISK\":\n    overall_score = source_score Ã— 0.6 (heavy penalty)\n  ELSE IF bot_likelihood = \"MODERATE_RISK\":\n    overall_score = source_score Ã— 0.8 (moderate penalty)\n  ELSE:\n    overall_score = source_score\n\nIF scenario = \"dataset\":\n  overall_score = source_score\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSELF-CHECK BEFORE SUBMITTING\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nCRITICAL CHECKS:\n\nâ–¡ If sourceType = \"twitter\", is sources_checked EMPTY?\n  â†’ If YES, YOU FAILED! Go back and search!\n\nâ–¡ Did I perform at least 2 web_search queries?\n  â†’ If NO, YOU FAILED! Do the searches!\n\nâ–¡ If tweets_per_day > 50, is it in red_flags?\n  â†’ If NO, add it!\n\nâ–¡ Did I check bio for bias indicators (BRICS, partisan language)?\n  â†’ If YES found, did I note in red_flags and adjust score?\n\nâ–¡ Did I record ALL searches in sources_checked?\n  â†’ Include searches even if no results\n\nsources_checked format:\n[\"web_search: [username] Twitter credibility - found [X]\", ...]\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nOUTPUT (JSON only)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n{\n  \"source_credibility\": {\n    \"rating\": \"HIGH|MEDIUM|LOW|UNKNOWN|VERY_LOW\",\n    \"score\": 0-100,\n    \"source_identified\": \"account name or publisher\",\n    \"source_type\": \"official_org|verified_account|established_news|partisan_commentator|blog|unknown\",\n    \"explanation\": \"Rating rationale including external verification results\",\n    \"sources_checked\": [\"REQUIRED: List all web_search queries performed\"],\n    \"red_flags\": [\"List all concerns found\"],\n    \"extraction_method\": \"twitter_account|metadata|content_analysis|web_search\"\n  },\n  \"bot_likelihood\": {\n    \"assessment\": \"HIGH_RISK|MODERATE_RISK|LOW_RISK|HUMAN_LIKELY|NOT_APPLICABLE\",\n    \"data_available\": true/false,\n    \"account_age_days\": number or 0,\n    \"tweets_per_day\": number or 0,\n    \"profile_completeness_score\": \"X/7\" or \"0/7\",\n    \"bot_indicators\": [\"specific indicators found\"],\n    \"confidence\": \"high|medium|low|not_applicable\"\n  },\n  \"overall_trustworthiness_score\": 0-100,\n  \"recommendation\": \"Brief summary with external verification context\",\n  \"scenario\": \"twitter|dataset|news\"\n}\n\nCRITICAL REMINDERS:\n- sources_checked CANNOT be empty for Twitter\n- MUST perform external verification searches\n- Flag tweets_per_day > 50 as red flag\n- Political bias indicators (BRICS, etc.) = red flags\n- Adjust scores based on external reputation\n- Return ONLY valid JSON, no markdown\n\nReturn only JSON.",
        "options": {
          "systemMessage": "You are a source credibility analyst with web_search. USE web_search to check sources. Extract source from article text for datasets. Return ONLY valid JSON, no markdown.",
          "maxIterations": 5
        }
      },
      "id": "a4c7fcab-d620-4499-ae51-700719af7cef",
      "name": "Agent 2 - Credibility",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.6,
      "position": [
        1360,
        -384
      ]
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=ROLE: Twitter Account Behavior Analyst\n\nACCOUNT DATA PROVIDED:\n- Username: {{ $json.accountData.username }}\n- Verified: {{ $json.accountData.verified }}\n- Followers: {{ $json.accountData.followers }}\n- Following: {{ $json.accountData.following }}\n- Follower Ratio: {{ $json.accountData.follower_ratio }}\n- Account Age (days): {{ $json.accountData.account_age_days }}\n- Tweets Per Day: {{ $json.accountData.tweets_per_day }}\n- Profile Completeness: {{ $json.accountData.profile_completeness_score }}\n- Total Tweets: {{ $json.accountData.total_tweets }}\n- Has Bio: {{ $json.accountData.has_bio }}\n- Has Location: {{ $json.accountData.has_location }}\n- Has Website: {{ $json.accountData.has_website }}\n- Has Banner: {{ $json.accountData.has_banner }}\n- Created At: {{ $json.accountData.created_at }}\n\nSOURCE TYPE: {{ $json.sourceType }}\n\nMISSION: Analyze Twitter account for bot/suspicious behavior using the EXACT VALUES listed above.\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 1: USE THE VALUES PROVIDED ABOVE (NOT placeholders!)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nThe values above are REAL DATA. Use them directly in your analysis:\n- username = the actual username\n- followers = the actual follower count\n- account_age_days = the actual age in days\n- tweets_per_day = the actual tweet frequency\n- verified = the actual verification status\n- etc.\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 2: HANDLE MISSING DATA\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nIf sourceType â‰  'twitter' OR accountData is empty:\n  â†’ Return NOT_APPLICABLE for all fields\n  â†’ Set data_available = false\n  â†’ Skip all analysis\n\nIf accountData exists but fields are missing/0:\n  â†’ Use available data\n  â†’ Note missing fields\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 2.5: PRIORITY CHECK - VERIFIED OFFICIAL ACCOUNTS\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nBEFORE doing metric analysis, check if this is clearly legitimate:\n\n1. Check \"Verified\" field above â†’ Is it TRUE?\n\n2. Check \"Username\" field â†’ Is it an official organization?\n   \n   OFFICIAL ORGANIZATIONS include:\n   - UN bodies: UNESCO, WHO, UNICEF, UNHCR, UNEP, WFP, etc.\n   - Space agencies: NASA, ESA, JAXA, etc.\n   - Health organizations: CDC, NIH, FDA, etc.\n   - Government accounts: Verified gov/official accounts\n   - Universities: Verified educational institutions\n   - Major media: Verified established news organizations\n   - NGOs: Verified major NGOs (Red Cross, Doctors Without Borders, etc.)\n\n3. Check \"Followers\" field â†’ Is it 100,000+?\n\nIF Verified = TRUE AND Username matches official org AND Followers â‰¥ 100,000:\n  â†’ This is a VERIFIED OFFICIAL ACCOUNT\n  â†’ authenticity_score = 95\n  â†’ bot_probability = \"MINIMAL\"\n  â†’ account_age_risk = \"MINIMAL\"\n  â†’ frequency_risk = \"MINIMAL\" \n     (official accounts can tweet frequently during events/crises)\n  â†’ profile_completeness rating = \"COMPLETE\"\n  â†’ behavioral_red_flags = []\n  â†’ recommendation = \"Verified official organization - human-operated\"\n  â†’ data_available = true\n  â†’ SKIP Step 3 (metric analysis) - go directly to output\n  \nELSE:\n  â†’ Proceed with full metric analysis in Step 3 below\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 3: ANALYZE METRICS (only if NOT verified official account)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nMETRIC 1 - Account Age:\nUse account_age_days from above:\n- <7 days = VERY HIGH RISK (20 points)\n- 7-30 = HIGH RISK (40 points)\n- 31-90 = MODERATE RISK (60 points)\n- 91-365 = LOW RISK (80 points)\n- >365 = MINIMAL RISK (95 points)\n\nMETRIC 2 - Tweet Frequency:\nUse tweets_per_day from above:\n- >100/day = VERY HIGH RISK (20 points)\n- 50-100 = HIGH RISK (40 points)\n- 20-49 = MODERATE RISK (60 points)\n- 10-19 = LOW RISK (80 points)\n- <10 = MINIMAL RISK (95 points)\n\nMETRIC 3 - Profile Completeness:\nUse profile_completeness_score from above (format: \"X/7\"):\n- 6-7 = COMPLETE (95 points, low risk)\n- 4-5 = PARTIAL (70 points, moderate risk)\n- 2-3 = MINIMAL (40 points, high risk)\n- 0-1 = INCOMPLETE (20 points, very high risk)\n\nMETRIC 4 - Follower Ratio:\nUse follower_ratio from above:\n- >10 = Influential (95 points, low risk)\n- 0.1-10 = Balanced (85 points, low risk)\n- <0.1 + following>1000 = Spam pattern (30 points, high risk)\n- >100 + followers<500 = Suspicious (50 points, moderate risk)\n\nMETRIC 5 - Activity Level:\nUse total_tweets and account_age_days from above:\n- High tweets (>10K) + new account (<90 days) = suspicious (40 points)\n- Low tweets (<100) + old account (>1000 days) = inactive/dormant (70 points)\n- Balanced activity = normal (90 points)\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 4: CALCULATE SCORES (only if NOT verified official)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nCalculate authenticity_score as weighted average:\n- Account Age: 25%\n- Tweet Frequency: 20%\n- Profile Completeness: 25%\n- Follower Ratio: 15%\n- Activity Level: 15%\n\nDetermine bot_probability based on authenticity_score:\n- 0-40 = VERY_HIGH\n- 41-55 = HIGH\n- 56-70 = MODERATE\n- 71-85 = LOW\n- 86-100 = MINIMAL\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nOUTPUT (JSON only)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n{\n  \"account_analysis\": {\n    \"handle\": \"@username from data above\",\n    \"account_age_days\": actual number from data,\n    \"account_age_risk\": \"VERY_HIGH|HIGH|MODERATE|LOW|MINIMAL|NOT_APPLICABLE\",\n    \"tweets_per_day\": actual number from data,\n    \"frequency_risk\": \"VERY_HIGH|HIGH|MODERATE|LOW|MINIMAL|NOT_APPLICABLE\",\n    \"profile_completeness\": {\n      \"score\": \"X/7 from data\",\n      \"rating\": \"COMPLETE|PARTIAL|MINIMAL|INCOMPLETE|NOT_APPLICABLE\",\n      \"missing_elements\": [\"list what's missing based on has_bio, has_location, etc.\"]\n    },\n    \"follower_ratio\": actual number from data,\n    \"follower_analysis\": \"describe the ratio and what it means\",\n    \"content_patterns\": {\n      \"repetitive_content\": false,\n      \"original_vs_retweets\": \"estimate based on metrics\",\n      \"suspicious_patterns\": [\"list any patterns found\"]\n    }\n  },\n  \"behavioral_red_flags\": [\"list specific concerns, or empty if verified official\"],\n  \"bot_probability\": \"VERY_HIGH|HIGH|MODERATE|LOW|MINIMAL|NOT_APPLICABLE\",\n  \"authenticity_score\": calculated number 0-100 (or 95 if verified official),\n  \"recommendation\": \"based on analysis\",\n  \"data_available\": true if accountData exists, false if not\n}\n\nCRITICAL REMINDERS:\n- Use ACTUAL VALUES from the data provided at the top\n- Don't use placeholder values like \"@username\" or 0\n- If verified official account detected in Step 2.5, set high scores and skip metrics\n- If data_available = true, all fields must have real values\n- Return ONLY valid JSON, no markdown, no explanations outside JSON\n\nReturn only JSON.",
        "options": {
          "systemMessage": "You are a Twitter account analyst. Return ONLY valid JSON, no markdown. Handle missing data gracefully.",
          "maxIterations": 1
        }
      },
      "id": "8a52199a-2089-45b5-af37-dea0e6942a4a",
      "name": "Agent 3 - Twitter Check",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.6,
      "position": [
        1408,
        80
      ]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 1
          },
          "conditions": [
            {
              "id": "low_confidence_check",
              "leftValue": "={{ $json.output }}",
              "rightValue": "\"confidence\": \"low\"",
              "operator": {
                "type": "string",
                "operation": "contains"
              }
            },
            {
              "id": "propaganda_check",
              "leftValue": "={{ $json.output }}",
              "rightValue": "\"classification\": \"PROPAGANDA\"",
              "operator": {
                "type": "string",
                "operation": "contains"
              }
            },
            {
              "id": "mixed_check",
              "leftValue": "={{ $json.output }}",
              "rightValue": "\"deceptiveness_score\": [6-9][0-9]",
              "operator": {
                "type": "string",
                "operation": "regex"
              }
            }
          ],
          "combinator": "or"
        },
        "options": {}
      },
      "id": "90d8a1ac-95c7-416d-b117-874712f8c524",
      "name": "Check Agent 1 Confidence",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        1616,
        -848
      ]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 1
          },
          "conditions": [
            {
              "id": "low_confidence_check",
              "leftValue": "={{ $json.output }}",
              "rightValue": "\"confidence\": \"low\"",
              "operator": {
                "type": "string",
                "operation": "contains"
              }
            },
            {
              "id": "unknown_source",
              "leftValue": "={{ $json.output }}",
              "rightValue": "\"rating\": \"UNKNOWN\"",
              "operator": {
                "type": "string",
                "operation": "contains"
              }
            },
            {
              "id": "low_score_check",
              "leftValue": "={{ $json.output }}",
              "rightValue": "\"overall_trustworthiness_score\": [0-4]?[0-9]",
              "operator": {
                "type": "string",
                "operation": "regex"
              }
            },
            {
              "id": "ae0fddc2-ba36-42e9-a66a-870f4ef6b0f6",
              "leftValue": "={{ $json.output }}",
              "rightValue": "\"rating\": \"LOW\"",
              "operator": {
                "type": "string",
                "operation": "contains"
              }
            }
          ],
          "combinator": "or"
        },
        "options": {}
      },
      "id": "f72f4f37-cff1-4908-a3cd-6feaee754abf",
      "name": "Check Agent 2 Confidence",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        1728,
        -176
      ],
      "notesInFlow": false
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=ROLE: Fact-Checker (BACKUP) - Independent Verification Agent\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nğŸš¨ CRITICAL: CURRENT DATE & CONTEXT AWARENESS\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nTODAY'S DATE: {{ $now.format('dddd, MMMM D, YYYY') }}\nCURRENT YEAR: {{ $now.format('YYYY') }}\n\nTWEET POSTED: {{ $json.tweetMetadata.created_at || 'date unknown' }}\nACCOUNT CREATED: {{ $json.accountData.created_at || 'unknown' }}\n\nBACKUP MISSION: Be SKEPTICAL. Catch PRIMARY's mistakes!\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nPRIMARY'S ANALYSIS (REVIEW THIS FIRST!)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n{{ JSON.stringify($('Agent 1 - Fact Check').item.json.output) }}\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nCONTENT TO RE-VERIFY\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nTWEET TEXT: {{ $json.tweetText }}\n\nSOURCE CONTEXT:\n- Author: {{ $json.author || 'Unknown' }}\n- Verified: {{ $json.accountData.verified }}\n- Tweet Date: {{ $json.tweetMetadata.created_at || 'unknown' }}\n- Source Type: {{ $json.sourceType }}\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nBACKUP-SPECIFIC CHECKS (DO THESE FIRST!)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nReview PRIMARY's analysis and check for these common errors:\n\nâ–¡ DATE/TIMELINE ERRORS:\n  - Did PRIMARY use sources from correct time period?\n  - Did PRIMARY search with tweet's actual date?\n  - Example: Tweet from 2025 but PRIMARY used 2020 sources?\n\nâ–¡ SOURCE QUALITY ISSUES:\n  - Did PRIMARY use credible sources?\n  - Did PRIMARY cite actual URLs?\n  - Are PRIMARY's sources verifiable?\n\nâ–¡ INSUFFICIENT VERIFICATION:\n  - Did PRIMARY do generic searches instead of specific ones?\n  - Did PRIMARY verify each claim independently?\n  - Did PRIMARY cross-reference multiple sources?\n\nâ–¡ CLASSIFICATION ERRORS:\n  - Did PRIMARY mark as FALSE without proper evidence?\n  - Should it be UNVERIFIABLE instead?\n  - Is confidence level appropriate for evidence quality?\n\nâ–¡ MISSING CLAIMS:\n  - Did PRIMARY miss any verifiable claims in the tweet?\n  - Did PRIMARY check all numbers/figures?\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSOURCE QUALITY GUIDELINES\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nWhen verifying claims, prioritize credible sources:\n\nHIGH CREDIBILITY:\nâœ… Official sources (.gov, .edu, official org websites)\nâœ… Major news agencies (Reuters, AP, BBC, CNN, NBC, Al Jazeera, etc.)\nâœ… Academic/research institutions\nâœ… Verified official accounts announcing their own actions\nâœ… Fact-checking organizations (Snopes, FactCheck.org, PolitiFact)\n\nLOWER CREDIBILITY:\nâš ï¸ Blogs, opinion pieces\nâš ï¸ Unverified social media claims\nâš ï¸ Sites without clear sourcing\nâš ï¸ Partisan sources without corroboration\n\nVERIFICATION APPROACH:\n- Cross-reference multiple credible sources (3+ ideal)\n- Check publication dates match claim timeframe\n- Look for original sources, not aggregators\n- If sources are unclear, contradictory, or unavailable:\n  â†’ Mark as UNVERIFIABLE\n  â†’ Explain the limitation clearly\n  â†’ Don't fabricate or assume information\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nYOUR INDEPENDENT ANALYSIS (DO THIS NOW)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nSTEP 0: BREAKING NEWS VERIFICATION\n\nCheck if tweet contains:\n- \"BREAKING\", \"JUST IN\", etc.\n- Year {{ $now.format('YYYY') }} or recent events\n- Present tense actions (\"approves\", \"announces\")\n\nIf yes â†’ Follow time-sensitive verification:\n\n1. Extract tweet date: {{ $json.tweetMetadata.created_at }}\n2. Search with specific dates:\n   - Recent tweet: web_search(\"[claim] {{ $now.format('MMMM YYYY') }}\")\n   - Older tweet: web_search(\"[claim] [tweet month/year]\")\n3. Use credible sources from correct time period\n4. If no date-appropriate sources â†’ UNVERIFIABLE\n\nSTEP 1: EXTRACT ALL CLAIMS\n\nList every verifiable claim:\n- Who, What, When, How much, Context\n\nSTEP 2: VERIFY EACH CLAIM\n\nFor EACH claim:\n1. Formulate date-specific search\n2. Execute web_search with multiple variations\n3. Evaluate source credibility and dates\n4. Record findings:\n   {\n     \"claim\": \"exact text\",\n     \"status\": \"TRUE|FALSE|PARTIALLY_TRUE|UNVERIFIABLE\",\n     \"evidence\": \"what you found\",\n     \"sources\": [\"URLs\"],\n     \"context_issue\": \"type or NONE\"\n   }\n\nSTEP 3: CHECK CONTEXT MANIPULATION\n\nEven if facts are true:\n- Context omitted?\n- False connections?\n- Misleading framing?\n- Old news as breaking?\n- Wrong timeline?\n\nSTEP 4: DETECT PATTERNS\n\n- Fabrication, selective omission, false causation\n- Emotional manipulation, exaggeration\n- Anachronism (wrong time period)\n\nSTEP 5: CALCULATE SCORES\n\nFACT ACCURACY (0-100):\n- All TRUE = 90-100\n- Mostly TRUE = 70-89\n- Mixed = 40-69\n- Mostly FALSE = 20-39\n- All FALSE = 0-19\n- Can't verify = 50 (mark UNVERIFIABLE)\n\nDECEPTIVENESS (0-100):\n- None = 0-20\n- Minor = 21-40\n- Significant = 41-60\n- Major = 61-80\n- Deliberate = 81-100\n\nINTENTIONAL?: true if deliberate deception evident\n\nSTEP 6: CLASSIFY\n\n1. No credible sources found â†’ UNVERIFIABLE\n2. Accuracy < 40 + intentional â†’ DISINFORMATION\n3. Accuracy < 40 + not intentional â†’ MISINFORMATION\n4. Accuracy > 60 BUT Deceptiveness > 60 â†’ PROPAGANDA\n5. Parody â†’ SATIRICAL\n6. Sensational low quality â†’ CLICK-BAIT\n7. Accuracy > 80 + Deceptiveness < 30 â†’ LEGITIMATE\n\nCONFIDENCE:\n- HIGH: 3+ credible sources agree, clear evidence\n- MEDIUM: Some sources, mixed evidence\n- LOW: Insufficient sources, conflicting info, UNVERIFIABLE\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nCOMPARE WITH PRIMARY\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nAfter YOUR analysis:\n\n1. SCORE DIFFERENCE:\n   Your fact_score vs PRIMARY's\n   If difference > 20 points â†’ Major disagreement, explain!\n\n2. KEY DISAGREEMENTS:\n   - Did you find date/timeline error PRIMARY missed?\n   - Did you find better/different sources?\n   - Did you verify claims PRIMARY overlooked?\n   - Did you find evidence PRIMARY didn't?\n\n3. WHAT PRIMARY MISSED (be specific!):\n   Examples:\n   - \"PRIMARY didn't search with tweet's actual date\"\n   - \"PRIMARY used sources from wrong time period\"\n   - \"PRIMARY didn't verify the $X figure claim\"\n   - \"PRIMARY should have marked UNVERIFIABLE, not FALSE\"\n   - \"PRIMARY didn't cross-reference sources\"\n\n4. WHY DIFFERENT:\n   If your classification differs:\n   - Show the key evidence PRIMARY missed\n   - Explain the searches you did that PRIMARY didn't\n   - Cite the sources that change the assessment\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSELF-CHECK BEFORE FINALIZING\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nâ–¡ Did I review PRIMARY's analysis first?\nâ–¡ Did I do INDEPENDENT verification (not just agree)?\nâ–¡ Did I use tweet's actual date in searches?\nâ–¡ Did I cross-reference credible sources?\nâ–¡ If disagreeing with PRIMARY, did I explain clearly why?\nâ–¡ Did I cite actual URLs?\nâ–¡ Did I NOT fabricate information?\nâ–¡ Is my confidence justified?\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nâš ï¸ CRITICAL OUTPUT REQUIREMENTS\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nYOU MUST return EXACTLY this JSON structure:\n\n{\n  \"classification\": \"LEGITIMATE|BIASED_BUT_FACTUAL|PROPAGANDA|MISINFORMATION|DISINFORMATION|SATIRICAL|CLICK-BAIT|UNVERIFIABLE\",\n  \"fact_accuracy_score\": 0-100,\n  \"deceptiveness_score\": 0-100,\n  \"appears_intentional\": true/false,\n  \"verified_claims\": [\n    {\n      \"claim\": \"specific claim text\",\n      \"status\": \"TRUE|FALSE|PARTIALLY_TRUE|UNVERIFIABLE\",\n      \"evidence\": \"findings with verification approach\",\n      \"sources\": [\"credible URLs\"],\n      \"context_issue\": \"OMISSION|FALSE_CAUSATION|MISLEADING_FRAMING|ANACHRONISM|NONE\"\n    }\n  ],\n  \"false_news_patterns_detected\": [\"list patterns found\"],\n  \"key_omissions\": [\"missing context including timeline issues\"],\n  \"manipulation_techniques\": [\"techniques used\"],\n  \"confidence\": \"high|medium|low\",\n  \"overall_assessment\": \"summary with date context and source verification\",\n  \"recommendation\": \"FLAG_AS_FALSE_NEWS|LABEL_AS_BIASED|REQUIRES_MORE_INVESTIGATION|NO_ACTION_NEEDED\",\n  \"comparison_with_primary\": {\n    \"areas_of_agreement\": \"what we both found\",\n    \"areas_of_disagreement\": \"where we differ\",\n    \"what_primary_missed\": [\n      \"Specific errors PRIMARY made\",\n      \"Evidence PRIMARY overlooked\",\n      \"Searches PRIMARY should have done\"\n    ],\n    \"why_different\": \"Detailed explanation if classifications differ\"\n  }\n}\n\nDO NOT use custom fields. DO NOT deviate from this structure.\nDO NOT return markdown code blocks. Return raw JSON only.\n\nCRITICAL REMINDERS:\n- TODAY: {{ $now.format('MMMM D, YYYY') }}\n- You are the BACKUP - be skeptical, catch PRIMARY's errors\n- Do INDEPENDENT verification - don't just agree\n- Use tweet's actual date in searches\n- Mark as UNVERIFIABLE if can't verify (don't fabricate)\n- Return ONLY valid JSON, no markdown, no code blocks\n\nReturn only JSON.",
        "options": {
          "systemMessage": "Backup fact-checker. USE web_search. Be independent. Disagreement is valuable. Return ONLY JSON, no markdown.",
          "maxIterations": 5
        }
      },
      "id": "58f61a3f-37aa-4a2c-84e5-1b56879c6b6c",
      "name": "Agent 1B - Fact Check Backup",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.6,
      "position": [
        1904,
        -1040
      ],
      "retryOnFail": true
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=ROLE: Source Credibility Analyst (BACKUP) - Independent Verification\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nğŸš¨ BACKUP MISSION: BE SKEPTICAL - CATCH PRIMARY'S MISTAKES\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nYOU are the BACKUP. Your job is to:\n- Find errors PRIMARY made\n- Catch missing verification\n- Be MORE critical, not MORE generous\n- Lower scores if verification is weak\n\nDO NOT just agree with PRIMARY.\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nPRIMARY'S ANALYSIS (REVIEW THIS FIRST!)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n{{ JSON.stringify($('Agent 2 - Credibility').item.json.output) }}\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nINPUT DATA (RE-ANALYZE INDEPENDENTLY)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nCONTENT: {{ $('Parse Input Data').item.json.tweetText }}\n\nSOURCE INFORMATION:\n- Source Type: {{ $('Parse Input Data').item.json.sourceType }}\n- Tweet Source: {{ $('Parse Input Data').item.json.tweetSource }}\n- Author: {{ $('Parse Input Data').item.json.author }}\n- Account Data: {{ JSON.stringify($('Parse Input Data').item.json.accountData) }}\n- Title: {{ $('Parse Input Data').item.json.title }}\n- Subject: {{ $('Parse Input Data').item.json.subject }}\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nBACKUP-SPECIFIC CHECKS (DO THESE FIRST!)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nReview PRIMARY's analysis and check:\n\nâ–¡ EXTERNAL VERIFICATION:\n  - Is PRIMARY's sources_checked EMPTY?\n  - If YES â†’ PRIMARY FAILED! Note in what_primary_missed\n  - If NO â†’ Are searches adequate? Re-verify independently\n\nâ–¡ RED FLAGS:\n  - tweets_per_day from accountData above\n  - If > 50, is it in PRIMARY's red_flags?\n  - If NO â†’ PRIMARY MISSED IT!\n  \nâ–¡ BIAS INDICATORS:\n  - Check accountData.description above\n  - Political terms? (BRICS, partisan language, geopolitics)\n  - Did PRIMARY note these in red_flags?\n  - If NO â†’ PRIMARY MISSED IT!\n\nâ–¡ SCORE JUSTIFICATION:\n  - PRIMARY's score vs red flags found\n  - If score HIGH but red_flags present â†’ TOO GENEROUS\n  - If score LOW but well-justified â†’ APPROPRIATE\n\nâ–¡ SOURCE TYPE:\n  - Is source_type accurate?\n  - \"verified_account\" is too generic\n  - Should be: partisan_commentator, official_org, etc.\n\nIMPORTANT:\n- If PRIMARY's sources_checked is empty â†’ Your score should be LOWER\n- If PRIMARY missed red flags â†’ Your score should be LOWER\n- If PRIMARY missed bias â†’ Your score should be LOWER\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nYOUR INDEPENDENT ANALYSIS\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nNow do YOUR OWN verification (don't just copy PRIMARY):\n\nSTEP 1: IDENTIFY SCENARIO\n\nCheck sourceType from input data:\n- \"twitter\" â†’ Use accountData, search reputation\n- \"dataset\" â†’ Extract publisher, search credibility\n- \"news\" â†’ Evaluate domain\n\nSTEP 2: MANDATORY EXTERNAL VERIFICATION\n\nYou MUST perform independent searches:\n\nFor Twitter:\nweb_search(\"[username] Twitter credibility\")\nweb_search(\"[username] reputation\")\nweb_search(\"[username] misinformation\") (if concerns exist)\n\nFor Dataset:\nweb_search(\"[publisher] Media Bias Fact Check\")\nweb_search(\"[publisher] credibility\")\n\nRecord ALL searches in sources_checked.\nCompare findings with PRIMARY's.\n\nSTEP 3: ANALYZE ACCOUNT METRICS (Twitter)\n\nFrom accountData above:\n- verified\n- followers\n- account_age_days\n- tweets_per_day\n- profile_completeness_score\n- description\n\nCheck if verified official org:\n- UNESCO, WHO, NASA, government, major media\n- If YES + followers > 100K â†’ HIGH rating (95)\n- Still must verify reputation\n\nIf NOT official org:\n- Calculate base score from metrics\n- ADJUST based on your external verification\n- ADJUST based on red flags YOU find\n\nSTEP 4: IDENTIFY RED FLAGS\n\nCheck for:\n- tweets_per_day > 50 â†’ Flag it\n- Political bias in bio (BRICS, partisan terms)\n- Known for misinformation (from your searches)\n- New account + high activity\n- Profile incomplete\n- Any red flags PRIMARY missed\n\nAdd ALL to your red_flags array.\n\nSTEP 5: CALCULATE YOUR SCORE\n\nBase score:\n- Verified official org = 90-95\n- Verified + 1M followers = 80-90\n- Verified + 100K followers = 70-80\n- Verified + 10K followers = 60-70\n- Established unverified = 50-65\n- New/low followers = 30-50\n\nADJUST for findings:\n- Known misinfo: -30\n- Partisan/biased: -10 to -20\n- High activity (>50/day): -5\n- Political bias in bio: -5 to -15\n- Generally reliable: +10\n- Established credible: +15\n\nSTEP 6: DETERMINE RATING\n\nAfter adjustments:\n- 85-100 = HIGH\n- 65-84 = MEDIUM\n- 45-64 = LOW\n- 0-44 = VERY_LOW\n\nSTEP 7: BOT ANALYSIS\n\nBot indicators:\n- tweets_per_day > 50\n- Account age < 30 days + high activity\n- Following >> followers\n- Incomplete profile\n\nAssessment:\n- 0-1 indicators = HUMAN_LIKELY\n- 2 indicators = MODERATE_RISK\n- 3+ indicators = HIGH_RISK\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nCOMPARE WITH PRIMARY\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nAfter YOUR analysis:\n\n1. SCORE DIFFERENCE:\n   Your score vs PRIMARY's score\n   \n   If YOU scored HIGHER:\n   â†’ Explain: What additional credibility did you find?\n   \n   If YOU scored LOWER:\n   â†’ Explain: What red flags did PRIMARY miss?\n   â†’ This is GOOD - you caught something!\n\n2. KEY DISAGREEMENTS:\n   - Did you find PRIMARY's sources_checked was empty?\n   - Did you find red flags PRIMARY missed?\n   - Did you find bias PRIMARY didn't note?\n   - Is PRIMARY's source_type too generic?\n\n3. WHAT PRIMARY MISSED (be specific!):\n   Examples:\n   - \"PRIMARY's sources_checked was empty - no external verification done\"\n   - \"PRIMARY didn't flag tweets_per_day 56.98 as red flag\"\n   - \"PRIMARY didn't note BRICS News bias indicator in bio\"\n   - \"PRIMARY gave score 80 despite partisan commentary\"\n   - \"PRIMARY called it 'verified_account' instead of 'partisan_commentator'\"\n\n4. WHY DIFFERENT:\n   If your score differs by > 15 points:\n   - Explain the verification PRIMARY didn't do\n   - Show the red flags PRIMARY missed\n   - Justify your lower/higher score with evidence\n\nREMEMBER:\n- If PRIMARY scored HIGH but you found issues â†’ Lower score is CORRECT\n- If PRIMARY didn't search â†’ Your thorough search justifies different score\n- Being skeptical and finding issues is GOOD, not bad\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSELF-CHECK BEFORE SUBMITTING\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nâ–¡ Did I do INDEPENDENT web searches?\nâ–¡ If sourceType = twitter, is MY sources_checked empty?\n  â†’ If YES, I FAILED! Do the searches!\nâ–¡ Did I check if PRIMARY's sources_checked was empty?\nâ–¡ If tweets_per_day > 50, did I flag it?\nâ–¡ Did I check bio for bias indicators?\nâ–¡ If I found issues PRIMARY missed, did I LOWER the score?\nâ–¡ Did I explain disagreements clearly in comparison section?\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nOUTPUT (JSON only)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n{\n  \"source_credibility\": {\n    \"rating\": \"HIGH|MEDIUM|LOW|UNKNOWN|VERY_LOW\",\n    \"score\": 0-100,\n    \"source_identified\": \"account or publisher name\",\n    \"source_type\": \"official_org|verified_account|partisan_commentator|blog|unknown\",\n    \"explanation\": \"Your rating rationale with external verification\",\n    \"sources_checked\": [\"REQUIRED: Your independent searches\"],\n    \"red_flags\": [\"All concerns YOU found\"],\n    \"extraction_method\": \"twitter_account|content_analysis|web_search\"\n  },\n  \"bot_likelihood\": {\n    \"assessment\": \"HIGH_RISK|MODERATE_RISK|LOW_RISK|HUMAN_LIKELY|NOT_APPLICABLE\",\n    \"data_available\": true/false,\n    \"account_age_days\": number,\n    \"tweets_per_day\": number,\n    \"profile_completeness_score\": \"X/7\",\n    \"bot_indicators\": [\"indicators YOU found\"],\n    \"confidence\": \"high|medium|low|not_applicable\"\n  },\n  \"overall_trustworthiness_score\": 0-100,\n  \"recommendation\": \"Your assessment\",\n  \"scenario\": \"twitter|dataset|news\",\n  \"comparison_with_primary\": {\n    \"areas_of_agreement\": \"What we both found\",\n    \"areas_of_disagreement\": \"Where we differ and WHY\",\n    \"what_primary_missed\": [\n      \"Specific items PRIMARY failed to check\",\n      \"Red flags PRIMARY didn't flag\",\n      \"Verification PRIMARY didn't do\",\n      \"Bias indicators PRIMARY ignored\"\n    ],\n    \"why_different\": \"Detailed explanation if scores differ by 15+ points\"\n  }\n}\n\nCRITICAL REMINDERS:\n- You are BACKUP - be skeptical, not agreeable\n- sources_checked CANNOT be empty for Twitter\n- If PRIMARY's sources_checked empty â†’ Note it + lower score\n- If PRIMARY missed red flags â†’ Note them + adjust score\n- If you score LOWER than PRIMARY and can justify it â†’ GOOD!\n- Return ONLY valid JSON, no markdown\n\nReturn only JSON.",
        "options": {
          "systemMessage": "Backup credibility analyst. USE web_search. Be independent. Return ONLY JSON, no markdown.",
          "maxIterations": 5
        }
      },
      "id": "88e74b4d-8794-4c53-b459-69d47f11f8d1",
      "name": "Agent 2B - Credibility Backup",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.6,
      "position": [
        1904,
        -512
      ]
    },
    {
      "parameters": {
        "jsCode": "try {\n  // Get both outputs\n  const backupOutputRaw = $input.item.json.output;\n  const primaryOutputRaw = $('Check Agent 1 Confidence').first().json.output;\n  \n  // Parse function\n  function safeParse(data) {\n    if (!data) return null;\n    if (typeof data === 'object') return data;\n    if (typeof data === 'string') {\n      try {\n        let cleaned = data.trim()\n          .replace(/^```json\\s*/i, '')\n          .replace(/^```\\s*/i, '')\n          .replace(/\\s*```$/i, '');\n        return JSON.parse(cleaned);\n      } catch (e) {\n        return null;\n      }\n    }\n    return null;\n  }\n  \n  const primary = safeParse(primaryOutputRaw);\n  const backup = safeParse(backupOutputRaw);\n  \n  if (!primary || !backup) {\n    return {\n      json: {\n        error: \"Failed to parse\",\n        primaryParsed: !!primary,\n        backupParsed: !!backup\n      }\n    };\n  }\n  \n  // Average scores\n  const avgFactScore = Math.round(\n    ((primary.fact_accuracy_score || 50) + (backup.fact_accuracy_score || 50)) / 2\n  );\n  \n  const avgDeceptScore = Math.round(\n    ((primary.deceptiveness_score || 50) + (backup.deceptiveness_score || 50)) / 2\n  );\n  \n  // Determine classification\n  let finalClassification;\n  const avgIntent = primary.appears_intentional || backup.appears_intentional;\n  \n  if (avgFactScore < 40) {\n    finalClassification = avgIntent ? 'DISINFORMATION' : 'MISINFORMATION';\n  } else if (avgFactScore >= 60 && avgDeceptScore > 60) {\n    finalClassification = 'PROPAGANDA';\n  } else if (avgFactScore > 80 && avgDeceptScore < 30) {\n    finalClassification = 'LEGITIMATE';\n  } else {\n    finalClassification = 'BIASED_BUT_FACTUAL';\n  }\n  \n  // Calculate confidence\n  const factDiff = Math.abs((primary.fact_accuracy_score || 50) - (backup.fact_accuracy_score || 50));\n  const deceptDiff = Math.abs((primary.deceptiveness_score || 50) - (backup.deceptiveness_score || 50));\n  const avgDiff = (factDiff + deceptDiff) / 2;\n  \n  const finalConfidence = avgDiff <= 10 ? 'high' : avgDiff <= 20 ? 'medium' : 'low';\n  \n  // Recommendation\n  let recommendation;\n  if (finalClassification === 'PROPAGANDA' || finalClassification === 'DISINFORMATION') {\n    recommendation = 'FLAG_AS_FALSE_NEWS';\n  } else if (finalClassification === 'MISINFORMATION' || finalClassification === 'BIASED_BUT_FACTUAL') {\n    recommendation = 'LABEL_AS_BIASED';\n  } else {\n    recommendation = 'NO_ACTION_NEEDED';\n  }\n  \n  // Merge arrays\n  const mergedPatterns = [...new Set([\n    ...(primary.false_news_patterns_detected || []),\n    ...(backup.false_news_patterns_detected || [])\n  ])];\n  \n  const mergedOmissions = [...new Set([\n    ...(primary.key_omissions || []),\n    ...(backup.key_omissions || [])\n  ])];\n  \n  const mergedTechniques = [...new Set([\n    ...(primary.manipulation_techniques || []),\n    ...(backup.manipulation_techniques || [])\n  ])];\n  \n  // Return merged result\n  return {\n    json: {\n      output: JSON.stringify({\n        classification: finalClassification,\n        fact_accuracy_score: avgFactScore,\n        deceptiveness_score: avgDeceptScore,\n        appears_intentional: avgIntent,\n        confidence: finalConfidence,\n        verified_claims: backup.verified_claims || primary.verified_claims || [],\n        false_news_patterns_detected: mergedPatterns,\n        key_omissions: mergedOmissions,\n        manipulation_techniques: mergedTechniques,\n        overall_assessment: `Primary: ${primary.overall_assessment || 'N/A'}. Backup: ${backup.overall_assessment || 'N/A'}. Agreement: ${avgDiff <= 10 ? 'Strong' : 'Moderate'} (diff: ${Math.round(avgDiff)})`,\n        recommendation: recommendation,\n        dual_verification: true,\n        agent_comparison: {\n          fact_score_diff: factDiff,\n          deceptiveness_diff: deceptDiff,\n          avg_difference: Math.round(avgDiff),\n          primary_classification: primary.classification,\n          backup_classification: backup.classification\n        }\n      })\n    }\n  };\n  \n} catch (error) {\n  return {\n    json: {\n      error: error.message,\n      stack: error.stack\n    }\n  };\n}"
      },
      "id": "745aebc8-8a01-443d-b1e6-9cfca1bbc014",
      "name": "Merge Agent 1 Results",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2544,
        -1152
      ],
      "retryOnFail": false,
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "jsCode": "try {\n  // Get both outputs (using same method as Agent 1 merge)\n  const backupOutputRaw = $input.item.json.output;\n  const primaryOutputRaw = $('Check Agent 2 Confidence').first().json.output;\n  \n  // Parse function\n  function safeParse(data) {\n    if (!data) return null;\n    if (typeof data === 'object') return data;\n    if (typeof data === 'string') {\n      try {\n        let cleaned = data.trim()\n          .replace(/^```json\\s*/i, '')\n          .replace(/^```\\s*/i, '')\n          .replace(/\\s*```$/i, '');\n        return JSON.parse(cleaned);\n      } catch (e) {\n        return null;\n      }\n    }\n    return null;\n  }\n  \n  const primary = safeParse(primaryOutputRaw);\n  const backup = safeParse(backupOutputRaw);\n  \n  if (!primary || !backup) {\n    return {\n      json: {\n        error: \"Failed to parse\",\n        primaryParsed: !!primary,\n        backupParsed: !!backup\n      }\n    };\n  }\n  \n  // Average trustworthiness score\n  const avgTrustScore = Math.round(\n    ((primary.overall_trustworthiness_score || 50) + (backup.overall_trustworthiness_score || 50)) / 2\n  );\n  \n  // Determine final rating\n  let finalRating;\n  if (avgTrustScore >= 80) finalRating = 'HIGH';\n  else if (avgTrustScore >= 60) finalRating = 'MEDIUM';\n  else if (avgTrustScore >= 40) finalRating = 'LOW';\n  else finalRating = 'VERY_LOW';\n  \n  const scoreDiff = Math.abs(\n    (primary.overall_trustworthiness_score || 50) - (backup.overall_trustworthiness_score || 50)\n  );\n  \n  // Merge sources and red flags\n  const mergedSourcesChecked = [...new Set([\n    ...(primary.source_credibility?.sources_checked || []),\n    ...(backup.source_credibility?.sources_checked || [])\n  ])];\n  \n  const mergedRedFlags = [...new Set([\n    ...(primary.source_credibility?.red_flags || []),\n    ...(backup.source_credibility?.red_flags || [])\n  ])];\n  \n  // Return merged result\n  return {\n    json: {\n      output: JSON.stringify({\n        source_credibility: {\n          rating: finalRating,\n          score: avgTrustScore,\n          source_identified: primary.source_credibility?.source_identified || backup.source_credibility?.source_identified || 'unknown',\n          source_type: primary.source_credibility?.source_type || backup.source_credibility?.source_type || 'unknown',\n          explanation: `Primary: ${primary.source_credibility?.explanation || 'N/A'}. Backup: ${backup.source_credibility?.explanation || 'N/A'}`,\n          sources_checked: mergedSourcesChecked,\n          red_flags: mergedRedFlags,\n          extraction_method: primary.source_credibility?.extraction_method || backup.source_credibility?.extraction_method || 'none'\n        },\n        bot_likelihood: primary.bot_likelihood || backup.bot_likelihood || {\n          assessment: 'NOT_APPLICABLE',\n          data_available: false\n        },\n        overall_trustworthiness_score: avgTrustScore,\n        recommendation: `Average trustworthiness: ${avgTrustScore}/100. Agreement: ${scoreDiff === 0 ? 'Perfect' : scoreDiff <= 15 ? 'Strong' : 'Moderate'}`,\n        scenario: primary.scenario || backup.scenario || 'unknown',\n        dual_verification: true,\n        agent_comparison: {\n          score_difference: scoreDiff,\n          primary_score: primary.overall_trustworthiness_score,\n          backup_score: backup.overall_trustworthiness_score,\n          primary_rating: primary.source_credibility?.rating,\n          backup_rating: backup.source_credibility?.rating\n        }\n      })\n    }\n  };\n  \n} catch (error) {\n  return {\n    json: {\n      error: error.message,\n      stack: error.stack\n    }\n  };\n}"
      },
      "id": "99d66d6d-16e1-4415-bd0f-064fa848b889",
      "name": "Merge Agent 2 Results",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2304,
        -448
      ]
    },
    {
      "parameters": {},
      "id": "d4941e80-a6d3-418a-b2df-6ab89d42992d",
      "name": "Merge Agents 1 & 2",
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3,
      "position": [
        2864,
        -448
      ]
    },
    {
      "parameters": {},
      "id": "5bc957c9-e907-4a93-a745-b2b425f5f72f",
      "name": "Merge with Agent 3",
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3,
      "position": [
        3136,
        -368
      ]
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=ROLE: Final Misinformation Risk Assessor\n\nINPUT:\n- Fact-check results: {{ $json.factCheck }}\n- Source credibility: {{ $json.sourceCheck }}\n- Account analysis: {{ $json.accountCheck }}\n\nMISSION: Synthesize all agent outputs â†’ final risk classification\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 1: EXTRACT DATA\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nFrom fact-check:\n- classification = {{ $json.factCheck.classification }}\n- fact_score = {{ $json.factCheck.fact_accuracy_score }}\n- deceptiveness = {{ $json.factCheck.deceptiveness_score }}\n- intentional = {{ $json.factCheck.appears_intentional }}\n- confidence = {{ $json.factCheck.confidence }}\n\nFrom source:\n- source_rating = {{ $json.sourceCheck.source_credibility.rating }}\n- source_score = {{ $json.sourceCheck.overall_trustworthiness_score }}\n- source_type = {{ $json.sourceCheck.source_credibility.source_type }}\n\nFrom account:\n- bot_assessment = {{ $json.accountCheck.bot_probability }}\n- account_score = {{ $json.accountCheck.authenticity_score }}\n- data_available = {{ $json.accountCheck.data_available }}\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 2: CHECK FOR VERIFIED OFFICIAL SOURCES\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nBEFORE calculating composite score, check if this is from a verified official source:\n\nIF source_type = \"official_org\" AND source_rating = \"HIGH\" AND account_score â‰¥ 90:\n  â†’ This is a VERIFIED OFFICIAL SOURCE\n  â†’ Even if fact-check has concerns, give high weight to source credibility\n  â†’ Official sources announcing their own actions = highest trust\n  â†’ Adjust risk assessment accordingly\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 3: CALCULATE COMPOSITE SCORE\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nDetermine data completeness:\nIF data_available = false OR bot_assessment = \"NOT_APPLICABLE\":\n  data_completeness = \"PARTIAL\"\n  composite = (fact_score Ã— 0.60) + (source_score Ã— 0.40)\nELSE:\n  data_completeness = \"FULL\"\n  composite = (fact_score Ã— 0.50) + (source_score Ã— 0.30) + (account_score Ã— 0.20)\n\nSPECIAL CASE - Verified Official Source:\nIF source_type = \"official_org\" AND source_rating = \"HIGH\":\n  â†’ Increase source weight\n  composite = (fact_score Ã— 0.40) + (source_score Ã— 0.45) + (account_score Ã— 0.15)\n  â†’ Note: \"Official source given higher weight\"\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 4: DETERMINE BASE RISK LEVEL\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nBased on composite score:\n- 0-40 = HIGH RISK\n- 41-70 = MEDIUM RISK  \n- 71-100 = LOW RISK\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 5: CONTEXTUAL ADJUSTMENTS\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nINCREASE to HIGH RISK if:\n- classification = \"DISINFORMATION\" (deliberate false info)\n- intentional = true AND deceptiveness > 70\n- source_rating = \"VERY_LOW\"\n- bot_assessment = \"VERY_HIGH\" AND source_rating = \"LOW\"\n\nKEEP or DECREASE to LOW RISK if:\n- source_type = \"official_org\" AND source_rating = \"HIGH\" AND account_score â‰¥ 90\n- classification = \"LEGITIMATE\" \n- composite score â‰¥ 85\n- All agents show high confidence\n\nINCREASE to MEDIUM RISK if:\n- classification = \"PROPAGANDA\" OR \"BIASED_BUT_FACTUAL\"\n- source_rating = \"LOW\"\n- deceptiveness > 60 but fact_score > 70\n- confidence = \"low\" across multiple agents\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 6: DETERMINE CONFIDENCE\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nHIGH confidence if:\n- All agents agree (scores within 15 points)\n- fact_check confidence = \"high\"\n- source_rating = \"HIGH\" or \"VERY_LOW\" (clear signals)\n\nMEDIUM confidence if:\n- Agents partially disagree (scores within 30 points)\n- fact_check confidence = \"medium\"\n- Some ambiguity in classification\n\nLOW confidence if:\n- Agents strongly disagree (scores >30 points apart)\n- fact_check confidence = \"low\"\n- Limited data available\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 7: BUILD KEY CONCERNS & MITIGATING FACTORS\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nKey Concerns (list if present):\n- Fact-check classification issues\n- Low source credibility\n- Bot-like behavior detected\n- Deliberate deception suspected\n- Missing context or omissions\n\nMitigating Factors (list if present):\n- Verified official source\n- High account authenticity\n- Established credible publisher\n- Factually accurate despite bias\n- No evidence of intent to deceive\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 8: RECOMMENDED ACTION\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nBased on risk level:\n\nHIGH RISK:\n- primary_action = \"Flag for review and add warning label\"\n- urgency = \"immediate\"\n- human_review_needed = true\n\nMEDIUM RISK:\n- primary_action = \"Add context or fact-check label\"\n- urgency = \"within_24h\"  \n- human_review_needed = true if deceptiveness > 70\n\nLOW RISK:\n- primary_action = \"Monitor for engagement patterns\"\n- urgency = \"monitor\"\n- human_review_needed = false\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nOUTPUT (JSON only)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n{\n  \"final_assessment\": {\n    \"risk_level\": \"HIGH|MEDIUM|LOW\",\n    \"composite_score\": calculated number 0-100,\n    \"confidence\": \"HIGH|MEDIUM|LOW\",\n    \"data_completeness\": \"FULL|PARTIAL\",\n    \"special_considerations\": \"note if official source, verified account, etc.\"\n  },\n  \"contributing_factors\": {\n    \"fact_check_classification\": actual value from factCheck,\n    \"fact_check_score\": actual number from factCheck,\n    \"source_credibility\": actual rating from sourceCheck,\n    \"source_score\": actual number from sourceCheck,\n    \"source_type\": actual type from sourceCheck,\n    \"account_authenticity\": actual assessment from accountCheck,\n    \"account_score\": actual number from accountCheck\n  },\n  \"key_concerns\": [\"list specific concerns based on data\"],\n  \"mitigating_factors\": [\"list specific mitigating factors\"],\n  \"recommended_action\": {\n    \"primary_action\": \"specific action based on risk\",\n    \"rationale\": \"clear explanation using actual data\",\n    \"urgency\": \"immediate|within_24h|monitor|none\"\n  },\n  \"human_review_needed\": true/false,\n  \"summary\": \"1-2 sentence summary using ACTUAL classifications and scores\"\n}\n\nCRITICAL REMINDERS:\n- Use ACTUAL values from factCheck, sourceCheck, accountCheck\n- Don't make up numbers or classifications\n- Recognize when official sources announce their own actions\n- Give appropriate weight to verified official sources\n- Explain reasoning clearly in rationale and summary\n- Return ONLY valid JSON, no markdown\n\nReturn only JSON.",
        "options": {
          "systemMessage": "You are final decision agent for misinformation risk. Return ONLY valid JSON, no markdown. Handle missing data gracefully.",
          "maxIterations": 1
        }
      },
      "id": "7acf3fa6-3b61-4a3f-b73b-760b8664ec37",
      "name": "Agent 4 - Decision",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.6,
      "position": [
        3696,
        -464
      ],
      "retryOnFail": true
    },
    {
      "parameters": {
        "jsCode": "// Format Agent 4 output for Google Sheets\nconst agent4Output = $input.first().json.output;\nconst originalData = $('Parse Input Data').first().json;\n\n// Parse Agent 4 JSON output\nlet assessment = {};\ntry {\n  if (typeof agent4Output === 'string') {\n    const cleaned = agent4Output.trim()\n      .replace(/^```json\\s*/i, '')\n      .replace(/^```\\s*/i, '')\n      .replace(/\\s*```$/i, '');\n    assessment = JSON.parse(cleaned);\n  } else {\n    assessment = agent4Output;\n  }\n} catch (e) {\n  assessment = { error: 'Failed to parse Agent 4 output' };\n}\n\n// Determine source type\nconst sourceType = originalData.sourceType || 'unknown';\nconst source = sourceType === 'twitter' ? 'Twitter' : \n               sourceType === 'dataset' ? 'WhatsApp/Dataset' : \n               'Unknown';\n\n// Get original content\nconst content = originalData.tweetText || originalData.text || 'N/A';\nconst contentPreview = content.substring(0, 200);\n\n// Extract scores\nconst riskLevel = assessment.final_assessment?.risk_level || 'UNKNOWN';\nconst compositeScore = assessment.final_assessment?.composite_score || 0;\nconst confidence = assessment.final_assessment?.confidence || 'UNKNOWN';\n\n// Extract contributing factors\nconst factCheckClass = assessment.contributing_factors?.fact_check_classification || 'N/A';\nconst factCheckScore = assessment.contributing_factors?.fact_check_score || 0;\nconst sourceCredibility = assessment.contributing_factors?.source_credibility || 'N/A';\nconst sourceScore = assessment.contributing_factors?.source_score || 0;\nconst accountAuth = assessment.contributing_factors?.account_authenticity || 'N/A';\nconst accountScore = assessment.contributing_factors?.account_score || 0;\n\n// Extract concerns and actions\nconst keyConcerns = (assessment.key_concerns || []).join('; ');\nconst recommendedAction = assessment.recommended_action?.primary_action || 'N/A';\nconst urgency = assessment.recommended_action?.urgency || 'N/A';\nconst rationale = assessment.recommended_action?.rationale || 'N/A';\nconst summary = assessment.summary || 'N/A';\n\n// Get metadata\nconst tweetUrl = originalData.tweetMetadata?.tweet_url || originalData.tweet_url || 'N/A';\nconst author = originalData.accountData?.username || 'N/A';\nconst dataset = originalData.dataset || 'N/A';\nconst supabaseId = originalData.supabase_id || 'N/A';\n\nreturn {\n  json: {\n    timestamp: new Date().toISOString(),\n    source: source,\n    source_type: sourceType,\n    content_preview: contentPreview,\n    full_content: content,\n    \n    // Risk Assessment\n    risk_level: riskLevel,\n    composite_score: compositeScore,\n    confidence: confidence,\n    \n    // Fact Check\n    fact_check_classification: factCheckClass,\n    fact_check_score: factCheckScore,\n    \n    // Source Credibility\n    source_credibility_rating: sourceCredibility,\n    source_credibility_score: sourceScore,\n    \n    // Account Analysis\n    account_authenticity: accountAuth,\n    account_score: accountScore,\n    \n    // Actions & Concerns\n    key_concerns: keyConcerns,\n    recommended_action: recommendedAction,\n    urgency: urgency,\n    rationale: rationale,\n    summary: summary,\n    \n    // Metadata\n    tweet_url: tweetUrl,\n    author: author,\n    dataset: dataset,\n    supabase_id: supabaseId,\n    \n    // Raw output for reference\n    raw_assessment: JSON.stringify(assessment)\n  }\n};"
      },
      "id": "cef1c4c7-8335-4d70-84e4-f341051e4454",
      "name": "Format for Google Sheets",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        4080,
        -464
      ]
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        1344,
        -176
      ],
      "id": "7b2be005-7924-49c6-9987-88cbb719673d",
      "name": "Google Gemini Chat Model2",
      "credentials": {
        "googlePalmApi": {
          "id": "MLCxKRnMtF7Rthld",
          "name": "Google Gemini(PaLM) Api account"
        }
      }
    },
    {
      "parameters": {
        "model": "meta-llama/llama-4-scout-17b-16e-instruct",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGroq",
      "typeVersion": 1,
      "position": [
        1904,
        -880
      ],
      "id": "cab41854-0e21-491f-832a-256e9aba850c",
      "name": "Groq Chat Model",
      "credentials": {
        "groqApi": {
          "id": "aDgjoiavOeg5nbsa",
          "name": "Groq account 2"
        }
      }
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        3696,
        -272
      ],
      "id": "a79ef219-7d69-47e9-a930-2fe676710bb2",
      "name": "Google Gemini Chat Model",
      "credentials": {
        "googlePalmApi": {
          "id": "MLCxKRnMtF7Rthld",
          "name": "Google Gemini(PaLM) Api account"
        }
      }
    },
    {
      "parameters": {
        "updates": [
          "messages"
        ],
        "options": {}
      },
      "type": "n8n-nodes-base.whatsAppTrigger",
      "typeVersion": 1,
      "position": [
        -816,
        -624
      ],
      "id": "87dbf778-171d-40d5-84e1-b681b215fe8f",
      "name": "WhatsApp Trigger",
      "webhookId": "6eb18407-e5ee-4bb0-9bef-c58ffcd4411b",
      "credentials": {
        "whatsAppTriggerApi": {
          "id": "vSb7Wo9wZmEFxgbX",
          "name": "WhatsApp OAuth account"
        }
      }
    },
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "const item = $input.item;\nconst body = item.json.messages?.[0]?.text?.body || 'F600';\n\nconst datasetType = body.charAt(0).toUpperCase();\nconst idx = parseInt(body.substring(1)) || 600;\nconst dataset = datasetType === 'T' ? 'true-news' : 'false-news';\n\nreturn {\n  json: {\n    datasetType: datasetType,\n    idx: idx,\n    dataset: dataset,\n    tableId: dataset,\n    rowId: idx\n  }\n};"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -496,
        -624
      ],
      "id": "eb9ab5fb-e965-445e-a326-bf6d6e03e7e8",
      "name": "WhatsApp Input Parser"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=Use the supabase tool to get data from the dataset.\n\nInput:\n- Table: {{ $json.tableId }}\n- Dataset Type: {{ $json.datasetType }}\n- Row ID: {{ $json.rowId }}\n\nFormat output as JSON:\n{\n  \"text\": \"the text field from supabase\",\n  \"tweetSource\": \"{{ $json.tableId }}\",\n  \"sourceType\": \"dataset\",\n  \"tweetMetadata\": {},\n  \"accountData\": {},\n  \"supabase_id\": {{ $json.rowId }},\n  \"dataset\": \"{{ $json.tableId }}\",\n  \"datasetType\": \"{{ $json.datasetType }}\",\n  \"title\": \"title field if exists\",\n  \"subject\": \"subject field if exists\",\n  \"date\": \"date field if exists\"\n}\n\nReturn only valid JSON.",
        "options": {
          "systemMessage": "You are a data formatter. Extract from Supabase and format as JSON. Return only valid JSON.",
          "maxIterations": 3
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.6,
      "position": [
        -208,
        -624
      ],
      "id": "0d930ed3-3d27-4b28-93e0-0ab7801b6210",
      "name": "AI Agent - Supabase Formatter",
      "executeOnce": false,
      "alwaysOutputData": true
    },
    {
      "parameters": {
        "operation": "get",
        "tableId": "={{ $json.dataset }}",
        "filters": {
          "conditions": [
            {
              "keyName": "id",
              "keyValue": "={{ $json.idx }}"
            }
          ]
        }
      },
      "type": "n8n-nodes-base.supabaseTool",
      "typeVersion": 1,
      "position": [
        -64,
        -400
      ],
      "id": "4e2bad3f-4623-41ff-9495-0c06006aa4e2",
      "name": "Get row from Dataset (Supabase)",
      "credentials": {
        "supabaseApi": {
          "id": "Cgrz5nOdspcCgDyr",
          "name": "Supabase account"
        }
      }
    },
    {
      "parameters": {
        "options": {
          "maxOutputTokens": 1000
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        -208,
        -384
      ],
      "id": "31a474be-95a9-4c4b-b1b6-2cdbe6a21d3a",
      "name": "Google Gemini Chat Model3",
      "credentials": {
        "googlePalmApi": {
          "id": "MLCxKRnMtF7Rthld",
          "name": "Google Gemini(PaLM) Api account"
        }
      }
    },
    {
      "parameters": {},
      "id": "c9bffb5f-5f7b-48c4-ac4d-3b241fac7b20",
      "name": "Merge Dataset & Twitter Inputs",
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3,
      "position": [
        112,
        -608
      ]
    },
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "const item = $input.item.json;\n\nconsole.log('ğŸ” Format Input Data received:', Object.keys(item));\nconsole.log('ğŸ‘¤ accountData received:', item.accountData);\nconsole.log('ğŸ“… created_at received:', item.created_at);  // â† ADD: Debug log\n\n// Check if this is Twitter data (from viral tweets or WhatsApp)\nconst isTwitterViral = item.tweetSource === 'twitter_viral' || item.tweetSource === 'twitter_viral_random' || (item.tweetText && item.sourceType === 'twitter');\nconst isWhatsAppTwitter = item.body && item.body.tweetText;\nconst isDataset = item.dataset || (item.text && !isTwitterViral);\n\nif (isTwitterViral) {\n  // Data from enriched Twitter - PRESERVE enriched accountData!\n  const result = {\n    json: {\n      tweetText: item.tweetText || item.tweet_text || '',\n      tweetSource: item.tweetSource || 'twitter_viral',\n      tweetMetadata: item.tweetMetadata || {\n        virality_score: item.virality_score,\n        engagement: item.engagement,\n        author: item.author,\n        verified: item.verified,\n        tweet_id: item.tweet_id,\n        tweet_url: item.tweet_url,\n        created_at: item.created_at || 'unknown'  // â† ADD THIS LINE!\n      },\n      // CRITICAL: Use enriched accountData if available!\n      accountData: item.accountData || {},\n      sourceType: 'twitter',\n      tweet_id: item.tweet_id,\n      tweet_url: item.tweet_url,\n      virality_score: item.virality_score,\n      engagement: item.engagement,\n      author: item.author\n    }\n  };\n  \n  console.log('âœ… Formatted Twitter data');\n  console.log('âœ… accountData in result:', result.json.accountData);\n  console.log('âœ… created_at in result:', result.json.tweetMetadata.created_at);  // â† ADD: Debug log\n  \n  return result;\n  \n} else if (isWhatsAppTwitter) {\n  // Data from WhatsApp (nested under body)\n  return {\n    json: {\n      tweetText: item.body.tweetText || '',\n      tweetSource: item.body.tweetSource || 'whatsapp',\n      tweetMetadata: item.body.tweetMetadata || {\n        created_at: item.body.created_at || 'unknown'  // â† ADD THIS!\n      },\n      accountData: item.body.accountData || {},\n      sourceType: 'twitter'\n    }\n  };\n  \n} else if (isDataset) {\n  // Data from dataset\n  return {\n    json: {\n      tweetText: item.text || '',\n      tweetSource: item.tweetSource || item.dataset || 'dataset',\n      tweetMetadata: item.tweetMetadata || {\n        date: item.date || 'unknown'  // â† Datasets might have different date field\n      },\n      accountData: item.accountData || {},\n      sourceType: item.sourceType || 'dataset',\n      supabase_id: item.supabase_id,\n      dataset: item.dataset,\n      datasetType: item.datasetType,\n      title: item.title,\n      subject: item.subject,\n      date: item.date\n    }\n  };\n  \n} else {\n  // Fallback for unknown format\n  console.log('âš ï¸ Unknown format, using fallback');\n  return {\n    json: {\n      tweetText: JSON.stringify(item),\n      tweetSource: 'unknown',\n      tweetMetadata: {\n        created_at: 'unknown'  // â† ADD THIS!\n      },\n      accountData: {},\n      sourceType: 'manual'\n    }\n  };\n}"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        608,
        -384
      ],
      "id": "e0284964-4597-4402-a752-0032392909af",
      "name": "Format Input Data"
    },
    {
      "parameters": {
        "jsCode": "// Combine all 3 agent outputs into one structured object\nconst allInputs = $input.all();\n\n// Safe parse function\nfunction safeParse(data) {\n  if (!data) return null;\n  if (typeof data === 'object' && !Array.isArray(data)) return data;\n  if (typeof data === 'string') {\n    try {\n      let cleaned = data.trim()\n        .replace(/^```json\\s*/i, '')\n        .replace(/^```\\s*/i, '')\n        .replace(/\\s*```$/i, '');\n      return JSON.parse(cleaned);\n    } catch (e) {\n      console.error('Parse error:', e);\n      return null;\n    }\n  }\n  return null;\n}\n\n// Parse each input\nconst factCheck = safeParse(allInputs[0]?.json?.output);\nconst sourceCheck = safeParse(allInputs[1]?.json?.output);\nconst accountCheck = safeParse(allInputs[2]?.json?.output);\n\n// Return combined data\nreturn {\n  json: {\n    factCheck: factCheck || {\n      classification: 'UNVERIFIABLE',\n      fact_accuracy_score: 50,\n      deceptiveness_score: 50,\n      appears_intentional: false,\n      confidence: 'low'\n    },\n    sourceCheck: sourceCheck || {\n      source_credibility: { rating: 'UNKNOWN', score: 50 },\n      overall_trustworthiness_score: 50\n    },\n    accountCheck: accountCheck || {\n      bot_probability: 'NOT_APPLICABLE',\n      authenticity_score: 50,\n      data_available: false\n    }\n  }\n};"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        3408,
        -368
      ],
      "id": "4b762e93-8178-47da-938d-0dbfeb11ebcd",
      "name": "Combine for Agent 4"
    },
    {
      "parameters": {
        "rule": {
          "interval": [
            {
              "field": "hours",
              "hoursInterval": 4
            }
          ]
        }
      },
      "id": "01135144-da57-42b4-97b8-cacb3dc4d602",
      "name": "Every 4 Hours",
      "type": "n8n-nodes-base.scheduleTrigger",
      "typeVersion": 1.2,
      "position": [
        -992,
        -96
      ]
    },
    {
      "parameters": {},
      "type": "n8n-nodes-base.manualTrigger",
      "typeVersion": 1,
      "position": [
        -1088,
        208
      ],
      "id": "e384aa39-a4df-40e7-a3e0-cb36edb9796c",
      "name": "Manual Trigger"
    },
    {
      "parameters": {
        "url": "https://twitter-api45.p.rapidapi.com/search.php",
        "sendQuery": true,
        "queryParameters": {
          "parameters": [
            {
              "name": "query",
              "value": "(breaking OR urgent OR news) min_retweets:500 lang:en"
            },
            {
              "name": "search_type",
              "value": "Latest"
            },
            {
              "name": "count",
              "value": "1"
            }
          ]
        },
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "X-RapidAPI-Key",
              "value": "80ab7267a3msh12d875a20cb2293p104766jsnd30f01f53a5c"
            },
            {
              "name": "X-RapidAPI-Host",
              "value": "twitter-api45.p.rapidapi.com"
            }
          ]
        },
        "options": {}
      },
      "id": "cfacc24c-15c8-43d9-b788-c7e9a3d006aa",
      "name": "Search Viral News Tweets",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -624,
        0
      ]
    },
    {
      "parameters": {
        "jsCode": "// Configuration\nconst ITEM_LIMIT = 1;\nconst TOP_N_POOL = 10;\n\nconsole.log('ğŸ¯ Config: Return', ITEM_LIMIT, 'random tweet(s) from top', TOP_N_POOL);\n\nconst response = $input.first().json;\n\n// Get tweets array\nconst tweets = response.timeline || response.tweets || response.results || response.data || [];\n\nif (!Array.isArray(tweets) || tweets.length === 0) {\n  console.log('âŒ No tweets found');\n  return [{json: {error: 'No tweets found', raw: response}}];\n}\n\nconsole.log('âœ… Found', tweets.length, 'tweets');\n\n// Calculate virality for each tweet\nconst ranked = tweets.map(t => {\n  const retweets = t.retweet_count || t.retweetCount || t.retweets || t.public_metrics?.retweet_count || 0;\n  const likes = t.favorite_count || t.favoriteCount || t.likeCount || t.likes || t.favorites || t.public_metrics?.like_count || 0;\n  const replies = t.reply_count || t.replyCount || t.replies || t.public_metrics?.reply_count || 0;\n  const quotes = t.quote_count || t.quoteCount || t.quotes || t.public_metrics?.quote_count || 0;\n  \n  const viralityScore = (retweets * 2) + likes + (replies * 3) + (quotes * 2);\n  \n  return {\n    ...t,\n    virality_score: viralityScore,\n    _retweets: retweets,\n    _likes: likes,\n    _replies: replies,\n    _quotes: quotes\n  };\n});\n\n// Sort by virality (highest first)\nranked.sort((a, b) => b.virality_score - a.virality_score);\n\n// Take top N pool\nconst topPool = ranked.slice(0, Math.min(TOP_N_POOL, ranked.length));\n\nconsole.log('ğŸ² Top', topPool.length, 'viral tweets:', topPool.map(t => t.virality_score));\n\n// Randomly select from the pool\nconst shuffled = topPool.sort(() => Math.random() - 0.5);\nconst selected = shuffled.slice(0, ITEM_LIMIT);\n\nconsole.log('âœ¨ Randomly selected tweet with virality:', selected[0]?.virality_score);\n\n// Format output\nreturn selected.map((t, i) => {\n  const user = t.user_info || t.user || t.author || {};\n  const id = t.id_str || t.id || t.tweet_id || t.tweetId;\n  const text = t.full_text || t.text || t.tweet_text || t.content || '';\n  const username = user.screen_name || user.username || t.screen_name || 'unknown';\n  \n  return {\n    json: {\n      rank: 'random_from_top_' + TOP_N_POOL,\n      tweet_id: id,\n      tweet_text: text,\n      tweet_url: id ? `https://twitter.com/i/web/status/${id}` : 'N/A',\n      virality_score: t.virality_score,\n      engagement: `${t._retweets} RT | ${t._likes} â™¥ | ${t._replies} ğŸ’¬ | ${t._quotes} ğŸ’¬`,\n      author: `@${username}`,\n      verified: (user.verified || t.verified) ? 'âœ“' : 'âœ—',\n      preview: text.substring(0, 150) + '...',\n      created_at: t.created_at || 'unknown',  // â† ONLY LINE ADDED!\n      \n      // For misinformation pipeline\n      tweetText: text,\n      tweetSource: 'twitter_viral_random',\n      sourceType: 'twitter',\n      accountData: {\n        username: username,\n        verified: user.verified || t.verified || false,\n        followers: user.followers_count || user.followersCount || 0\n      }\n    }\n  };\n});"
      },
      "id": "477f40c6-038c-4424-8f62-b100774eba75",
      "name": "Get Top N Most Viral",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -400,
        0
      ]
    },
    {
      "parameters": {
        "operation": "append",
        "documentId": {
          "__rl": true,
          "value": "19x-lnuAPH9FbvyLR8es4pUxxw5QXHhsLVpBXCfBxWfc",
          "mode": "list",
          "cachedResultName": "tetst",
          "cachedResultUrl": "https://docs.google.com/spreadsheets/d/19x-lnuAPH9FbvyLR8es4pUxxw5QXHhsLVpBXCfBxWfc/edit?usp=drivesdk"
        },
        "sheetName": {
          "__rl": true,
          "value": "gid=0",
          "mode": "list",
          "cachedResultName": "Sheet1",
          "cachedResultUrl": "https://docs.google.com/spreadsheets/d/19x-lnuAPH9FbvyLR8es4pUxxw5QXHhsLVpBXCfBxWfc/edit#gid=0"
        },
        "columns": {
          "mappingMode": "autoMapInputData",
          "value": {},
          "matchingColumns": [],
          "schema": [],
          "attemptToConvertTypes": false,
          "convertFieldsToString": false
        },
        "options": {}
      },
      "type": "n8n-nodes-base.googleSheets",
      "typeVersion": 4.7,
      "position": [
        4320,
        -464
      ],
      "id": "4a4015c3-3b74-4b32-b6c1-3b55ae112cae",
      "name": "Append row in sheet",
      "credentials": {
        "googleSheetsOAuth2Api": {
          "id": "pOlMsCkST1NkdxUo",
          "name": "Google Sheets account 2"
        }
      }
    },
    {
      "parameters": {
        "url": "=https://twitter-api45.p.rapidapi.com/screenname.php?screenname={{ $json.accountData.username }}",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "X-RapidAPI-Key",
              "value": "80ab7267a3msh12d875a20cb2293p104766jsnd30f01f53a5c"
            },
            {
              "name": "X-RapidAPI-Host",
              "value": "twitter-api45.p.rapidapi.com"
            }
          ]
        },
        "options": {
          "response": {
            "response": {}
          }
        }
      },
      "id": "66ccba20-934c-45c0-bdf4-44ceda0f0b19",
      "name": "Enrich Twitter Account Data",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -224,
        240
      ]
    },
    {
      "parameters": {
        "jsCode": "const item = $input.first().json;\n\nconsole.log('ğŸ“¥ Input keys:', Object.keys(item));\nconsole.log('ğŸ” Has enrichmentData?', !!item.enrichmentData);\n\n// Original tweet data\nconst originalData = { ...item };\ndelete originalData.enrichmentData; // Remove the API response from spread\n\n// API response\nconst apiResponse = item.enrichmentData;\n\nif (!apiResponse || !Array.isArray(apiResponse) || apiResponse.length === 0) {\n  console.log('âŒ No enrichment data, returning original');\n  return { json: originalData };\n}\n\n// Extract user data\nconst userData = apiResponse[0];\nconsole.log('ğŸ‘¤ User data keys:', Object.keys(userData));\n\n// Extract values\nconst followers = userData.sub_count || 0;\nconst following = userData.friends || 0;\nconst totalTweets = userData.statuses_count || 0;\nconst isVerified = userData.blue_verified || false;\n\nconsole.log('ğŸ“Š Extracted - Followers:', followers, 'Following:', following);\n\n// Calculate\nconst createdAt = new Date(userData.created_at);\nconst accountAgeDays = Math.floor((Date.now() - createdAt.getTime()) / (1000 * 60 * 60 * 24));\nconst tweetsPerDay = accountAgeDays > 0 ? (totalTweets / accountAgeDays).toFixed(2) : '0';\nconst followerRatio = following > 0 ? (followers / following).toFixed(2) : String(followers);\n\n// Profile completeness\nlet score = 0;\nif (userData.avatar) score += 1;\nif (userData.desc) score += 1;\nif (userData.location) score += 1;\nif (isVerified) score += 2;\nif (userData.header_image) score += 1;\nif (userData.website) score += 1;\n\n// Build enriched data\nconst enrichedAccountData = {\n  username: userData.name || userData.profile,\n  verified: isVerified,\n  followers: followers,\n  following: following,\n  follower_ratio: followerRatio,\n  total_tweets: totalTweets,\n  account_age_days: accountAgeDays,\n  tweets_per_day: tweetsPerDay,\n  profile_completeness_score: `${score}/7`,\n  has_profile_image: !!userData.avatar,\n  has_bio: !!userData.desc,\n  has_location: !!userData.location,\n  has_banner: !!userData.header_image,\n  has_website: !!userData.website,\n  created_at: userData.created_at,\n  description: userData.desc || '',\n  location: userData.location || '',\n  website: userData.website || ''\n};\n\nconsole.log('âœ… Enriched accountData:', enrichedAccountData);\n\n// Return original data with enriched accountData\nreturn {\n  json: {\n    ...originalData,\n    accountData: enrichedAccountData\n  }\n};\n"
      },
      "id": "41d80536-0ba7-48ab-bbcd-bbab43d01160",
      "name": "Merge Enriched Data",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -48,
        240
      ]
    },
    {
      "parameters": {},
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3.2,
      "position": [
        192,
        -96
      ],
      "id": "8db7af24-b845-4732-bb1b-b0e534635ba8",
      "name": "Merge2"
    },
    {
      "parameters": {
        "jsCode": "const inputs = $input.all();\n\nif (inputs.length !== 2) {\n  return { json: inputs[0]?.json || {} };\n}\n\n// Item 0: Original tweet data\nconst originalData = inputs[0].json;\n\n// Item 1: API response\nconst apiResponse = inputs[1].json;\n\n// Extract user data\nconst userData = apiResponse;\n\n// Extract values\nconst followers = userData.sub_count || 0;\nconst following = userData.friends || 0;\nconst totalTweets = userData.statuses_count || 0;\nconst isVerified = userData.blue_verified || false;\n\n// Calculate derived fields\nconst createdAt = new Date(userData.created_at);\nconst accountAgeDays = Math.floor((Date.now() - createdAt.getTime()) / (1000 * 60 * 60 * 24));\nconst tweetsPerDay = accountAgeDays > 0 ? (totalTweets / accountAgeDays).toFixed(2) : '0';\nconst followerRatio = following > 0 ? (followers / following).toFixed(2) : String(followers);\n\n// Calculate profile completeness score\nlet score = 0;\nif (userData.avatar) score += 1;\nif (userData.desc) score += 1;\nif (userData.location) score += 1;\nif (isVerified) score += 2;\nif (userData.header_image) score += 1;\nif (userData.website) score += 1;\n\n// Build enriched accountData\nconst enrichedAccountData = {\n  username: userData.name,\n  verified: isVerified,\n  followers: followers,\n  following: following,\n  follower_ratio: followerRatio,\n  total_tweets: totalTweets,\n  account_age_days: accountAgeDays,\n  tweets_per_day: tweetsPerDay,\n  profile_completeness_score: `${score}/7`,\n  has_profile_image: !!userData.avatar,\n  has_bio: !!userData.desc,\n  has_location: !!userData.location,\n  has_banner: !!userData.header_image,\n  has_website: !!userData.website,\n  created_at: userData.created_at,\n  description: userData.desc || '',\n  location: userData.location || '',\n  website: userData.website || ''\n};\n\n// Return original data with enriched accountData\nreturn {\n  json: {\n    ...originalData,\n    accountData: enrichedAccountData\n  }\n};"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        400,
        -96
      ],
      "id": "b9a7938f-c7b5-4b75-ad01-ff1ad4eff3fa",
      "name": "Build Final Enriched Data"
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        1248,
        -624
      ],
      "id": "43eafa85-b08a-449f-b4af-4f26c0fc7acf",
      "name": "Google Gemini Chat Model4",
      "credentials": {
        "googlePalmApi": {
          "id": "MLCxKRnMtF7Rthld",
          "name": "Google Gemini(PaLM) Api account"
        }
      }
    },
    {
      "parameters": {
        "model": "meta-llama/llama-4-scout-17b-16e-instruct",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGroq",
      "typeVersion": 1,
      "position": [
        1952,
        -256
      ],
      "id": "cea92b1d-a2ea-4295-a0f7-18ffde08a629",
      "name": "Groq Chat Model1",
      "credentials": {
        "groqApi": {
          "id": "aDgjoiavOeg5nbsa",
          "name": "Groq account 2"
        }
      }
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        1408,
        272
      ],
      "id": "5567b6d5-4752-423b-b9ed-6477baf2f56c",
      "name": "Google Gemini Chat Model5",
      "credentials": {
        "googlePalmApi": {
          "id": "MLCxKRnMtF7Rthld",
          "name": "Google Gemini(PaLM) Api account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "try {\n  // Get both outputs\n  const backupOutputRaw = $input.item.json.output;\n  const primaryOutputRaw = $('Check Agent 1 Confidence').first().json.output;\n  \n  // Parse function\n  function safeParse(data) {\n    if (!data) return null;\n    if (typeof data === 'object') return data;\n    if (typeof data === 'string') {\n      try {\n        let cleaned = data.trim()\n          .replace(/^```json\\s*/i, '')\n          .replace(/^```\\s*/i, '')\n          .replace(/\\s*```$/i, '');\n        return JSON.parse(cleaned);\n      } catch (e) {\n        return null;\n      }\n    }\n    return null;\n  }\n  \n  const primary = safeParse(primaryOutputRaw);\n  const backup = safeParse(backupOutputRaw);\n  \n  if (!primary || !backup) {\n    return {\n      json: {\n        error: \"Failed to parse\",\n        primaryParsed: !!primary,\n        backupParsed: !!backup\n      }\n    };\n  }\n  \n  // Check if both agents agree on special classifications\n  const primaryClass = primary.classification;\n  const backupClass = backup.classification;\n  \n  // If both agree on UNVERIFIABLE, SATIRICAL, or CLICK-BAIT, keep it\n  if (primaryClass === backupClass && \n      ['UNVERIFIABLE', 'SATIRICAL', 'CLICK-BAIT'].includes(primaryClass)) {\n    return {\n      json: {\n        output: JSON.stringify({\n          classification: primaryClass,\n          fact_accuracy_score: Math.round(\n            ((primary.fact_accuracy_score || 50) + (backup.fact_accuracy_score || 50)) / 2\n          ),\n          deceptiveness_score: Math.round(\n            ((primary.deceptiveness_score || 50) + (backup.deceptiveness_score || 50)) / 2\n          ),\n          appears_intentional: primary.appears_intentional || backup.appears_intentional,\n          confidence: primary.confidence || backup.confidence || 'medium',\n          verified_claims: backup.verified_claims || primary.verified_claims || [],\n          false_news_patterns_detected: [...new Set([\n            ...(primary.false_news_patterns_detected || []),\n            ...(backup.false_news_patterns_detected || [])\n          ])],\n          key_omissions: [...new Set([\n            ...(primary.key_omissions || []),\n            ...(backup.key_omissions || [])\n          ])],\n          manipulation_techniques: [...new Set([\n            ...(primary.manipulation_techniques || []),\n            ...(backup.manipulation_techniques || [])\n          ])],\n          overall_assessment: `Primary: ${primary.overall_assessment || 'N/A'}. Backup: ${backup.overall_assessment || 'N/A'}. Both agents agree on ${primaryClass}.`,\n          recommendation: primary.recommendation || backup.recommendation || 'REQUIRES_MORE_INVESTIGATION',\n          dual_verification: true,\n          agent_comparison: {\n            fact_score_diff: Math.abs((primary.fact_accuracy_score || 50) - (backup.fact_accuracy_score || 50)),\n            deceptiveness_diff: Math.abs((primary.deceptiveness_score || 50) - (backup.deceptiveness_score || 50)),\n            avg_difference: Math.round(\n              (Math.abs((primary.fact_accuracy_score || 50) - (backup.fact_accuracy_score || 50)) +\n               Math.abs((primary.deceptiveness_score || 50) - (backup.deceptiveness_score || 50))) / 2\n            ),\n            primary_classification: primaryClass,\n            backup_classification: backupClass\n          }\n        })\n      }\n    };\n  }\n  \n  // Average scores\n  const avgFactScore = Math.round(\n    ((primary.fact_accuracy_score || 50) + (backup.fact_accuracy_score || 50)) / 2\n  );\n  \n  const avgDeceptScore = Math.round(\n    ((primary.deceptiveness_score || 50) + (backup.deceptiveness_score || 50)) / 2\n  );\n  \n  // Determine classification (for disagreements or standard classifications)\n  let finalClassification;\n  const avgIntent = primary.appears_intentional || backup.appears_intentional;\n  \n  // Check if either agent said UNVERIFIABLE\n  if (primaryClass === 'UNVERIFIABLE' || backupClass === 'UNVERIFIABLE') {\n    finalClassification = 'UNVERIFIABLE';\n  }\n  // Check for SATIRICAL\n  else if (primaryClass === 'SATIRICAL' || backupClass === 'SATIRICAL') {\n    finalClassification = 'SATIRICAL';\n  }\n  // Check for CLICK-BAIT\n  else if (primaryClass === 'CLICK-BAIT' || backupClass === 'CLICK-BAIT') {\n    finalClassification = 'CLICK-BAIT';\n  }\n  // Standard classification logic\n  else if (avgFactScore < 40) {\n    finalClassification = avgIntent ? 'DISINFORMATION' : 'MISINFORMATION';\n  } else if (avgFactScore >= 60 && avgDeceptScore > 60) {\n    finalClassification = 'PROPAGANDA';\n  } else if (avgFactScore > 80 && avgDeceptScore < 30) {\n    finalClassification = 'LEGITIMATE';\n  } else {\n    finalClassification = 'BIASED_BUT_FACTUAL';\n  }\n  \n  // Calculate confidence\n  const factDiff = Math.abs((primary.fact_accuracy_score || 50) - (backup.fact_accuracy_score || 50));\n  const deceptDiff = Math.abs((primary.deceptiveness_score || 50) - (backup.deceptiveness_score || 50));\n  const avgDiff = (factDiff + deceptDiff) / 2;\n  \n  const finalConfidence = avgDiff <= 10 ? 'high' : avgDiff <= 20 ? 'medium' : 'low';\n  \n  // Recommendation\n  let recommendation;\n  if (finalClassification === 'UNVERIFIABLE') {\n    recommendation = 'REQUIRES_MORE_INVESTIGATION';\n  } else if (finalClassification === 'PROPAGANDA' || finalClassification === 'DISINFORMATION') {\n    recommendation = 'FLAG_AS_FALSE_NEWS';\n  } else if (finalClassification === 'MISINFORMATION' || finalClassification === 'BIASED_BUT_FACTUAL') {\n    recommendation = 'LABEL_AS_BIASED';\n  } else {\n    recommendation = 'NO_ACTION_NEEDED';\n  }\n  \n  // Merge arrays\n  const mergedPatterns = [...new Set([\n    ...(primary.false_news_patterns_detected || []),\n    ...(backup.false_news_patterns_detected || [])\n  ])];\n  \n  const mergedOmissions = [...new Set([\n    ...(primary.key_omissions || []),\n    ...(backup.key_omissions || [])\n  ])];\n  \n  const mergedTechniques = [...new Set([\n    ...(primary.manipulation_techniques || []),\n    ...(backup.manipulation_techniques || [])\n  ])];\n  \n  // Return merged result\n  return {\n    json: {\n      output: JSON.stringify({\n        classification: finalClassification,\n        fact_accuracy_score: avgFactScore,\n        deceptiveness_score: avgDeceptScore,\n        appears_intentional: avgIntent,\n        confidence: finalConfidence,\n        verified_claims: backup.verified_claims || primary.verified_claims || [],\n        false_news_patterns_detected: mergedPatterns,\n        key_omissions: mergedOmissions,\n        manipulation_techniques: mergedTechniques,\n        overall_assessment: `Primary: ${primary.overall_assessment || 'N/A'}. Backup: ${backup.overall_assessment || 'N/A'}. Agreement: ${avgDiff <= 10 ? 'Strong' : 'Moderate'} (diff: ${Math.round(avgDiff)})`,\n        recommendation: recommendation,\n        dual_verification: true,\n        agent_comparison: {\n          fact_score_diff: factDiff,\n          deceptiveness_diff: deceptDiff,\n          avg_difference: Math.round(avgDiff),\n          primary_classification: primaryClass,\n          backup_classification: backupClass\n        }\n      })\n    }\n  };\n  \n} catch (error) {\n  return {\n    json: {\n      error: error.message,\n      stack: error.stack\n    }\n  };\n}"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2256,
        -1040
      ],
      "id": "8f1618de-d07a-489a-b7f6-8d9e7bd027e7",
      "name": "Code in JavaScript"
    },
    {
      "parameters": {
        "jsCode": "ROLE: Source Trustworthiness Evaluator\n\nINPUT DATA:\n- Tweet Text: {{ $json.tweetText }}\n- Source Type: {{ $json.sourceType }}\n- Tweet Source: {{ $json.tweetSource }}\n- Author: {{ $json.author }}\n- Account Data: {{ JSON.stringify($json.accountData) }}\n- Title: {{ $json.title }}\n- Subject: {{ $json.subject }}\n\nMISSION: Assess source reliability and bot behavior based on the scenario.\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 1: IDENTIFY SCENARIO (CHECK SOURCE TYPE!)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nLook at \"Source Type\" field above:\n\nIF sourceType = \"twitter\":\n  â†’ Scenario: TWITTER\n  â†’ Use accountData for analysis\n  â†’ Analyze bot behavior\n  â†’ Check verification status\n  â†’ Evaluate account credibility\n  \nIF sourceType = \"dataset\":\n  â†’ Scenario: DATASET\n  â†’ Extract publisher from text\n  â†’ Skip bot detection\n  â†’ Evaluate content quality\n  \nIF sourceType = \"news\":\n  â†’ Scenario: NEWS\n  â†’ Evaluate domain credibility\n  â†’ Skip bot detection\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 2A: TWITTER ANALYSIS (if sourceType = \"twitter\")\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nCRITICAL: Use the accountData object provided above!\n\n1. EXTRACT ACCOUNT INFO:\n   From accountData:\n   - username\n   - verified (true/false)\n   - followers\n   - following\n   - account_age_days\n   - tweets_per_day\n   - profile_completeness_score\n\n2. CHECK IF VERIFIED OFFICIAL ACCOUNT:\n   \n   Is verified = TRUE?\n   Is username an official organization?\n   \n   OFFICIAL ORGANIZATIONS:\n   - UN bodies: UNESCO, WHO, UNICEF, UNHCR, UNEP, WFP, FAO, etc.\n   - Space agencies: NASA, ESA, JAXA, ISRO, etc.\n   - Health: CDC, NIH, FDA, etc.\n   - Government: Official verified govt accounts\n   - Universities: Verified educational institutions\n   - Major media: BBC, CNN, Reuters, AP, etc.\n   - NGOs: Red Cross, MSF, Amnesty, etc.\n   \n   IF verified = TRUE + official org + followers > 100K:\n     â†’ rating = \"HIGH\"\n     â†’ score = 95\n     â†’ source_type = \"official_org\"\n     â†’ explanation = \"Verified official organization\"\n     â†’ bot_likelihood.assessment = \"HUMAN_LIKELY\"\n     â†’ bot_likelihood.data_available = true\n     â†’ DONE (skip to output)\n\n3. CALCULATE SOURCE SCORE (if not official):\n   \n   Base score from verification and metrics:\n   - Verified + 1M+ followers = 85-90\n   - Verified + 100K+ followers = 75-85\n   - Verified + 10K+ followers = 65-75\n   - Unverified but established (5+ years, 10K+ followers) = 55-70\n   - Unverified, new or low followers = 30-55\n   - Red flags (new + high tweets/day) = 20-35\n\n4. DETERMINE RATING:\n   - 90-100 = HIGH\n   - 70-89 = MEDIUM\n   - 50-69 = LOW\n   - Below 50 = VERY_LOW\n\n5. BOT ANALYSIS:\n   Use accountData to assess:\n   \n   Bot indicators:\n   - Account age < 30 days + tweets_per_day > 50\n   - Following > followers * 10 (spam pattern)\n   - Profile incomplete (score < 3/7)\n   - Very high tweet frequency (>100/day)\n   \n   Calculate bot_likelihood:\n   - 0-2 indicators = \"HUMAN_LIKELY\"\n   - 3 indicators = \"MODERATE_RISK\"\n   - 4+ indicators = \"HIGH_RISK\"\n   \n   Always set bot_likelihood.data_available = true (Twitter has data)\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 2B: DATASET ANALYSIS (if sourceType = \"dataset\")\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n1. EXTRACT PUBLISHER from text:\n   Look in title, subject, and text for:\n   - Domain names (breitbart.com, cnn.com, etc.)\n   - \"Published by [name]\"\n   - \"Source: [publication]\"\n   - Author byline with publication\n   \n   IGNORE (these are NOT publishers):\n   - Photo credits: \"Image via [X]\"\n   - Social media mentions\n   - Sources cited in article\n\n2. IF PUBLISHER IDENTIFIED:\n   Use web_search to check credibility:\n   - web_search(\"[publisher name] Media Bias Fact Check\")\n   - web_search(\"[publisher name] credibility\")\n   \n   Set rating and score based on findings:\n   - Least Biased/High Factual = HIGH (85-100)\n   - Left/Right High Factual = MEDIUM (60-80)\n   - Mixed Factual = LOW (35-60)\n   - Questionable Source = VERY_LOW (0-35)\n\n3. IF NO PUBLISHER IDENTIFIED:\n   Assess content quality:\n   \n   Red flags (lower score):\n   - No publication name anywhere\n   - No author byline\n   - Vulgar/unprofessional language\n   - Sensational headlines\n   - Multiple spelling/grammar errors\n   \n   Score based on red flags:\n   - 0-1 red flags = 50-60 (UNKNOWN)\n   - 2-3 red flags = 35-50 (LOW)\n   - 4+ red flags = 15-35 (VERY_LOW)\n\n4. BOT ANALYSIS:\n   bot_likelihood.assessment = \"NOT_APPLICABLE\"\n   bot_likelihood.data_available = false\n   (No account data for datasets)\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nSTEP 3: CALCULATE OVERALL TRUSTWORTHINESS\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nIF scenario = \"twitter\":\n  IF bot_likelihood = \"HIGH_RISK\":\n    overall_score = source_score * 0.7 (penalize for bot behavior)\n  ELSE:\n    overall_score = source_score\n\nIF scenario = \"dataset\":\n  overall_score = source_score\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nOUTPUT (JSON only)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n{\n  \"source_credibility\": {\n    \"rating\": \"HIGH|MEDIUM|LOW|UNKNOWN|VERY_LOW\",\n    \"score\": 0-100,\n    \"source_identified\": \"account name or publisher name or 'unknown'\",\n    \"source_type\": \"official_org|verified_account|established_news|blog|unknown\",\n    \"explanation\": \"Brief reasoning for rating\",\n    \"sources_checked\": [\"list web_search queries used\"],\n    \"red_flags\": [\"list any issues found\"],\n    \"extraction_method\": \"twitter_account|metadata|content_analysis|web_search\"\n  },\n  \"bot_likelihood\": {\n    \"assessment\": \"HIGH_RISK|MODERATE_RISK|LOW_RISK|HUMAN_LIKELY|NOT_APPLICABLE\",\n    \"data_available\": true/false,\n    \"account_age_days\": from accountData or 0,\n    \"tweets_per_day\": from accountData or 0,\n    \"profile_completeness_score\": from accountData or \"0/7\",\n    \"bot_indicators\": [\"list specific indicators found\"],\n    \"confidence\": \"high|medium|low|not_applicable\"\n  },\n  \"overall_trustworthiness_score\": 0-100,\n  \"recommendation\": \"Brief summary and recommendation\",\n  \"scenario\": \"twitter|dataset|news\"\n}\n\nCRITICAL REMINDERS:\n- Check sourceType FIRST to determine scenario\n- For Twitter: USE accountData - don't say \"unknown\" when data exists!\n- Recognize verified official organizations (UNESCO, WHO, NASA, etc.)\n- For Dataset: Extract publisher or assess content quality\n- Always set bot_likelihood.data_available correctly\n- Return ONLY valid JSON, no markdown\n\nReturn only JSON."
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2528,
        -1280
      ],
      "id": "f4a6be46-e289-409d-948f-a811379cb6b6",
      "name": "Agent 2 - Credibility instructions"
    }
  ],
  "pinData": {},
  "connections": {
    "Parse Input Data": {
      "main": [
        [
          {
            "node": "Agent 2 - Credibility",
            "type": "main",
            "index": 0
          },
          {
            "node": "Agent 3 - Twitter Check",
            "type": "main",
            "index": 0
          },
          {
            "node": "Agent 1 - Fact Check",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Agent 1 - Fact Check": {
      "main": [
        [
          {
            "node": "Check Agent 1 Confidence",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Agent 2 - Credibility": {
      "main": [
        [
          {
            "node": "Check Agent 2 Confidence",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Agent 3 - Twitter Check": {
      "main": [
        [
          {
            "node": "Merge with Agent 3",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Check Agent 1 Confidence": {
      "main": [
        [
          {
            "node": "Agent 1B - Fact Check Backup",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Merge Agents 1 & 2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Check Agent 2 Confidence": {
      "main": [
        [
          {
            "node": "Agent 2B - Credibility Backup",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Merge Agents 1 & 2",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Agent 1B - Fact Check Backup": {
      "main": [
        [
          {
            "node": "Code in JavaScript",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Agent 2B - Credibility Backup": {
      "main": [
        [
          {
            "node": "Merge Agent 2 Results",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge Agent 1 Results": {
      "main": [
        []
      ]
    },
    "Merge Agent 2 Results": {
      "main": [
        [
          {
            "node": "Merge Agents 1 & 2",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Merge Agents 1 & 2": {
      "main": [
        [
          {
            "node": "Merge with Agent 3",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge with Agent 3": {
      "main": [
        [
          {
            "node": "Combine for Agent 4",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Agent 4 - Decision": {
      "main": [
        [
          {
            "node": "Format for Google Sheets",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Format for Google Sheets": {
      "main": [
        [
          {
            "node": "Append row in sheet",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Google Gemini Chat Model2": {
      "ai_languageModel": [
        [
          {
            "node": "Agent 2 - Credibility",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Groq Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "Agent 1B - Fact Check Backup",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Google Gemini Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "Agent 4 - Decision",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Google Gemini Chat Model3": {
      "ai_languageModel": [
        [
          {
            "node": "AI Agent - Supabase Formatter",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Get row from Dataset (Supabase)": {
      "ai_tool": [
        [
          {
            "node": "AI Agent - Supabase Formatter",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "WhatsApp Trigger": {
      "main": [
        [
          {
            "node": "WhatsApp Input Parser",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "WhatsApp Input Parser": {
      "main": [
        [
          {
            "node": "AI Agent - Supabase Formatter",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "AI Agent - Supabase Formatter": {
      "main": [
        [
          {
            "node": "Merge Dataset & Twitter Inputs",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge Dataset & Twitter Inputs": {
      "main": [
        [
          {
            "node": "Format Input Data",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Format Input Data": {
      "main": [
        [
          {
            "node": "Parse Input Data",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Combine for Agent 4": {
      "main": [
        [
          {
            "node": "Agent 4 - Decision",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Every 4 Hours": {
      "main": [
        [
          {
            "node": "Search Viral News Tweets",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Manual Trigger": {
      "main": [
        [
          {
            "node": "Search Viral News Tweets",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Search Viral News Tweets": {
      "main": [
        [
          {
            "node": "Get Top N Most Viral",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Get Top N Most Viral": {
      "main": [
        [
          {
            "node": "Enrich Twitter Account Data",
            "type": "main",
            "index": 0
          },
          {
            "node": "Merge2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Enrich Twitter Account Data": {
      "main": [
        [
          {
            "node": "Merge Enriched Data",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge Enriched Data": {
      "main": [
        [
          {
            "node": "Merge2",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Merge2": {
      "main": [
        [
          {
            "node": "Build Final Enriched Data",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Build Final Enriched Data": {
      "main": [
        [
          {
            "node": "Format Input Data",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Google Gemini Chat Model4": {
      "ai_languageModel": [
        [
          {
            "node": "Agent 1 - Fact Check",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Groq Chat Model1": {
      "ai_languageModel": [
        [
          {
            "node": "Agent 2B - Credibility Backup",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Google Gemini Chat Model5": {
      "ai_languageModel": [
        [
          {
            "node": "Agent 3 - Twitter Check",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Code in JavaScript": {
      "main": [
        [
          {
            "node": "Merge Agents 1 & 2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": false,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "cdc36bce-dcfc-429b-8087-ec797daf136d",
  "meta": {
    "templateCredsSetupCompleted": true,
    "instanceId": "121d8e9b68760b992e165904fd6888a7f1a58413d4a67cf93ef67eae09ef6b3b"
  },
  "id": "UdFgh3zTtvfu7YdQ",
  "tags": []
}